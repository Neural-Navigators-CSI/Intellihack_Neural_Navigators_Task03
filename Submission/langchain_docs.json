[{"page_content": "DualPipe DualPipe innovative bidirectional pipeline parallelism algorithm introduced DeepSeekV3 Technical Report. It achieves full overlap forward backward computationcommunication phases, also reducing pipeline bubbles. For detailed information computationcommunication overlap, please refer profile data. Pipeline Bubbles Memory Usage Comparison Method Bubble Parameter Activation 1F1B PP1\ud835\udc39\ud835\udc35 1 PP ZB1P PP1\ud835\udc39\ud835\udc352\ud835\udc4a 1 PP DualPipe PP21\ud835\udc39\ud835\udc35\ud835\udc353\ud835\udc4a 2 PP1 \ud835\udc39 denotes execution time forward chunk, \ud835\udc35 denotes execution time full backward chunk, \ud835\udc4a denotes execution time backward weights chunk, \ud835\udc39\ud835\udc35 denotes execution time two mutually overlapped forward backward chunks. About A bidirectional pipeline parallelism algorithm computationcommunication overlap V3R1 training DualPipe created developed Jiashi Li Chengqi Deng Wenfeng Liang. Profiling Data DeepSeek Infra Here, publicly share profiling data training inference framework help community better understand communicationcomputation overlap strategies lowlevel implementation details. The profiling data captured using PyTorch Profiler. After downloading, visualize directly navigating chrometracing Chrome browser edgetracing Edge browser. Notice simulate absolutely balanced MoE routing strategy profiling. Training The training profile data demonstrates overlapping strategy pair individual forward backward chunks DualPipe. Each chunk contains 4 MoE Mixture Experts layers. The parallel configuration aligns DeepSeekV3 pretraining settings EP64, TP1 4K sequence length. And PP communication included profilng simplicity. Inference Prefilling For prefilling, profile employs EP32 TP1 line DeepSeek V3R1 actual online deployment, prompt length set 4K batch size 16K tokens per GPU. In prefilling stage, utilize two microbatches overlap computation alltoall communication, ensuring attention computation load balanced across two microbatches meaning prompt may split them. Decoding For decoding, profile employs EP128, TP1, prompt length 4K closely matching actual online deployment configuration, batch size 128 requests per GPU. Similar prefilling, decoding also leverages two microbatches overlapping computation alltoall communication. However, unlike prefilling, alltoall communication decoding occupy GPU SMs RDMA messages issued, GPU SMs freed, system waits alltoall communication complete computation finished. For information alltoall implementation, please refer DeepEP. Expert Parallelism Load Balancer EPLB When using expert parallelism EP, different experts assigned different GPUs. Because load different experts may vary depending current workload, important keep load different GPUs balanced. As described DeepSeekV3 paper, adopt redundant experts strategy duplicates heavyloaded experts. Then, heuristically pack duplicated experts GPUs ensure load balancing across different GPUs. Moreover, thanks grouplimited expert routing used DeepSeekV3, also attempt place experts group node reduce internode data traffic, whenever possible. To facilitate reproduction deployment, opensource deployed EP load balancing algorithm eplb.py. The algorithm computes balanced expert replication placement plan based estimated expert loads. Note exact method predict loads experts repos scope. A common method use moving average historical statistics. The Algorithm The load balancing algorithm comes two policies used different cases. Hierarchical Load Balancing When number server nodes divides number expert groups, use hierarchical load balancing policy harness grouplimited expert routing. We first pack expert groups nodes evenly, ensuring loads different nodes balanced. Then, replicate experts within node. Finally, pack replicated experts individual GPUs ensure different GPUs loadbalanced. The hierarchical load balancing policy used prefilling stage smaller expertparallel size. Global Load Balancing In cases, use global load balancing policy replicates experts globally regardless expert groups, pack replicated experts individual GPUs. This policy adopted decoding stage larger expertparallel size. FireFlyer File system The FireFlyer File System 3FS highperformance distributed file system designed address challenges AI training inference workloads. It leverages modern SSDs RDMA networks provide shared storage layer simplifies development distributed applications. Key features benefits 3FS include Performance Usability Disaggregated Architecture Combines throughput thousands SSDs network bandwidth hundreds storage nodes, enabling applications access storage resource localityoblivious manner. Strong Consistency Implements Chain Replication Apportioned Queries CRAQ strong consistency, making application code simple easy reason about. File Interfaces Develops stateless metadata services backed transactional keyvalue store e.g., FoundationDB. The file interface well known used everywhere. There need learn new storage API. Diverse Workloads Data Preparation Organizes outputs data analytics pipelines hierarchical directory structures manages large volume intermediate outputs efficiently. Dataloaders Eliminates need prefetching shuffling datasets enabling random access training samples across compute nodes. Checkpointing Supports highthroughput parallel checkpointing largescale training. KVCache Inference Provides costeffective alternative DRAMbased caching, offering high throughput significantly larger capacity. Performance 1. Peak throughput The following figure demonstrates throughput read stress test large 3FS cluster. This cluster consists 180 storage nodes, equipped 2200Gbps InfiniBand NICs sixteen 14TiB NVMe SSDs. Approximately 500 client nodes used read stress test, client node configured 1x200Gbps InfiniBand NIC. The final aggregate read throughput reached approximately 6.6 TiBs background traffic training jobs. 2. GraySort We evaluated smallpond using GraySort benchmark, measures sort performance largescale datasets. Our implementation adopts twophase approach 1 partitioning data via shuffle using prefix bits keys, 2 inpartition sorting. Both phases readwrite data fromto 3FS. The test cluster comprised 25 storage nodes 2 NUMA domainsnode, 1 storage serviceNUMA, 2400Gbps NICsnode 50 compute nodes 2 NUMA domains, 192 physical cores, 2.2 TiB RAM, 1200 Gbps NICnode. Sorting 110.5 TiB data across 8,192 partitions completed 30 minutes 14 seconds, achieving average throughput 3.66 TiBmin. 3. KVCache KVCache technique used optimize LLM inference process. It avoids redundant computations caching key value vectors previous tokens decoder layers. The top figure demonstrates read throughput KVCache clients, highlighting peak average values, peak throughput reaching 40 GiBs. The bottom figure presents IOPS removing ops garbage collection GC time period."}, {"page_content": "Design Notes Design implementation The 3FS system four components cluster manager, metadata service, storage service client. All components connected RDMA network InfiniBand RoCE. Metadata storage services send heartbeats cluster manager. Cluster manager handles membership changes distributes cluster configuration services clients. Multiple cluster managers deployed one elected primary. Another manager promoted primary primary fails. Cluster configuration typically stored reliable distributed coordination service, ZooKeeper etcd. In production environment, use keyvalue store file metadata reduce dependencies. File metadata operations e.g. open create filesdirectories sent metadata services, implement file system semantics. Metadata services stateless, since file metadata stored transactional keyvalue store e.g. FoundationDB. Clients connect metadata service. Each storage service manages local SSDs provides chunk store interface. The storage service implements Chain Replication Apportioned Queries CRAQ ensure strong consistency. CRAQs writeallreadany approach helps unleash throughput SSDs RDMA network. A 3FS file split equally sized chunks, replicated multiple SSDs. Two clients developed applications FUSE client native client. Most applications use FUSE client, low adoption barrier. Performancecritical applications integrated native client. File system interfaces Object store becoming popular option data analytics machine learning. However, file system semantics unified namespace files organized directories provide greater flexibility applications. Atomic directory manipulation An object store approximate hierarchical directory structures using slashes object keys. However, doesnt natively support operations like atomically moving filesdirectories, recursively deleting entire directories. Actually common pattern internal applications involves creating temporary directory, writing files it, moving directory final location. When handling large number small files, recursive delete directories crucial. Without it, applications traverse directory remove files one one. Symbolic hard links Our applications utilize symbolic hard links create lightweight snapshots dynamically updated datasets, new data appended individual files. Familiar interface The file interface well known used everywhere. There need learn new storage API. Many datasets stored CSVParquet files. Adapting filebased data loaders use 3FS FUSE client native client straightforward. Limitations FUSE FUSE Filesystem Userspace simplifies file system client development redirecting IO operations userspace processes FUSE kernel module. It creates illusion applications accessing remote file system local file system. However, performance limitations Memory copy overhead The userspace file system daemon cannot access application memory. Data transfer kernel user spaces consumes memory bandwidth increases endtoend latency. Primitive multithreading support When application initiates IO requests, FUSE places requests multithreaded shared queue, protected spin lock. The userspace file system daemon retrieves processes requests queue. Due lock contention, FUSEs IO processing capability fails scale number threads. Our benchmark results indicate FUSE handles approximately 400K 4KiB reads per second. Further increasing concurrency improve performance lock contention intensifies. perf profiling reveals kernelspace spin lock consumes significant amount CPU time. Most applications, e.g. data analytics, perform large block writes 3FS buffer data memory flush 3FS write buffer full. However, FUSE Linux 5.x support concurrent writes file1. Applications overcome limitation writing multiple files concurrently, maximizing total throughput. Read operations exhibit complex patterns. Some training jobs require random access dataset samples, read sizes varying kilobytes several megabytes per sample. And samples typically 4Kaligned files. Data loaders specifically designed fetch batches samples. But perform poorly handling small random reads FUSEmounted 3FS. Bandwidth SSDs RDMA network fully utilized. Asynchronous zerocopy API Implementing file system client VFS kernel module avoids performance issues mentioned above. But kernel module development significantly challenging userspace system programming. Bugs difficult diagnose lead catastrophic failures production environments. For example, machines may crash leave log message debugging. When upgrading kernel module, processes using file system must stopped cleanly otherwise, machine restart required. For reasons, chosen implement native client within FUSE daemon. This client offers interface supports asynchronous zerocopy IO operations. File meta operations still handled FUSE daemon e.g. openclosestat files. Applications call open obtain file descriptor fd register via native API. They perform IO operations file native client. This approach ensures consistency metadata operations POSIX API, making easier migrate existing code. The asynchronous, zerocopy API inspired Linux io_uring. Below key data structures API Iov A large memory region zerocopy readwrite operations, shared user process native client. InfiniBand memory registration managed client. In native API, read data read Iov, write data written Iov calling API. Ior A small shared ring buffer communication user process native client. The usage Ior similar Linux io_uring, user process enqueues readwrite requests, native client dequeues requests completion. The requests executed batches, sizes controlled io_depth parameter. Multiple batches processed parallel, whether different rings ring. However, multiple rings still recommended multithreaded applications, sharing ring requires synchronization, impact performance. Within native client, multiple threads spawned fetch IO requests Iors. These requests batched dispatched storage services, reducing RPC overhead caused small read requests. File metadata store Location file chunks 3FS divides file data equally sized chunks stripes across multiple replication chains replication chains chain tables defined Section Data placementdataplacement. Users specify chain table, chunk size, stripe size files perdirectory basis. Each chunk independently stored multiple storage services, chunk ID generated concatenating files inode id chunk index. When creating new file, metadata service employs roundrobin strategy select consecutive replication chains designated chain table, based stripe size. Next, random seed generated shuffle selected chains. This allocation strategy ensures balanced data distribution across chains SSDs. When application opens file, client contacts meta service obtain files data layout information. Then client independently compute chunk IDs chains data operations, minimizing involvement meta service critical path. File metadata transactional keyvalue store 3FS uses FoundationDB distributed storage system metadata. FoundationDB provides keyvalue store interface supports transactions Serializable Snapshot Isolation SSI. 3FS stores metadata keyvalue pairs FoundationDB. Meta services follow stateless architecture, greatly enhancing maintainability allowing administrators seamlessly upgrade restart services without disruption. When clients experience request failures timeouts, automatically fail available services. The file system metadata primarily consists two core structures inodes directory entries. Inodes store attribute information files, directories, symbolic links, identified globally unique 64bit identifier increments monotonically. Inode keys constructed concatenating INOD prefix inode id, encoded littleendian byte order spread inodes multiple FoundationDB nodes. The inode values vary type All inode types contain basic attributes ownership, permissions, accessmodificationchange times. Additional attributes file inodes file length, chunk size, selected range chain table, shuffle seed. Additional attributes directory inodes parent directorys inode id, default layout configurations subdirectoriesfiles chain table, chunk size, stripe size. The parents inode id required detect loops moving directories. When moving dir_adir_b dir_c, need ensure dir_c descendant dir_b, achieved checking ancestors dir_c upward. Additional attributes symbolic link inodes target path string. Directory entry keys composed DENT prefix, parent inode ID, entry name. Directory entry values store target inode id inode type. All entries within directory naturally form contiguous key range, allowing efficient directory listing via range queries. The meta operations leverage FoundationDBs transactions Readonly transactions used metadata queries fstat, lookup, listdir etc. Readwrite transactions used metadata updates create, link, unlink, rename etc. For write transactions, FoundationDB tracks readwrite key sets form conflict detection sets. When concurrent transaction conflicts detected, meta service automatically retries transaction. This design enables multiple meta services process requests parallel maintaining file system metadata consistency. Dynamic file attributes On local file systems, deleting opened file deferred associated file descriptors closed. Consequently, necessary track file descriptors file. Training jobs open large number files startup. Storing file descriptors would impose heavy load meta service FoundationDB. Since training jobs depend feature, 3FS track file descriptors opened readonly mode. 3FS maintains file session file descriptor fd opened write mode since deleting write opened files may lead unreclaimable garbage chunks concurrent writes. When file active write sessions deleted, meta service delays deletion fds closed. To prevent lingering sessions offline clients, 3FS meta service periodically checks client liveness cleans sessions offline clients. The file length stored inode. For files actively updated, length stored inode may diverge actual length. Clients periodically 5 seconds default report meta service maximum write position file opened write mode. If position exceeds length inode concurrent truncate operation, position adopted new file length. Due possibility concurrent writes multiple clients, method described ensures eventual consistency file lengths. When processing closefsync operations, meta service obtains precise file length querying ID length last chunk storage service. Since file data striped across multiple chains, operation incurs nonnegligible overhead. Concurrent updates files length multiple meta services may cause transaction conflicts lead repeated file length computation. To mitigate this, meta service distributes file length update tasks across multiple meta services using inode IDs rendezvous hash algorithm. Our production environments use large stripe size 200. For small files, number chains containing file chunks well number. The number potentially used chains stored file inode used hint updating length. It starts initial value 16 doubled time additional file chunks written chains. This allows us avoid querying 200 chains updating lengths small files. This optimization also extended deletion small files. Chunk storage system The design goal chunk storage system achieve highest bandwidth possible even storage medium failures. The readwrite throughput 3FS scale linearly number SSDs bisection network bandwidth clients storage services. Applications access storage services localityoblivious manner. Data placement Each file chunk replicated chain storage targets using chain replication apportioned queries CRAQ. In CRAQ write requests sent head target propagated along chain. Read requests sent storage target. Usually read traffic evenly distributed among targets chain better load balance. Multiple storage targets created SSD targets join different chains. Suppose 6 nodes A, B, C, D, E, F. Each node 1 SSD. Create 5 storage targets SSD 1, 2, ... 5. Then 30 targets total A1, A2, A3, ..., F5. If chunk 3 replicas, chain table constructed follows. Chain Version Target 1 head Target 2 Target 3 tail 1 1 A1 B1 C1 2 1 D1 E1 F1 3 1 A2 B2 C2 4 1 D2 E2 F2 5 1 A3 B3 C3 6 1 D3 E3 F3 7 1 A4 B4 C4 8 1 D4 E4 F4 9 1 A5 B5 C5 10 1 D5 E5 F5 Each chain version number. The version number incremented chain changed e.g. storage target offline. Only primary cluster manager makes changes chain tables. A chain tables constructed support different data placement requirements. For example, two chain tables created, one batchoffline jobs another online services. The two tables consist storage targets mutually exclusive nodes SSDs. Logically, state chain changes independently. Each chain included multiple chain tables. The concept chain table created let metadata service pick table file stripe file chunks across chains table. Balanced traffic recovery Suppose read traffic evenly distributed among storage targets chain table. When A fails read requests would redirected B C. Under heavy load read bandwidth B, C immediately saturated B, C become bottleneck entire system. Replacing failed SSD syncing data new SSD take several hours. The read throughput impaired period. To reduce performance impact, SSDs share redirected traffic. In following chain table, A paired every SSDs. When A fails, SSDs receives 15 As read traffic. Chain Version Target 1 head Target 2 Target 3 tail 1 1 B1 E1 F1 2 1 A1 B2 D1 3 1 A2 D2 F2 4 1 C1 D3 E2 5 1 A3 C2 F3 6 1 A4 B3 E3 7 1 B4 C3 F4 8 1 B5 C4 E4 9 1 A5 C5 D4 10 1 D5 E5 F5 To achieve maximum read throughput recovery, load balance problem formulated balanced incomplete block design. The optimal solution obtained using integer programming solver. Data replication CRAQ writeallreadany replication protocol optimized readheavy workloads. Utilizing read bandwidth replicas critical achieve highest read throughput allflash storage system. When write request received storage service, goes following steps 1. The service checks chain version write request matches latest known version reject request not. The write request could sent client predecessor chain. 2. The service issues RDMA Read operations pull write data. If clientpredecessor fails, RDMA Read operations may time write aborted. 3. Once write data fetched local memory buffer, lock chunk updated acquired lock manager. Concurrent writes chunk blocked. All writes serialized head target. 4. The service reads committed version chunk memory, applies update, stores updated chunk pending version. A storage target may store two versions chunk committed version pending version. Each version monotonicallyincreasing version number. The version numbers committed version pending versions v u respectively, satisfy u v 1. 5. If service tail, committed version atomically replaced pending version acknowledgment message sent predecessor. Otherwise, write request forwarded successor. When committed version updated, current chain version stored field chunk metadata. 6. When acknowledgment message arrives storage service, service replaces committed version pending version continues propagate message predecessor. The local chunk lock released. Suppose 3 targets chain A, B, C. A write request entered step 5 A. A forwards request successor B. Then B instantly fails forwarded write request lost. When cluster manager detects Bs failure, marks B offline moves end chain broadcasts updated chain table. Once A receives latest chain table, forwards write request new successor C. C may receive latest chain table yet rejects request. But A keep forwarding request C. Eventually C gets latest chain table accepts request. When read request arrives storage service 1. When service committed version chunk, version returned client. 2. Unlike CRAQ, implementation issue version query tail target. When committed pending versions, service replies special status code notify client. The client may wait short interval retry. Or client issue relaxed read request get pending version. Failure detection The cluster manager relies heartbeats detect failstop failures. Cluster manager declares service failed receive heartbeats configurable interval e.g. T seconds. A service stops processing requests exits cannot communicate cluster manager T2 seconds. The heartbeat seen request renew lease granted manager. The metadata services stateless. The list online meta services provided cluster manager simple service discovery mechanism helps clients create connections metadata services. If one meta service down, clients may switch metadata service. Cluster manager plays critical role membership changes storage services. It maintains global view chain tables storage targets states. Each storage target public state local state. Public state indicates ready serve read requests write requests would propagated it. Public states stored chain tables distributed services clients. Public State Read Write Notes serving Y Y service alive serving client requests syncing N Y service alive data recovery progress waiting N N service alive data recovery started yet lastsrv N N service last serving target offline N N service storage medium failure Local state known storage services cluster manager, stored memory cluster manager. If storage target medium failure, related service sets targets local state offline heartbeat. If storage service down, storage targets managed service marked offline. Local State Notes uptodate service alive serving client requests online service alive target syncing waiting state offline service storage medium failure A storage target change one public state another response latest local state. The local state plays role triggering event. The cluster manager periodically scans every chain updates public states targets chain according statetransition table. The chain version incremented chain updated. If storage target marked offline, moved end chain. If storage service finds public state local storage target lastsrv offline, exits immediately. The service may isolated cluster manager network partition error. Once data recovery storage target syncing state completed, storage service set targets local state uptodate subsequent heartbeat messages sent cluster manager. Local State Current Public State Predecessors Public State Next Public State uptodate serving serving syncing serving waiting waiting lastsrv serving offline waiting online serving serving syncing serving syncing serving waiting waiting serving syncing serving waiting lastsrv serving offline waiting offline serving predecessor lastsrv predecessor offline syncing offline waiting offline lastsrv lastsrv offline offline Data recovery When storage service exits e.g. process crashes restarts upgrade, storage medium failure occurs, related storage targets marked offline moved end chains cluster manager. Once service restarts, target service enters recovery process independently. The entire recovery process overlaps normal activity minimizes interruption. When previously offline storage service starts 1. The service periodically pulls latest chain tables cluster manager. But send heartbeats storage targets marked offline latest chain tables. This ensures targets would go data recovery process. 2. When write request arrives recovery, request always fullchunkreplace write. The local committed version updated existing pending version abandoned. Since current service tail, acknowledgment message sent predecessor. The full state predecessor copied returning service continuous stream fullchunkreplace writes. 3. Before data recovery storage target starts, predecessor sends dumpchunkmeta request returning service. Then service iterates local chunk metadata store collect ids, chain versions committedpending version numbers chunks target, replies collected metadata predecessor. 4. When syncdone message arrives, service knows storage target uptodate. It sets local state target uptodate heartbeat messages sent cluster manager. When storage service finds previously offline successor online 1. The service starts forward normal write requests successor. Clients may update portion chunk, forwarded write requests contain whole chunk, i.e. fullchunkreplace write. 2. The service sends dumpchunkmeta request successor. Once metadata chunks successor target received, collects chunk metadata local target. Then compares two copies chunk metadata decide chunks transferred. 3. The selected chunks transferred successor issuing fullchunkreplace write requests. The chunk lock first acquired chunk. The chain version, committed version number chunk content read transferred successor sending fullchunkreplace request. The chunk lock released. 4. When required chunks transferred, syncdone message sent successor. The rules used decide chunks transferred If chunk exists local target, transferred. If chunk exists remote target, removed. If chain version local chunk replica greater remote chunk replica, transferred. If chain versions localremote chunk replicas local committed version number equal remote pending version number, transferred. Otherwise, two chunk replicas either updated inprogress write requests. Chunks metadata File chunks stored chunk engine. On SSD, persistent storage chunk engine consists fixed number data files storing chunk data, RocksDB instance maintaining chunk metadata system information. Additionally, chunk engine maintains inmemory cache chunk metadata enhance query performance. A chunk allocator implemented fast allocation new chunks. The chunk engine interface provides threadsafe access following operations 1. openclose Initializes engine loading metadata RocksDB reconstructing chunk allocator states. 2. get Retrieves chunk metadata referencecounted handle hashmap cache, enabling concurrent access O1 average complexity. 3. update Implements copyonwrite COW semantics allocating new chunks modifying data. Old chunks remain readable handles released. 4. commit Commit updated chunk metadata RocksDB via write batches ensure atomic updates synchronously refresh chunk metadata cache. The chunk data ultimately stored physical blocks. Physical block sizes range 64KiB 64MiB increments powers two, totaling 11 distinct sizes. The allocator assign physical blocks whose sizes closely match actual chunk size. A resource pool constructed physical block size, pool containing 256 physical files. The usage status physical blocks maintained memory using bitmaps. When physical block reclaimed, bitmap flag set 0. The actual storage space block remains preserved prioritized subsequent allocations. When available physical blocks remain, fallocate used allocate contiguous large space physical files, creating 256 new physical blocks approach helps reduce disk fragmentation. When performing write operations chunk, allocator first assigns new physical block. The system reads existing chunk data buffer, applies update, writes updated buffer newly allocated block. An optimized process implemented appends, data directly added inplace end existing block. A new copy metadata constructed new blocks location existing chunk metadata. Subsequently, new chunk metadata statuses new old physical blocks atomically updated RocksDB. 1 httpselixir.bootlin.comlinuxv5.4.284sourcefsfusefile.cL1573"}, {"page_content": "source namehttpsmedium.comvisithkumarapperumadeepseekv3agamechangerinaihereswhyitmatters75591957ca07 author Visith Kumarapperuma Deepseek V3 A GameChanger A.I. Heres Why It Matters Currently, AI models Chinese startup Deepseek causing quite stir AI space. Their latest reasoning model, Deepseek r1, shows better equal performance competitors. But all, achieved fraction training inference cost. DeepSeeks AI Assistant overtook ChatGPT become downloaded free app U.S. App Store. This development led market concerns A.I. investments major U.S. tech companies. Impacting share prices tech firms including Nvidia. So made Deepseek big impact A.I. ? The significance Deepseek disruptor industry lies approach. Unlike companies pushed better hardware, Deepseek improved algorithms. Thus achieving better results software level. Note following details Deepseek V3 model. Deepseek said trained model using data centre 2,000 Nvidia H800 GPUs. Time duration 2 months cost final training run 5.5 million This 5.5M reflects rental cost GPU hours needed train DeepSeekV3. It include 1. The capital expenditure owning hardware. 2. Costs associated prior research, ablation studies, experiments alternative architecturesalgorithmsdata. Deepseek made training efficient 45 times efficient Use 8bit instead 32bit save memory. Compress key value indices eat lot VRAM got 93 compression ratios. Do multitoken prediction instead singletoken prediction doubled inference speeds The MOE model decomposes big model small models run consumergrade hardware. Summary Deepseek v3 efficient training frontier model 1. Model Architecture The model employs MixtureofExperts MoE architecture, 37B parameters fire token total 671B. This sparse activation significantly reduces compute requirements compared dense models. The model uses Multihead Latent Attention MLA. This compresses KeyValue cache, reducing memory usage enabling efficient training. 2. FP8 Mixed Precision Training They implemented FP8 mixed precision training framework. Which reduces memory usage accelerates training compared higher precision formats. Reduced memory footprint 50 compared traditional FP16FP32 formats. They use finegrained quantisation strategies increased accumulation precision maintain accuracy. 3. Load Balancing Strategy They pioneered auxiliary lossfree strategy load balancing MoE architecture. This improved performance without drawbacks traditional auxiliary loss methods. 4. Training Framework They developed custom training framework called HAILLM several optimisations DualPipe algorithm efficient pipeline parallelism. This reduces pipeline bubbles overlapping computation communication. Efficient crossnode alltoall communication kernels fully utilise network bandwidth. Careful memory optimisations avoid using costly tensor parallelism. Breakdown costs Deepseek v3 model Deepseeks flagship model v3 showcases architecture 671B parameter MOE Mixture Agents 37B active parameters per token Their success stems breakthrough engineering using MoE architecture, implementing FP8 mixed precision training, developing custom HAILLM framework. Deepseek excels reasoning math, surpassing GPT4 Claude 3.5 Sonnet. For writing coding tasks, Claude 3.5 Sonnet maintains slight lead. Deepseek pretrained model 14.8 trillion highquality data, taking 2,788,000 GPU hours Nvidia h800s cluster, costing around 6 million Llama 403b trained 11x that, taking 30,840,000 GPU hours, also 15 trillion tokens. So true claim 5.5 million, another marketing trick? 1. Underlying FLOP calculations Model Details Active Parameters 37B using FP8 precision FLOPs per token Using rule thumb 6 FLOPs per parameter per token. 37B6 222B FLOPs per token Total Training Tokens Approximately 14.8 trillion tokens Total FLOPs required 222 B FLOPstoken14.8 T tokens 3.310\u00b2\u2074 FLOPs GPU FLOP Capacity H800H100 An H100 roughly estimated deliver about. 3.95810\u00b9\u2075 FLOPs per second per standardised interval used comparative metric. Ideal Perfect Efficiency GPU hours. Dividing total required FLOPs perGPU capability gives 3.310\u00b2\u2074 3.95810\u00b9\u2075 8.3310\u2078 seconds0.4 million GPU hour Note This perfect efficiency scenario lower bound. Realworld training less efficient. 2. Adjusting RealWorld Inefficiencies Comparison Llama 3.1 Reference Model Llama 3.1 405B parameters, 15 T tokens reportedly required 30.84 M GPU hours practice. Recalculating FLOPs Llama 3.1 Using math 3.6410\u00b2\u2075 FLOPs required Scaling Efficiency Using ratio FLOPs needed DeepSeekV3 versus Llama 3.1. assuming similar inefficiencies. The estimate adjusts roughly 2.79M GPU hours DeepSeekV3 training. 3. DeepSeekV3 Reported Training Breakdown According DeepSeekV3 paper Pretraining Stage Per Trillion Tokens 180K H800 GPU hours Overall Pretraining Total 2,664K GPU hours This stage completed less two months using cluster 2,048 H800 GPUs. Context Length Extension Additional 119K GPU hours Posttraining An extra 5K GPU hours Total GPU Hours 2,664 K119 K5 K2.788M GPU hours 4. Cost Estimation Assumed GPU Rental Price 2 per GPU hour Total Rental Cost 2.788M GPU hours2hour5.576 million stated Deepseek paper During pretraining stage, training DeepSeekV3 trillion tokens requires 180K H800 GPU hours Consequently, pretraining stage completed less two months costs 2664K GPU hours. Combined 119K GPU hours context length extension 5K GPU hours posttraining, DeepSeekV3 costs 2.788M GPU hours full training. Assuming rental price H800 GPU 2 per GPU hour, total training costs amount 5.576M. 5. Summary Theoretical Perfect Efficiency Estimate 0.4 M GPU hours using idealised FLOP counts assuming perfect hardware utilisation0 Adjusted RealWorld Estimate via Llama 3.1 comparison 2.79 GPU hours DeepSeekV3 Reported Breakdown Pretraining 2,664K GPU hours Context Extension 119K GPU hours Posttraining 5K GPU hours Total 2.788 M GPU hours Cost 2 per GPU hour 5.576 million"}, {"page_content": "source namehttpsmedium.comjjjy213deepseekv3explainedfdac83ba280c author Ataka jeong 1. Introduction How could DeepSeekV3 model achieve incredible performance economical training open source model? In paper review, explore various features invented applied build DeepSeekV3 model. The way paper presents model may seem complicated people unfamiliar new conceptualization invented DeepSeek. However, core principle still resembles standard Transformer wellknown LLMs. It incredibly helpful general knowledge previously released large language models like LLaMA. I also add interpretation DeekSeek model story. Lets dive new features model architecture step step. 2. Model Architecture First all, investigate core architecture DeekSeekV3 model. The DeekSeekV3 model inherited parts model previous V2 model. These parts model elaborated V2 paper, worth noting principle V3 model built upon. While used structure ordinary transformer block like Llama, attention FeedForward Network sophisticated boost model performance. The overview Transformer block shown following diagram. The two main components MultiHead Latent AttentionMLA DeepSeekMoE. 2.1 MultiHead Latent AttentionMLA What MultiHead Latent AttentionMLA? You might noticed Latent additional word conventional attention module. MLA improved speed memory usage attention block compressing input vector. From data analysis perspective, data compressed lower dimension preserving information contains. One wellknown techniques Principal component analysis PCA, reduces dimension data maintains variance retain information. In latent diffusion model, input data compressed variational autoencoder reconstructed initial dimension. The MultiHead Latent AttentionMLA applied principle compress decompress input data. By storing compressed vector KV cache, DeepSeek model improve speed reducing data copying memory efficiency using smaller compressed vector. The weight matrix compression additionally required, human cannot compress manually, AI learn compression done. Applying RoPE compressed vector mathematically compatible, shown detail V2 paper, used decoupled RoPE. As illustrated figure above, RoPE applied query key, also query key without RoPE. The RoPEapplied query key concatenated respective nonRoPE counterparts. Finally, query key obtained normal transformer block, computation dotproduct attention different original one. But could reach point economical KV cache thanks lower dimension data. 2.2 DeekSeekMoE Secondly, note FeedForward Network unusual split lot experts, rather one large FFN. They called DeekSeekMoE. Like humans group, AI also needs specialized certain domain improve performance. Thus, mixture experts come play here. Each expert specialize certain domain, case, group tokens familiar with, instead coping entire range tokens alone. Dependent input sequencetokens, certain experts selected activated contribute make output. Shared experts generalist activated kind tokens. Then might interesting know algorithm select experts? We need assign vector expert determines range tokensdomain experts deal well. And give score expert check similar domain expert input token are. If score high, select expert let activated make output. Well, sounds quite simple. Lets see math behind it. e\u1d62 centroid vector. It learned training represents type input tokens expert specialized in. Each experts centroid vector encodes knowledge domain specializes in. u\u209c input vector FFN. The dot product u\u209c\u1d40 e\u1d62 quantifies similarity input vector u\u209c centroid domain expert e\u1d62, effectively measuring alignment input data experts specialized domain. So, s\u1d62 Sigmoidu\u209c\u1d40 e\u1d62 represents score ith expert, determining whether expert selected. By gating value g\u1d62, select K\u1d63 experts high score Topk algorithm. We add outputs selected experts shared experts, arrive final output. 2.3 MultiToken Prediction In standard transformer, model generates token time, new token fed back decoder input. Since way restricts efficiency speed convergence training, many researchers made effort come method generate multiple tokens time. DeepSeek improved conventional way MultiToken PredictionMTP. Instead previous parallel MTP, DeepSeek decided sequential MTP. They construct independent MTP modules, previous output Transformer block concatenated subsequent MTP module, illustrated following figure. As shown figure, structure MTP modules akin RNN model. But, unlike RNN, preserve hidden states nodes, MTP modules send output prediction subsequent module. Even though single Transformer block cannot generate multiple tokens, entire system MTP modules collectively enables multitoken prediction. As compares additional tokens per prediction, provides information weight updates training, leading efficient learning faster convergence. The model proactively learn prepare additional tokens. In actual training, DeepSeek opted generate one additional token, presumably due computational cost caused using many MTP modules. It necessitate compromise benefits MTP computational cost. During inference, MTP modules discarded, generating one token per prediction. 3. Infrastructure 3.1 DualPipe Since U.S. export great GPUs like NVIDIA H100 China, DeepSeek researchers devise innovative methods accelerate model training using weaker H800 GPUs. Since succeeded, NVIDIAs stock price briefly plunged, people believed highperformance GPUs would longer necessary training LLM. Because DeepSeek model trained 2048 H800 GPUs, communication GPUs accounts large portion training time. Therefore, enhanching networking GPUs play crucial role reduce training time. When use many GPUs simultaneously, GPUs wait certain amount time new data copied GPU. This waiting time, causes training inefficiencies, known bubble, minimize much possible. DeepSeek invented innovative method reduce bubble. During model training, data flows model forward backward processes. In forward process, data goes input layer output layer. On hand, backward process data moves output layer input later, updating weights based information minimize loss. Prior DeepSeek, researchers found backward process split two processes, backward input backward weight, order remove bubbles. The backward input computation gradient loss respect input data, whereas backward weight calculates gradient loss respect weight. The backward input must completed ahead backward weight, necessary compute backward weight. Mathematically, chain rule applied calculation backpropagation, backward input used calculation backward weight. In process, certain enormous number communications GPUs required. In order reduce number communication, DeepSeeks DualPipe combines forward process backward input initiating training data two devices opposite directions illustrated following figure. The batch 0 initial data, starts processing device 0 continues subsequent devices. In conventional training plan, device 7 remains idle, waiting batch 0 copied onto it. However, DualPipe makes device 7 start training batch data opposite direction. This allows us combine chunk continuously copy together devices reduce communication GPUs. With weaker H800 GPUs, couldnt improve speed GPUs, reduce communication GPUs accelerate training. 3.2 Mixed precision training Mixed precision training already prevalent technique LLM improve training memory efficiency maintaining model accuracy. In mixed precision training, critical task find parts model less significant model accuracy reduce precision parts. In DeepSeekV3 model, researchers found reduce precision parts model heavy computations executed, matrix multiplication. In contrast, preserved high precision matrix addition storing data, relatively lightweight computation. The mixed precision training DeepSeek shown following figure. While reducing precision method above, overflow underflow arise impediment. If numerical values quantized lower precision like FP8 format, values clipped certain representable range. While computation lower precision, values easily exceed range computation. Scaling values mitigate overflow underflow adjusting values lead proper representation limited range. But, static scaling, applies fixed scaling factor values, still cause overflow underflow many values. To cope issue, DeepSeek implemented FineGrained Quantization. In method, values grouped, group scaling factor. This approach allows group values suitable scaling factor, overflow underflow averted. Another issue quantization small errors accumulated become serious problem later. In order avoid lot values error summed errors accumulated, intermediate values copied high precision, number values reaches interval. It means values grouped, values stored high precision. Then, errors values arent accumulated large scale, small group values dont contribute large error. These two techniques prevent quantization error visualized following figure. 4. Reinforcement Learning After supervised finetuning, DeepSeek additionally implemented reinforcement learning. A reward model built trained reinforcement learning, gives feedback model determine direction learning. The rulebased reward modelRM modelbased reward modelRM employed. The rulebased RM applied questions specific rules, math problems LeetCode problems. In domains, specific rules used verify correctness answers questions logical reasoning involved. However, many questions, answer cannot verified specific rule. In cases rule provided, modelbased RM determines, whether answer matches groundtruth answer. Another innovative idea DeepSeek including chainofthought reward, whereas conventional models included final reward based answer. DeepSeekV3 model, V2 model did, adopted Group Relative POlicy Optimization GRPO. This GRPO algorithm maximizes following objective updating policy model \u03c0. Maximize objective updating weights model based reward. Advantage defined normalized reward. In LLM case, policy model \u03c0 model itself, \u03b8 weights model. q question output model. We interpret policy modelLLM outputs probability distribution tokens, policy \u03c0oq probability output given question q. Therefore, policy model LLM itself. If output right answer, reinforce probability model makes output o. So need maximize \u03c0oq multiplying advantagenormalized reward. If output correct, advantage reward positive value policy reinforced. Otherwise, negative \u03c0oq minimized. Plus, finetuned model initial base model want go far base model, might cause model forget basic language understanding important knowledge model learned pretraining finetuning. To implement safety concerns, GRPO algorithm used KL divergence epsilon parameter. The KL divergence measures difference current policy model reference policy modelinitial base model. So KL divergence term minimized maximized GRPO objective. And pick minimum original policy clipped policy 1\u03b5, 1\u03b5, model cannot deviate much 1. So, current policy cannot differ lot old policy, restricting effect reinforcement learning. This GRPO algorithm based rulebased modelbased reward model enhances model performance reasoning capability. 5. Conclusion DeepSeekV3 model offered great opportunity efficient training cheaper GPUs. It unclear performance exceeds OpenAI model, DeepSeek way economical train opensource model. AI researchers directly use DeekSeek models also implement innovative ideas designs model, new methods DeepSeek source code opened. Seemingly, DeepSeek researchers potential come advanced idea improve model performance efficient training process. In AI development, lower training cost almost always implies better model accuracy later on, data model easily scaled lower cost. I hope performance good AI model undermined censorship suppression Chinese government."}, {"page_content": "202502 OpenSource Week Were tiny team deepseekai pushing limits AGI exploration. Starting week , Feb 24, 2025 well opensource 5 repos one daily drop weve made grand claims, simply developers sharing smallbutsincere progress full transparency. These humble building blocks online service documented, deployed battletested production. No vaporware, sincere code moved tiny yet ambitious dream forward. Why? Because every line shared becomes collective momentum accelerates journey. Daily unlocks begin soon. No ivory towers pure garageenergy communitydriven innovation Stay tuned lets geek open together. Day 1 FlashMLA Efficient MLA Decoding Kernel Hopper GPUs Optimized variablelength sequences, battletested production FlashMLA GitHub Repo BF16 support Paged KV cache block size 64 Performance 3000 GBs memorybound BF16 580 TFLOPS computebound H800 Day 2 DeepEP Excited introduce DeepEP first opensource EP communication library MoE model training inference. DeepEP GitHub Repo Efficient optimized alltoall communication Both intranode internode support NVLink RDMA Highthroughput kernels training inference prefilling Lowlatency kernels inference decoding Native FP8 dispatch support Flexible GPU resource control computationcommunication overlapping Day 3 DeepGEMM Introducing DeepGEMM FP8 GEMM library supports dense MoE GEMMs, powering V3R1 training inference. DeepGEMM GitHub Repo Up 1350 FP8 TFLOPS Hopper GPUs No heavy dependency, clean tutorial Fully JustInTime compiled Core logic 300 lines yet outperforms experttuned kernels across matrix sizes Supports dense layout two MoE layouts Day 4 Optimized Parallelism Strategies DualPipe bidirectional pipeline parallelism algorithm computationcommunication overlap V3R1 training. GitHub Repo EPLB expertparallel load balancer V3R1. GitHub Repo Analyze computationcommunication overlap V3R1. GitHub Repo Day 5 3FS, Thruster All DeepSeek Data Access FireFlyer File System 3FS parallel file system utilizes full bandwidth modern SSDs RDMA networks. 6.6 TiBs aggregate read throughput 180node cluster 3.66 TiBmin throughput GraySort benchmark 25node cluster 40 GiBs peak throughput per client node KVCache lookup Disaggregated architecture strong consistency semantics Training data preprocessing, dataset loading, checkpoint savingreloading, embedding vector search KVCache lookups inference V3R1 3FS httpsgithub.comdeepseekai3FS Smallpond data processing framework 3FS httpsgithub.comdeepseekaismallpond Day 6 One More Thing DeepSeekV3R1 Inference System Overview Optimized throughput latency via Crossnode EPpowered batch scaling Computationcommunication overlap Load balancing Production data V3R1 online services 73.7k14.8k inputoutput tokens per second per H800 node Cost profit margin 545"}, {"page_content": "DeepSeekR1 Incentivizing Reasoning Capability LLMs via Reinforcement Learning DeepSeekAI researchdeepseek.com Abstract We introduce firstgeneration reasoning models, DeepSeekR1Zero DeepSeekR1. DeepSeekR1Zero, model trained via largescale reinforcement learning RL without super vised finetuning SFT preliminary step, demonstrates remarkable reasoning capabilities. Through RL, DeepSeekR1Zero naturally emerges numerous powerful intriguing reasoning behaviors. However, encounters challenges poor readability, language mixing. To address issues enhance reasoning performance, introduce DeepSeekR1, incorporates multistage training coldstart data RL. DeepSeek R1 achieves performance comparable OpenAIo11217 reasoning tasks. To support research community, opensource DeepSeekR1Zero, DeepSeekR1, six dense models 1.5B, 7B, 8B, 14B, 32B, 70B distilled DeepSeekR1 based Qwen Llama. AIME 2024 Pass1Codeforces PercentileGPQA Diamond Pass1MATH500 Pass1MMLU Pass1SWEbench Verified Resolved020406080100Accuracy Percentile 79.896.3 71.597.3 90.8 49.279.296.6 75.796.4 91.8 48.972.690.6 62.194.3 87.4 36.863.693.4 60.090.0 85.2 41.6 39.258.7 59.190.2 88.5 42.0DeepSeekR1 OpenAIo11217 DeepSeekR132B OpenAIo1mini DeepSeekV3 Figure 1Benchmark performance DeepSeekR1.arXiv2501.12948v1 cs.CL 22 Jan 2025Contents 1 Introduction 3 1.1 Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 1.2 Summary Evaluation Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 2 Approach 5 2.1 Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 2.2 DeepSeekR1Zero Reinforcement Learning Base Model . . . . . . . . . . 5 2.2.1 Reinforcement Learning Algorithm . . . . . . . . . . . . . . . . . . . . . . 5 2.2.2 Reward Modeling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 2.2.3 Training Template . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 2.2.4 Performance, Selfevolution Process Aha Moment DeepSeekR1Zero 6 2.3 DeepSeekR1 Reinforcement Learning Cold Start . . . . . . . . . . . . . . . 9 2.3.1 Cold Start . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9 2.3.2 Reasoningoriented Reinforcement Learning . . . . . . . . . . . . . . . . . 10 2.3.3 Rejection Sampling Supervised FineTuning . . . . . . . . . . . . . . . 10 2.3.4 Reinforcement Learning Scenarios . . . . . . . . . . . . . . . . . . . 11 2.4 Distillation Empower Small Models Reasoning Capability . . . . . . . . . . 11 3 Experiment 11 3.1 DeepSeekR1 Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13 3.2 Distilled Model Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14 4 Discussion 14 4.1 Distillation v.s. Reinforcement Learning . . . . . . . . . . . . . . . . . . . . . . . . 14 4.2 Unsuccessful Attempts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 5 Conclusion, Limitations, Future Work 16 A Contributions Acknowledgments 20 21. Introduction In recent years, Large Language Models LLMs undergoing rapid iteration evolution Anthropic, 2024 Google, 2024 OpenAI, 2024a, progressively diminishing gap towards Artificial General Intelligence AGI. Recently, posttraining emerged important component full training pipeline. It shown enhance accuracy reasoning tasks, align social values, adapt user preferences, requiring relatively minimal computational resources pretraining. In context reasoning capabilities, OpenAIs o1 OpenAI, 2024b series models first introduce inferencetime scaling increasing length Chainof Thought reasoning process. This approach achieved significant improvements various reasoning tasks, mathematics, coding, scientific reasoning. However, challenge effective testtime scaling remains open question research community. Several prior works explored various approaches, including processbased reward models Lightman et al., 2023 Uesato et al., 2022 Wang et al., 2023, reinforcement learning Kumar et al., 2024, search algorithms Monte Carlo Tree Search Beam Search Feng et al., 2024 Trinh et al., 2024 Xin et al., 2024. However, none methods achieved general reasoning performance comparable OpenAIs o1 series models. In paper, take first step toward improving language model reasoning capabilities using pure reinforcement learning RL. Our goal explore potential LLMs develop reasoning capabilities without supervised data, focusing selfevolution pure RL process. Specifically, use DeepSeekV3Base base model employ GRPO Shao et al., 2024 RL framework improve model performance reasoning. During training, DeepSeekR1Zero naturally emerged numerous powerful interesting reasoning behaviors. After thousands RL steps, DeepSeekR1Zero exhibits super performance reasoning benchmarks. For instance, pass1 score AIME 2024 increases 15.6 71.0, majority voting, score improves 86.7, matching performance OpenAIo10912. However, DeepSeekR1Zero encounters challenges poor readability, language mixing. To address issues enhance reasoning performance, introduce DeepSeekR1, incorporates small amount coldstart data multistage training pipeline. Specifically, begin collecting thousands coldstart data finetune DeepSeekV3Base model. Following this, perform reasoningoriented RL like DeepSeekR1 Zero. Upon nearing convergence RL process, create new SFT data rejection sampling RL checkpoint, combined supervised data DeepSeekV3 domains writing, factual QA, selfcognition, retrain DeepSeekV3Base model. After finetuning new data, checkpoint undergoes additional RL process, taking account prompts scenarios. After steps, obtained checkpoint referred DeepSeekR1, achieves performance par OpenAIo11217. We explore distillation DeepSeekR1 smaller dense models. Using Qwen2.5 32B Qwen, 2024b base model, direct distillation DeepSeekR1 outperforms applying RL it. This demonstrates reasoning patterns discovered larger base models cru cial improving reasoning capabilities. We opensource distilled Qwen Llama Dubey et al., 2024 series. Notably, distilled 14B model outperforms stateoftheart opensource QwQ32BPreview Qwen, 2024a large margin, distilled 32B 70B models set new record reasoning benchmarks among dense models. 31.1. Contributions PostTraining LargeScale Reinforcement Learning Base Model We directly apply RL base model without relying supervised finetuning SFT preliminary step. This approach allows model explore chainofthought CoT solving complex problems, resulting development DeepSeekR1Zero. DeepSeek R1Zero demonstrates capabilities selfverification, reflection, generating long CoTs, marking significant milestone research community. Notably, first open research validate reasoning capabilities LLMs incentivized purely RL, without need SFT. This breakthrough paves way future advancements area. We introduce pipeline develop DeepSeekR1. The pipeline incorporates two RL stages aimed discovering improved reasoning patterns aligning human pref erences, well two SFT stages serve seed models reasoning nonreasoning capabilities. We believe pipeline benefit industry creating better models. Distillation Smaller Models Can Be Powerful Too We demonstrate reasoning patterns larger models distilled smaller models, resulting better performance compared reasoning patterns discovered RL small models. The open source DeepSeekR1, well API, benefit research community distill better smaller models future. Using reasoning data generated DeepSeekR1, finetuned several dense models widely used research community. The evaluation results demonstrate distilled smaller dense models perform exceptionally well benchmarks. DeepSeek R1DistillQwen7B achieves 55.5 AIME 2024, surpassing QwQ32BPreview. Addi tionally, DeepSeekR1DistillQwen32B scores 72.6 AIME 2024, 94.3 MATH500, 57.2 LiveCodeBench. These results significantly outperform previous open source models comparable o1mini. We opensource distilled 1.5B, 7B, 8B, 14B, 32B, 70B checkpoints based Qwen2.5 Llama3 series community. 1.2. Summary Evaluation Results Reasoning tasks 1 DeepSeekR1 achieves score 79.8 Pass1 AIME 2024, slightly surpassing OpenAIo11217. On MATH500, attains impressive score 97.3, performing par OpenAIo11217 significantly outperforming models. 2 On codingrelated tasks, DeepSeekR1 demonstrates expert level code competition tasks, achieves 2,029 Elo rating Codeforces outperforming 96.3 human participants competition. For engineeringrelated tasks, DeepSeekR1 performs slightly better DeepSeekV3, could help developers real world tasks. Knowledge On benchmarks MMLU, MMLUPro, GPQA Diamond, DeepSeek R1 achieves outstanding results, significantly outperforming DeepSeekV3 scores 90.8 MMLU, 84.0 MMLUPro, 71.5 GPQA Diamond. While performance slightly OpenAIo11217 benchmarks, DeepSeekR1 surpasses closedsource models, demonstrating competitive edge educational tasks. On factual benchmark SimpleQA, DeepSeekR1 outperforms DeepSeekV3, demonstrating capability handling factbased queries. A similar trend observed OpenAIo1 surpasses 4o benchmark. 4Others DeepSeekR1 also excels wide range tasks, including creative writing, general question answering, editing, summarization, more. It achieves impressive lengthcontrolled winrate 87.6 AlpacaEval 2.0 winrate 92.3 Are naHard, showcasing strong ability intelligently handle nonexamoriented queries. Additionally, DeepSeekR1 demonstrates outstanding performance tasks requiring longcontext understanding, substantially outperforming DeepSeekV3 longcontext benchmarks. 2. Approach 2.1. Overview Previous work heavily relied large amounts supervised data enhance model performance. In study, demonstrate reasoning capabilities significantly improved largescale reinforcement learning RL, even without using supervised finetuning SFT cold start. Furthermore, performance enhanced inclusion small amount coldstart data. In following sections, present 1 DeepSeekR1Zero, applies RL directly base model without SFT data, 2 DeepSeekR1, applies RL starting checkpoint finetuned thousands long ChainofThought CoT examples. 3 Distill reasoning capability DeepSeekR1 small dense models. 2.2. DeepSeekR1Zero Reinforcement Learning Base Model Reinforcement learning demonstrated significant effectiveness reasoning tasks, ev idenced previous works Shao et al., 2024 Wang et al., 2023. However, works heavily depended supervised data, timeintensive gather. In section, explore potential LLMs develop reasoning capabilities without supervised data , focusing selfevolution pure reinforcement learning process. We start brief overview RL algorithm, followed presentation exciting results, hope provides community valuable insights. 2.2.1. Reinforcement Learning Algorithm Group Relative Policy Optimization In order save training costs RL, adopt Group Relative Policy Optimization GRPO Shao et al., 2024, foregoes critic model typically size policy model, estimates baseline group scores instead. Specifically, question \ud835\udc5e, GRPO samples group outputs \ud835\udc5c1,\ud835\udc5c2,,\ud835\udc5c\ud835\udc3afrom old policy\ud835\udf0b\ud835\udf03\ud835\udc5c\ud835\udc59\ud835\udc51and optimizes policy model \ud835\udf0b\ud835\udf03by maximizing following objective J\ud835\udc3a\ud835\udc45\ud835\udc43\ud835\udc42\ud835\udf03E\ud835\udc5e\ud835\udc43\ud835\udc44,\ud835\udc5c\ud835\udc56\ud835\udc3a \ud835\udc561\ud835\udf0b\ud835\udf03\ud835\udc5c\ud835\udc59\ud835\udc51\ud835\udc42\ud835\udc5e 1 \ud835\udc3a\ud835\udc3a \ud835\udc561 min\ud835\udf0b\ud835\udf03\ud835\udc5c\ud835\udc56\ud835\udc5e \ud835\udf0b\ud835\udf03\ud835\udc5c\ud835\udc59\ud835\udc51\ud835\udc5c\ud835\udc56\ud835\udc5e\ud835\udc34\ud835\udc56, clip\ud835\udf0b\ud835\udf03\ud835\udc5c\ud835\udc56\ud835\udc5e \ud835\udf0b\ud835\udf03\ud835\udc5c\ud835\udc59\ud835\udc51\ud835\udc5c\ud835\udc56\ud835\udc5e, 1\ud835\udf00, 1\ud835\udf00 \ud835\udc34\ud835\udc56 \ud835\udefdD\ud835\udc3e\ud835\udc3f \ud835\udf0b\ud835\udf03\ud835\udf0b\ud835\udc5f\ud835\udc52\ud835\udc53 ,1 D\ud835\udc3e\ud835\udc3f \ud835\udf0b\ud835\udf03\ud835\udf0b\ud835\udc5f\ud835\udc52\ud835\udc53\ud835\udf0b\ud835\udc5f\ud835\udc52\ud835\udc53\ud835\udc5c\ud835\udc56\ud835\udc5e \ud835\udf0b\ud835\udf03\ud835\udc5c\ud835\udc56\ud835\udc5elog\ud835\udf0b\ud835\udc5f\ud835\udc52\ud835\udc53\ud835\udc5c\ud835\udc56\ud835\udc5e \ud835\udf0b\ud835\udf03\ud835\udc5c\ud835\udc56\ud835\udc5e1, 2 where\ud835\udf00and\ud835\udefdare hyperparameters, \ud835\udc34\ud835\udc56is advantage, computed using group rewards\ud835\udc5f1,\ud835\udc5f2,...,\ud835\udc5f\ud835\udc3acorresponding outputs within group \ud835\udc34\ud835\udc56\ud835\udc5f\ud835\udc56m\ud835\udc52\ud835\udc4e\ud835\udc5b\ud835\udc5f1,\ud835\udc5f2,,\ud835\udc5f\ud835\udc3a s\ud835\udc61\ud835\udc51\ud835\udc5f1,\ud835\udc5f2,,\ud835\udc5f\ud835\udc3a. 3 5A conversation User Assistant. The user asks question, Assistant solves it. The assistant first thinks reasoning process mind provides user answer. The reasoning process answer enclosed within think think answer answer tags, respectively, i.e., think reasoning process think answer answer answer. User prompt. Assistant Table 1Template DeepSeekR1Zero. prompt replaced specific reasoning question training. 2.2.2. Reward Modeling The reward source training signal, decides optimization direction RL. To train DeepSeekR1Zero, adopt rulebased reward system mainly consists two types rewards Accuracy rewards The accuracy reward model evaluates whether response correct. For example, case math problems deterministic results, model required provide final answer specified format e.g., within box, enabling reliable rulebased verification correctness. Similarly, LeetCode problems, compiler used generate feedback based predefined test cases. Format rewards In addition accuracy reward model, employ format reward model enforces model put thinking process think think tags. We apply outcome process neural reward model developing DeepSeekR1Zero, find neural reward model may suffer reward hacking largescale reinforcement learning process, retraining reward model needs additional training resources complicates whole training pipeline. 2.2.3. Training Template To train DeepSeekR1Zero, begin designing straightforward template guides base model adhere specified instructions. As depicted Table 1, template requires DeepSeekR1Zero first produce reasoning process, followed final answer. We intentionally limit constraints structural format, avoiding contentspecific biasessuch mandating reflective reasoning promoting particular problemsolving strate giesto ensure accurately observe models natural progression RL process. 2.2.4. Performance, Selfevolution Process Aha Moment DeepSeekR1Zero Performance DeepSeekR1Zero Figure 2 depicts performance trajectory DeepSeek R1Zero AIME 2024 benchmark throughout RL training process. As illustrated, DeepSeekR1Zero demonstrates steady consistent enhancement performance RL training advances. Notably, average pass1 score AIME 2024 shows significant increase, jumping initial 15.6 impressive 71.0, reaching performance levels comparable OpenAIo10912. This significant improvement highlights efficacy RL algorithm optimizing models performance time. Table 2 provides comparative analysis DeepSeekR1Zero OpenAIs o10912 models across variety reasoningrelated benchmarks. The findings reveal RL empowers 6ModelAIME 2024 MATH500GPQA LiveCodeCodeForcesDiamond Bench pass1 cons64 pass1 pass1 pass1 rating OpenAIo1mini 63.6 80.0 90.0 60.0 53.8 1820 OpenAIo10912 74.4 83.3 94.8 77.3 63.4 1843 DeepSeekR1Zero 71.0 86.7 95.9 73.3 50.0 1444 Table 2Comparison DeepSeekR1Zero OpenAI o1 models reasoningrelated benchmarks. Figure 2AIME accuracy DeepSeekR1Zero training. For question, sample 16 responses calculate overall average accuracy ensure stable evaluation. DeepSeekR1Zero attain robust reasoning capabilities without need supervised finetuning data. This noteworthy achievement, underscores models ability learn generalize effectively RL alone. Additionally, performance DeepSeek R1Zero augmented application majority voting. For example, majority voting employed AIME benchmark, DeepSeekR1Zeros performance escalates 71.0 86.7, thereby exceeding performance OpenAIo10912. The ability DeepSeekR1Zero achieve competitive performance, without majority voting, highlights strong foundational capabilities potential advancements reasoning tasks. Selfevolution Process DeepSeekR1Zero The selfevolution process DeepSeekR1Zero fascinating demonstration RL drive model improve reasoning capabilities autonomously. By initiating RL directly base model, closely monitor models progression without influence supervised finetuning stage. This approach provides clear view model evolves time, particularly terms ability handle complex reasoning tasks. As depicted Figure 3, thinking time DeepSeekR1Zero shows consistent improve 7Figure 3The average response length DeepSeekR1Zero training set RL process. DeepSeekR1Zero naturally learns solve reasoning tasks thinking time. ment throughout training process. This improvement result external adjustments rather intrinsic development within model. DeepSeekR1Zero naturally acquires ability solve increasingly complex reasoning tasks leveraging extended testtime compu tation. This computation ranges generating hundreds thousands reasoning tokens, allowing model explore refine thought processes greater depth. One remarkable aspects selfevolution emergence sophisticated behaviors testtime computation increases. Behaviors reflectionwhere model revisits reevaluates previous stepsand exploration alternative approaches problemsolving arise spontaneously. These behaviors explicitly programmed instead emerge result models interaction reinforcement learning environment. This spontaneous development significantly enhances DeepSeekR1Zeros reasoning capabilities, enabling tackle challenging tasks greater efficiency accuracy. Aha Moment DeepSeekR1Zero A particularly intriguing phenomenon observed training DeepSeekR1Zero occurrence aha moment. This moment, illustrated Table 3, occurs intermediate version model. During phase, DeepSeekR1Zero learns allocate thinking time problem reevaluating initial approach. This behavior testament models growing reasoning abilities also captivating example reinforcement learning lead unexpected sophisticated outcomes. This moment aha moment model also researchers observing behavior. It underscores power beauty reinforcement learning rather explicitly teaching model solve problem, simply provide right incentives, autonomously develops advanced problemsolving strategies. The aha moment serves powerful reminder potential RL unlock new levels intelligence artificial systems, paving way autonomous adaptive models future. 8Question If \ud835\udc4e 1, sum real solutions \ud835\udc4e \ud835\udc4e\ud835\udc65\ud835\udc65is equal Response think To solve equation \ud835\udc4e \ud835\udc4e\ud835\udc65\ud835\udc65, lets start squaring \ud835\udc4e \ud835\udc4e\ud835\udc652 \ud835\udc652\ud835\udc4e \ud835\udc4e\ud835\udc65\ud835\udc652. Rearrange isolate inner square root term \ud835\udc4e\ud835\udc6522\ud835\udc4e\ud835\udc65\ud835\udc4e22\ud835\udc4e\ud835\udc652\ud835\udc6522\ud835\udc4e\ud835\udc65\ud835\udc6542\ud835\udc4e\ud835\udc652\ud835\udc65\ud835\udc4e2\ud835\udc4e0 . . . Wait, wait. Wait. Thats aha moment I flag here. Lets reevaluate stepbystep identify correct sum We started equation \ud835\udc4e \ud835\udc4e\ud835\udc65\ud835\udc65 First, lets square sides \ud835\udc4e \ud835\udc4e\ud835\udc65\ud835\udc652 \ud835\udc4e\ud835\udc65\ud835\udc4e\ud835\udc652 Next, I could square sides again, treating equation . . . Table 3An interesting aha moment intermediate version DeepSeekR1Zero. The model learns rethink using anthropomorphic tone. This also aha moment us, allowing us witness power beauty reinforcement learning. Drawback DeepSeekR1Zero Although DeepSeekR1Zero exhibits strong reasoning capabilities autonomously develops unexpected powerful reasoning behaviors, faces several issues. For instance, DeepSeekR1Zero struggles challenges like poor readability, language mixing. To make reasoning processes readable share open community, explore DeepSeekR1, method utilizes RL humanfriendly coldstart data. 2.3. DeepSeekR1 Reinforcement Learning Cold Start Inspired promising results DeepSeekR1Zero, two natural questions arise 1 Can reasoning performance improved convergence accelerated incorporating small amount highquality data cold start? 2 How train userfriendly model produces clear coherent Chains Thought CoT also demonstrates strong general capabilities? To address questions, design pipeline train DeepSeekR1. The pipeline consists four stages, outlined follows. 2.3.1. Cold Start Unlike DeepSeekR1Zero, prevent early unstable cold start phase RL training base model, DeepSeekR1 construct collect small amount long CoT data finetune model initial RL actor. To collect data, explored several approaches using fewshot prompting long CoT example, directly prompting models generate detailed answers reflection verification, gathering DeepSeekR1 Zero outputs readable format, refining results postprocessing human annotators. In work, collect thousands coldstart data finetune DeepSeekV3Base starting point RL. Compared DeepSeekR1Zero, advantages cold start data 9include Readability A key limitation DeepSeekR1Zero content often suitable reading. Responses may mix multiple languages lack markdown formatting highlight answers users. In contrast, creating coldstart data DeepSeekR1, design readable pattern includes summary end response filters responses readerfriendly. Here, define output format special_tokenreasoning_processspecial_tokensummary, reasoning process CoT query, summary used summarize reasoning results. Potential By carefully designing pattern coldstart data human priors, observe better performance DeepSeekR1Zero. We believe iterative training better way reasoning models. 2.3.2. Reasoningoriented Reinforcement Learning After finetuning DeepSeekV3Base cold start data, apply largescale reinforcement learning training process employed DeepSeekR1Zero. This phase focuses enhancing models reasoning capabilities, particularly reasoningintensive tasks coding, mathematics, science, logic reasoning, involve welldefined problems clear solutions. During training process, observe CoT often exhibits language mixing, particularly RL prompts involve multiple languages. To mitigate issue language mixing, introduce language consistency reward RL training, calculated proportion target language words CoT. Although ablation experiments show alignment results slight degradation models performance, reward aligns human preferences, making readable. Finally, combine accuracy reasoning tasks reward language consistency directly summing form final reward. We apply RL training finetuned model achieves convergence reasoning tasks. 2.3.3. Rejection Sampling Supervised FineTuning When reasoningoriented RL converges, utilize resulting checkpoint collect SFT Supervised FineTuning data subsequent round. Unlike initial coldstart data, primarily focuses reasoning, stage incorporates data domains enhance models capabilities writing, roleplaying, generalpurpose tasks. Specifically, generate data finetune model described below. Reasoning data We curate reasoning prompts generate reasoning trajectories perform ing rejection sampling checkpoint RL training. In previous stage, included data could evaluated using rulebased rewards. However, stage, expand dataset incorporating additional data, use generative reward model feeding groundtruth model predictions DeepSeekV3 judgment. Additionally, model output sometimes chaotic difficult read, filtered chainofthought mixed languages, long parapraphs, code blocks. For prompt, sample multiple responses retain correct ones. In total, collect 600k reasoning related training samples. 10NonReasoning data For nonreasoning data, writing, factual QA, selfcognition, translation, adopt DeepSeekV3 pipeline reuse portions SFT dataset DeepSeekV3. For certain nonreasoning tasks, call DeepSeekV3 generate potential chainofthought answering question prompting. However, simpler queries, hello provide CoT response. In end, collected total approximately 200k training samples unrelated reasoning. We finetune DeepSeekV3Base two epochs using curated dataset 800k samples. 2.3.4. Reinforcement Learning Scenarios To align model human preferences, implement secondary reinforcement learning stage aimed improving models helpfulness harmlessness simultane ously refining reasoning capabilities. Specifically, train model using combination reward signals diverse prompt distributions. For reasoning data, adhere methodology outlined DeepSeekR1Zero, utilizes rulebased rewards guide learning process math, code, logical reasoning domains. For general data, resort reward models capture human preferences complex nuanced scenarios. We build upon DeepSeekV3 pipeline adopt similar distribution preference pairs train ing prompts. For helpfulness, focus exclusively final summary, ensuring assessment emphasizes utility relevance response user minimizing interference underlying reasoning process. For harmlessness, evaluate entire response model, including reasoning process summary, identify mitigate potential risks, biases, harmful content may arise generation process. Ultimately, integration reward signals diverse data distributions enables us train model excels reasoning prioritizing helpfulness harmlessness. 2.4. Distillation Empower Small Models Reasoning Capability To equip efficient smaller models reasoning capabilities like DeepSeekR1, directly finetuned opensource models like Qwen Qwen, 2024b Llama AIMeta, 2024 using 800k samples curated DeepSeekR1, detailed 2.3.3. Our findings indicate straightforward distillation method significantly enhances reasoning abilities smaller models. The base models use Qwen2.5Math1.5B, Qwen2.5Math7B, Qwen2.5 14B, Qwen2.532B, Llama3.18B, Llama3.370BInstruct. We select Llama3.3 reasoning capability slightly better Llama3.1. For distilled models, apply SFT include RL stage, even though incorporating RL could substantially boost model performance. Our primary goal demonstrate effectiveness distillation technique, leaving exploration RL stage broader research community. 3. Experiment Benchmarks We evaluate models MMLU Hendrycks et al., 2020, MMLURedux Gema et al., 2024, MMLUPro Wang et al., 2024, CEval Huang et al., 2023, CMMLU Li et al., 2023, IFEval Zhou et al., 2023, FRAMES Krishna et al., 2024, GPQA Diamond Rein et al., 2023, SimpleQA OpenAI, 2024c, CSimpleQA He et al., 2024, SWEBench Verified OpenAI, 112024d, Aider1, LiveCodeBench Jain et al., 2024 202408 202501, Codeforces2, Chinese National High School Mathematics Olympiad CNMO 20243, American Invitational Math ematics Examination 2024 AIME 2024 MAA, 2024. In addition standard benchmarks, also evaluate models openended generation tasks using LLMs judges. Specifically, adhere original configurations AlpacaEval 2.0 Dubois et al., 2024 ArenaHard Li et al., 2024, leverage GPT4Turbo1106 judges pairwise comparisons. Here, feed final summary evaluation avoid length bias. For distilled models, report representative results AIME 2024, MATH500, GPQA Diamond, Codeforces, LiveCodeBench. Evaluation Prompts Following setup DeepSeekV3, standard benchmarks MMLU, DROP , GPQA Diamond, SimpleQA evaluated using prompts simple evals framework. For MMLURedux, adopt ZeroEval prompt format Lin, 2024 zeroshot setting. In terms MMLUPro, CEval CLUEWSC, since original prompts fewshot, slightly modify prompt zeroshot setting. The CoT fewshot may hurt performance DeepSeekR1. Other datasets follow original evaluation protocols default prompts provided creators. For code math benchmarks, HumanEvalMul dataset covers eight mainstream programming languages Python, Java, C, C, JavaScript, TypeScript, PHP , Bash. Model performance LiveCodeBench evaluated using CoT format, data collected August 2024 January 2025. The Codeforces dataset evaluated using problems 10 Div.2 contests along expertcrafted test cases, expected ratings percentages competitors calculated. SWEBench verified results obtained via agentless framework Xia et al., 2024. AIDERrelated benchmarks measured using diff format. DeepSeekR1 outputs capped maximum 32,768 tokens benchmark. Baselines We conduct comprehensive evaluations several strong baselines, including DeepSeekV3, ClaudeSonnet3.51022, GPT4o0513, OpenAIo1mini, OpenAIo11217. Since accessing OpenAIo11217 API challenging mainland China, report perfor mance based official reports. For distilled models, also compare opensource model QwQ32BPreview Qwen, 2024a. Evaluation Setup We set maximum generation length 32,768 tokens models. We found using greedy decoding evaluate longoutput reasoning models results higher repetition rates significant variability across different checkpoints. Therefore, default pass \ud835\udc58evaluation Chen et al., 2021 report pass1 using nonzero temperature. Specifically, use sampling temperature 0.6and top \ud835\udc5dvalue 0.95 generate \ud835\udc58 responses typically 4and 64, depending test set size question. Pass1 calculated pass1 1 \ud835\udc58\ud835\udc58 \ud835\udc561\ud835\udc5d\ud835\udc56, where\ud835\udc5d\ud835\udc56denotes correctness \ud835\udc56th response. This method provides reliable performance estimates. For AIME 2024, also report consensus majority vote results Wang et al., 2022 using 64 samples, denoted cons64. 1httpsaider.chat 2httpscodeforces.com 3httpswww.cms.org.cnHomecompcompcid12.html 123.1. DeepSeekR1 Evaluation Benchmark MetricClaude3.5 GPT4o DeepSeek OpenAI OpenAI DeepSeek Sonnet1022 0513 V3 o1mini o11217 R1 Architecture MoE MoE Activated Params 37B 37B Total Params 671B 671B EnglishMMLU Pass1 88.3 87.2 88.5 85.2 91.8 90.8 MMLURedux EM 88.9 88.0 89.1 86.7 92.9 MMLUPro EM 78.0 72.6 75.9 80.3 84.0 DROP 3shot F1 88.3 83.7 91.6 83.9 90.2 92.2 IFEval Prompt Strict 86.5 84.3 86.1 84.8 83.3 GPQA Diamond Pass1 65.0 49.9 59.1 60.0 75.7 71.5 SimpleQA Correct 28.4 38.2 24.9 7.0 47.0 30.1 FRAMES Acc. 72.5 80.5 73.3 76.9 82.5 AlpacaEval2.0 LCwinrate 52.0 51.1 70.0 57.8 87.6 ArenaHard GPT41106 85.2 80.4 85.5 92.0 92.3 CodeLiveCodeBench Pass1COT 38.9 32.9 36.2 53.8 63.4 65.9 Codeforces Percentile 20.3 23.6 58.7 93.4 96.6 96.3 Codeforces Rating 717 759 1134 1820 2061 2029 SWE Verified Resolved 50.8 38.8 42.0 41.6 48.9 49.2 AiderPolyglot Acc. 45.3 16.0 49.6 32.9 61.7 53.3 MathAIME 2024 Pass1 16.0 9.3 39.2 63.6 79.2 79.8 MATH500 Pass1 78.3 74.6 90.2 90.0 96.4 97.3 CNMO 2024 Pass1 13.1 10.8 43.2 67.6 78.8 ChineseCLUEWSC EM 85.4 87.9 90.9 89.9 92.8 CEval EM 76.7 76.0 86.5 68.9 91.8 CSimpleQA Correct 55.4 58.7 68.0 40.3 63.7 Table 4Comparison DeepSeekR1 representative models. For educationoriented knowledge benchmarks MMLU, MMLUPro, GPQA Diamond, DeepSeekR1 demonstrates superior performance compared DeepSeekV3. This im provement primarily attributed enhanced accuracy STEMrelated questions, signif icant gains achieved largescale reinforcement learning. Additionally, DeepSeekR1 excels FRAMES, longcontextdependent QA task, showcasing strong document analysis capabilities. This highlights potential reasoning models AIdriven search data analysis tasks. On factual benchmark SimpleQA, DeepSeekR1 outperforms DeepSeekV3, demonstrating capability handling factbased queries. A similar trend observed OpenAIo1 surpasses GPT4o benchmark. However, DeepSeekR1 performs worse DeepSeekV3 Chinese SimpleQA benchmark, primarily due tendency refuse answering certain queries safety RL. Without safety RL, DeepSeekR1 could achieve accuracy 70. DeepSeekR1 also delivers impressive results IFEval, benchmark designed assess models ability follow format instructions. These improvements linked inclusion instructionfollowing data final stages supervised finetuning SFT RL training. Furthermore, remarkable performance observed AlpacaEval2.0 ArenaHard, indicating DeepSeekR1s strengths writing tasks opendomain question answering. Its significant outperformance DeepSeekV3 underscores generalization benefits largescale RL, boosts reasoning capabilities also improves performance across diverse domains. Moreover, summary lengths generated DeepSeekR1 concise, average 689 tokens ArenaHard 2,218 characters AlpacaEval 2.0. This indicates 13DeepSeekR1 avoids introducing length bias GPTbased evaluations, solidifying robustness across multiple tasks. On math tasks, DeepSeekR1 demonstrates performance par OpenAIo11217, surpassing models large margin. A similar trend observed coding algorithm tasks, LiveCodeBench Codeforces, reasoningfocused models dominate benchmarks. On engineeringoriented coding tasks, OpenAIo11217 outperforms DeepSeekR1 Aider achieves comparable performance SWE Verified. We believe engineering performance DeepSeekR1 improve next version, amount related RL training data currently remains limited. 3.2. Distilled Model Evaluation ModelAIME 2024 MATH500GPQA LiveCodeCodeForcesDiamond Bench pass1 cons64 pass1 pass1 pass1 rating GPT4o0513 9.3 13.4 74.6 49.9 32.9 759 Claude3.5Sonnet1022 16.0 26.7 78.3 65.0 38.9 717 OpenAIo1mini 63.6 80.0 90.0 60.0 53.8 1820 QwQ32BPreview 50.0 60.0 90.6 54.5 41.9 1316 DeepSeekR1DistillQwen1.5B 28.9 52.7 83.9 33.8 16.9 954 DeepSeekR1DistillQwen7B 55.5 83.3 92.8 49.1 37.6 1189 DeepSeekR1DistillQwen14B 69.7 80.0 93.9 59.1 53.1 1481 DeepSeekR1DistillQwen32B 72.6 83.3 94.3 62.1 57.2 1691 DeepSeekR1DistillLlama8B 50.4 80.0 89.1 49.0 39.6 1205 DeepSeekR1DistillLlama70B 70.0 86.7 94.5 65.2 57.5 1633 Table 5Comparison DeepSeekR1 distilled models comparable models reasoningrelated benchmarks. As shown Table 5, simply distilling DeepSeekR1s outputs enables efficient DeepSeek R17B i.e., DeepSeekR1DistillQwen7B, abbreviated similarly outperform non reasoning models like GPT4o0513 across board. DeepSeekR114B surpasses QwQ32B Preview evaluation metrics, DeepSeekR132B DeepSeekR170B significantly exceed o1mini benchmarks. These results demonstrate strong potential distilla tion. Additionally, found applying RL distilled models yields significant gains. We believe warrants exploration therefore present results simple SFTdistilled models here. 4. Discussion 4.1. Distillation v.s. Reinforcement Learning In Section 3.2, see distilling DeepSeekR1, small model achieve impressive results. However, still one question left model achieve comparable performance largescale RL training discussed paper without distillation? To answer question, conduct largescale RL training Qwen32BBase using math, code, STEM data, training 10K steps, resulting DeepSeekR1ZeroQwen32B. The experimental results, shown Table 6, demonstrate 32B base model, largescale 14ModelAIME 2024 MATH500 GPQA Diamond LiveCodeBench pass1 cons64 pass1 pass1 pass1 QwQ32BPreview 50.0 60.0 90.6 54.5 41.9 DeepSeekR1ZeroQwen32B 47.0 60.0 91.6 55.0 40.2 DeepSeekR1DistillQwen32B 72.6 83.3 94.3 62.1 57.2 Table 6Comparison distilled RL Models ReasoningRelated Benchmarks. RL training, achieves performance par QwQ32BPreview. However, DeepSeekR1 DistillQwen32B, distilled DeepSeekR1, performs significantly better DeepSeekR1ZeroQwen32B across benchmarks. Therefore, draw two conclusions First, distilling powerful models smaller ones yields excellent results, whereas smaller models relying largescale RL mentioned paper require enormous computational power may even achieve performance distillation. Second, distillation strategies economical effective, advancing beyond boundaries intelligence may still require powerful base models larger scale reinforcement learning. 4.2. Unsuccessful Attempts In early stages developing DeepSeekR1, also encountered failures setbacks along way. We share failure experiences provide insights, imply approaches incapable developing effective reasoning models. Process Reward Model PRM PRM reasonable method guide model toward better approaches solving reasoning tasks Lightman et al., 2023 Uesato et al., 2022 Wang et al., 2023. However, practice, PRM three main limitations may hinder ultimate suc cess. First, challenging explicitly define finegrain step general reasoning. Second, determining whether current intermediate step correct challenging task. Automated annotation using models may yield satisfactory results, manual annotation con ducive scaling up. Third, modelbased PRM introduced, inevitably leads reward hacking Gao et al., 2022, retraining reward model needs additional training resources complicates whole training pipeline. In conclusion, PRM demonstrates good ability rerank topN responses generated model assist guided search Snell et al., 2024, advantages limited compared additional computational overhead introduces largescale reinforcement learning process experiments. Monte Carlo Tree Search MCTS Inspired AlphaGo Silver et al., 2017b AlphaZero Sil ver et al., 2017a, explored using Monte Carlo Tree Search MCTS enhance testtime compute scalability. This approach involves breaking answers smaller parts allow model explore solution space systematically. To facilitate this, prompt model generate multiple tags correspond specific reasoning steps necessary search. For training, first use collected prompts find answers via MCTS guided pretrained value model. Subsequently, use resulting questionanswer pairs train actor model value model, iteratively refining process. However, approach encounters several challenges scaling training. First, unlike chess, search space relatively welldefined, token generation presents 15exponentially larger search space. To address this, set maximum extension limit node, lead model getting stuck local optima. Second, value model directly influences quality generation since guides step search process. Training finegrained value model inherently difficult, makes challenging model iteratively improve. While AlphaGos core success relied training value model progressively enhance performance, principle proves difficult replicate setup due complexities token generation. In conclusion, MCTS improve performance inference paired pretrained value model, iteratively boosting model performance selfsearch remains significant challenge. 5. Conclusion, Limitations, Future Work In work, share journey enhancing model reasoning abilities reinforcement learning. DeepSeekR1Zero represents pure RL approach without relying coldstart data, achieving strong performance across various tasks. DeepSeekR1 powerful, leveraging coldstart data alongside iterative RL finetuning. Ultimately, DeepSeekR1 achieves performance comparable OpenAIo11217 range tasks. We explore distillation reasoning capability small dense models. We use DeepSeekR1 teacher model generate 800K training samples, finetune several small dense models. The results promising DeepSeekR1DistillQwen1.5B outperforms GPT4o Claude3.5Sonnet math benchmarks 28.9 AIME 83.9 MATH. Other dense models also achieve impressive results, significantly outperforming instruction tuned models based underlying checkpoints. In future, plan invest research across following directions DeepSeekR1. General Capability Currently, capabilities DeepSeekR1 fall short DeepSeekV3 tasks function calling, multiturn, complex roleplaying, JSON output. Moving forward, plan explore long CoT leveraged enhance tasks fields. Language Mixing DeepSeekR1 currently optimized Chinese English, may result language mixing issues handling queries languages. For instance, DeepSeekR1 might use English reasoning responses, even query language English Chinese. We aim address limitation future updates. Prompting Engineering When evaluating DeepSeekR1, observe sensitive prompts. Fewshot prompting consistently degrades performance. Therefore, recommend users directly describe problem specify output format using zeroshot setting optimal results. Software Engineering Tasks Due long evaluation times, impact effi ciency RL process, largescale RL applied extensively software engineering tasks. As result, DeepSeekR1 demonstrated huge improvement DeepSeekV3 software engineering benchmarks. Future versions address implementing rejection sampling software engineering data incorporating asynchronous evaluations RL process improve efficiency. 16References AIMeta. Llama 3.1 model card, 2024. URL httpsgithub.commetallamallamam odelsblobmainmodelsllama3_1MODEL_CARD.md . Anthropic. Claude 3.5 sonnet, 2024. URL httpswww.anthropic.comnewsclaude3 5sonnet . M. Chen, J. Tworek, H. Jun, Q. Yuan, H. P . de Oliveira Pinto, J. Kaplan, H. Edwards, Y. Burda, N. Joseph, G. Brockman, A. Ray, R. Puri, G. Krueger, M. Petrov, H. Khlaaf, G. Sastry, P . Mishkin, B. Chan, S. Gray, N. Ryder, M. Pavlov, A. Power, L. Kaiser, M. Bavarian, C. Winter, P . Tillet, F. P . Such, D. Cummings, M. Plappert, F. Chantzis, E. Barnes, A. HerbertVoss, W. H. Guss, A. Nichol, A. Paino, N. Tezak, J. Tang, I. Babuschkin, S. Balaji, S. Jain, W. Saunders, C. Hesse, A. N. Carr, J. Leike, J. Achiam, V . Misra, E. Morikawa, A. Radford, M. Knight, M. Brundage, M. Murati, K. Mayer, P . Welinder, B. McGrew, D. Amodei, S. McCandlish, I. Sutskever, W. Zaremba. Evaluating large language models trained code. CoRR , abs2107.03374, 2021. URL httpsarxiv.orgabs2107.03374 . A. Dubey, A. Jauhri, A. Pandey, A. Kadian, A. AlDahle, A. Letman, A. Mathur, A. Schelten, A. Yang, A. Fan, et al. The llama 3 herd models. arXiv preprint arXiv2407.21783, 2024. Y. Dubois, B. Galambosi, P . Liang, T. B. Hashimoto. Lengthcontrolled alpacaeval A simple way debias automatic evaluators. arXiv preprint arXiv2404.04475, 2024. X. Feng, Z. Wan, M. Wen, S. M. McAleer, Y. Wen, W. Zhang, J. Wang. Alphazerolike treesearch guide large language model decoding training, 2024. URL https arxiv.orgabs2309.17179 . L. Gao, J. Schulman, J. Hilton. Scaling laws reward model overoptimization, 2022. URL httpsarxiv.orgabs2210.10760 . A. P . Gema, J. O. J. Leang, G. Hong, A. Devoto, A. C. M. Mancino, R. Saxena, X. He, Y. Zhao, X. Du, M. R. G. Madani, C. Barale, R. McHardy, J. Harris, J. Kaddour, E. van Krieken, P . Minervini. Are done mmlu? CoRR , abs2406.04127, 2024. URL httpsdoi.or g10.48550arXiv.2406.04127 . Google. Our nextgeneration model Gemini 1.5, 2024. URL httpsblog.googletechno logyaigooglegemininextgenerationmodelfebruary2024 . Y. He, S. Li, J. Liu, Y. Tan, W. Wang, H. Huang, X. Bu, H. Guo, C. Hu, B. Zheng, et al. Chi nese simpleqa A chinese factuality evaluation large language models. arXiv preprint arXiv2411.07140, 2024. D. Hendrycks, C. Burns, S. Basart, A. Zou, M. Mazeika, D. Song, J. Steinhardt. Measuring massive multitask language understanding. arXiv preprint arXiv2009.03300, 2020. Y. Huang, Y. Bai, Z. Zhu, J. Zhang, J. Zhang, T. Su, J. Liu, C. Lv, Y. Zhang, J. Lei, et al. CEval A multilevel multidiscipline chinese evaluation suite foundation models. arXiv preprint arXiv2305.08322, 2023. N. Jain, K. Han, A. Gu, W. Li, F. Yan, T. Zhang, S. Wang, A. SolarLezama, K. Sen, I. Stoica. Livecodebench Holistic contamination free evaluation large language models code. CoRR, abs2403.07974, 2024. URL httpsdoi.org10.48550arXiv.2403.07974 . 17S. Krishna, K. Krishna, A. Mohananey, S. Schwarcz, A. Stambler, S. Upadhyay, M. Faruqui. Fact, fetch, reason A unified evaluation retrievalaugmented generation. CoRR , abs2409.12941, 2024. doi 10.48550ARXIV.2409.12941. URL httpsdoi.org10.485 50arXiv.2409.12941 . A. Kumar, V . Zhuang, R. Agarwal, Y. Su, J. D. CoReyes, A. Singh, K. Baumli, S. Iqbal, C. Bishop, R. Roelofs, et al. Training language models selfcorrect via reinforcement learning. arXiv preprint arXiv2409.12917, 2024. H. Li, Y. Zhang, F. Koto, Y. Yang, H. Zhao, Y. Gong, N. Duan, T. Baldwin. CMMLU Measur ing massive multitask language understanding Chinese. arXiv preprint arXiv2306.09212 , 2023. T. Li, W.L. Chiang, E. Frick, L. Dunlap, T. Wu, B. Zhu, J. E. Gonzalez, I. Stoica. From crowdsourced data highquality benchmarks Arenahard benchbuilder pipeline. arXiv preprint arXiv2406.11939, 2024. H. Lightman, V . Kosaraju, Y. Burda, H. Edwards, B. Baker, T. Lee, J. Leike, J. Schulman, I. Sutskever, K. Cobbe. Lets verify step step. arXiv preprint arXiv2305.20050, 2023. B. Y. Lin. ZeroEval A Unified Framework Evaluating Language Models, July 2024. URL httpsgithub.comWildEvalZeroEval . MAA. American invitational mathematics examination aime. In American Invitational Mathematics Examination AIME 2024 , February 2024. URL httpsmaa.orgmath competitionsamericaninvitationalmathematicsexaminationaime . OpenAI. Hello GPT4o, 2024a. URL httpsopenai.comindexhellogpt4o . OpenAI. Learning reason llms, 2024b. URL httpsopenai.comindexlearnin gtoreasonwithllms . OpenAI. Introducing SimpleQA, 2024c. URL httpsopenai.comindexintroducing simpleqa . OpenAI. Introducing SWEbench verified releasing humanvalidated subset swe bench more, 2024d. URL httpsopenai.comindexintroducingswebench verified . Qwen. Qwq Reflect deeply boundaries unknown, 2024a. URL httpsqwenlm .github.ioblogqwq32bpreview . Qwen. Qwen2.5 A party foundation models, 2024b. URL httpsqwenlm.github.iob logqwen2.5 . D. Rein, B. L. Hou, A. C. Stickland, J. Petty, R. Y. Pang, J. Dirani, J. Michael, S. R. Bowman. GPQA A graduatelevel googleproof qa benchmark. arXiv preprint arXiv2311.12022 , 2023. Z. Shao, P . Wang, Q. Zhu, R. Xu, J. Song, M. Zhang, Y. Li, Y. Wu, D. Guo. Deepseekmath Pushing limits mathematical reasoning open language models. arXiv preprint arXiv2402.03300, 2024. D. Silver, T. Hubert, J. Schrittwieser, I. Antonoglou, M. Lai, A. Guez, M. Lanctot, L. Sifre, D. Kumaran, T. Graepel, T. P . Lillicrap, K. Simonyan, D. Hassabis. Mastering chess shogi selfplay general reinforcement learning algorithm. CoRR , abs1712.01815, 2017a. URL httparxiv.orgabs1712.01815 . 18D. Silver, J. Schrittwieser, K. Simonyan, I. Antonoglou, A. Huang, A. Guez, T. Hubert, L. Baker, M. Lai, A. Bolton, Y. Chen, T. P . Lillicrap, F. Hui, L. Sifre, G. van den Driessche, T. Graepel, D. Hassabis. Mastering game go without human knowledge. Nat. , 5507676354359, 2017b. doi 10.1038NATURE24270. URL httpsdoi.org10.1038nature24270 . C. Snell, J. Lee, K. Xu, A. Kumar. Scaling llm testtime compute optimally effective scaling model parameters, 2024. URL httpsarxiv.orgabs2408.033 14. T. Trinh, Y. Wu, Q. Le, H. He, T. Luong. Solving olympiad geometry without human demonstrations. Nature, 2024. doi 10.1038s41586023067475. J. Uesato, N. Kushman, R. Kumar, F. Song, N. Siegel, L. Wang, A. Creswell, G. Irving, I. Higgins. Solving math word problems processand outcomebased feedback. arXiv preprint arXiv2211.14275, 2022. P . Wang, L. Li, Z. Shao, R. Xu, D. Dai, Y. Li, D. Chen, Y. Wu, Z. Sui. Mathshepherd A label free stepbystep verifier llms mathematical reasoning. arXiv preprint arXiv2312.08935 , 2023. X. Wang, J. Wei, D. Schuurmans, Q. Le, E. Chi, S. Narang, A. Chowdhery, D. Zhou. Selfconsistency improves chain thought reasoning language models. arXiv preprint arXiv2203.11171, 2022. Y. Wang, X. Ma, G. Zhang, Y. Ni, A. Chandra, S. Guo, W. Ren, A. Arulraj, X. He, Z. Jiang, T. Li, M. Ku, K. Wang, A. Zhuang, R. Fan, X. Yue, W. Chen. Mmlupro A robust challenging multitask language understanding benchmark. CoRR , abs2406.01574, 2024. URL httpsdoi.org10.48550arXiv.2406.01574 . C. S. Xia, Y. Deng, S. Dunn, L. Zhang. Agentless Demystifying llmbased software engineering agents. arXiv preprint, 2024. H. Xin, Z. Z. Ren, J. Song, Z. Shao, W. Zhao, H. Wang, B. Liu, L. Zhang, X. Lu, Q. Du, W. Gao, Q. Zhu, D. Yang, Z. Gou, Z. F. Wu, F. Luo, C. Ruan. Deepseekproverv1.5 Harnessing proof assistant feedback reinforcement learning montecarlo tree search, 2024. URL httpsarxiv.orgabs2408.08152 . J. Zhou, T. Lu, S. Mishra, S. Brahma, S. Basu, Y. Luan, D. Zhou, L. Hou. Instructionfollowing evaluation large language models. arXiv preprint arXiv2311.07911, 2023. 19Appendix A. Contributions Acknowledgments Core Contributors Daya Guo Dejian Yang Haowei Zhang Junxiao Song Ruoyu Zhang Runxin Xu Qihao Zhu Shirong Ma Peiyi Wang Xiao Bi Xiaokang Zhang Xingkai Yu Yu Wu Z.F. Wu Zhibin Gou Zhihong Shao Zhuoshu Li Ziyi Gao Contributors Aixin Liu Bing Xue Bingxuan Wang Bochao Wu Bei Feng Chengda Lu Chenggang Zhao Chengqi Deng Chong Ruan Damai Dai Deli Chen Dongjie Ji Erhang Li Fangyun Lin Fucong Dai Fuli Luo Guangbo Hao Guanting Chen Guowei Li H. Zhang Hanwei Xu Honghui Ding Huazuo Gao Hui QuHui Li Jianzhong Guo Jiashi Li Jingchang Chen Jingyang Yuan Jinhao Tu Junjie Qiu Junlong Li J.L. Cai Jiaqi Ni Jian Liang Jin Chen Kai Dong Kai Hu Kaichao You Kaige Gao Kang Guan Kexin Huang Kuai Yu Lean Wang Lecong Zhang Liang Zhao Litong Wang Liyue Zhang Lei Xu Leyi Xia Mingchuan Zhang Minghua Zhang Minghui Tang Mingxu Zhou Meng Li Miaojun Wang Mingming Li Ning Tian Panpan Huang Peng Zhang Qiancheng Wang Qinyu Chen Qiushi Du Ruiqi Ge Ruisong Zhang Ruizhe Pan Runji Wang R.J. Chen R.L. Jin 20Ruyi Chen Shanghao Lu Shangyan Zhou Shanhuang Chen Shengfeng Ye Shiyu Wang Shuiping Yu Shunfeng Zhou Shuting Pan S.S. Li Shuang Zhou Shaoqing Wu Shengfeng Ye Tao Yun Tian Pei Tianyu Sun T. Wang Wangding Zeng Wen Liu Wenfeng Liang Wenjun Gao Wenqin Yu Wentao Zhang W.L. Xiao Wei An Xiaodong Liu Xiaohan Wang Xiaokang Chen Xiaotao Nie Xin Cheng Xin Liu Xin Xie Xingchao Liu Xinyu Yang Xinyuan Li Xuecheng Su Xuheng Lin X.Q. Li Xiangyue Jin Xiaojin Shen Xiaosha Chen Xiaowen Sun Xiaoxiang Wang Xinnan Song Xinyi Zhou Xianzu Wang Xinxia Shan Y.K. Li Y.Q. WangY.X. Wei Yang Zhang Yanhong Xu Yao Li Yao Zhao Yaofeng Sun Yaohui Wang Yi Yu Yichao Zhang Yifan Shi Yiliang Xiong Ying He Yishi Piao Yisong Wang Yixuan Tan Yiyang Ma Yiyuan Liu Yongqiang Guo Yuan Ou Yuduan Wang Yue Gong Yuheng Zou Yujia He Yunfan Xiong Yuxiang Luo Yuxiang You Yuxuan Liu Yuyang Zhou Y.X. Zhu Yanping Huang Yaohui Li Yi Zheng Yuchen Zhu Yunxian Ma Ying Tang Yukun Zha Yuting Yan Z.Z. Ren Zehui Ren Zhangli Sha Zhe Fu Zhean Xu Zhenda Xie Zhengyan Zhang Zhewen Hao Zhicheng Ma Zhigang Yan Zhiyu Wu Zihui Gu 21Zijia Zhu Zijun Liu Zilin Li Ziwei Xie Ziyang Song Zizheng PanZhen Huang Zhipeng Xu Zhongyu Zhang Zhen Zhang Within role, authors listed alphabetically first name. Names marked denote individuals departed team. 22"}, {"page_content": "Artificial intelligence AI refers capability computational systems perform tasks typically associated human intelligence, learning, reasoning, problemsolving, perception, decisionmaking. It field research computer science develops studies methods software enable machines perceive environment use learning intelligence take actions maximize chances achieving defined goals. Such machines may called AIs. Highprofile applications AI include advanced web search engines e.g., Google Search recommendation systems used YouTube, Amazon, Netflix virtual assistants e.g., Google Assistant, Siri, Alexa autonomous vehicles e.g., Waymo generative creative tools e.g., ChatGPT AI art superhuman play analysis strategy games e.g., chess Go. However, many AI applications perceived AI A lot cutting edge AI filtered general applications, often without called AI something becomes useful enough common enough labeled AI anymore. Various subfields AI research centered around particular goals use particular tools. The traditional goals AI research include learning, reasoning, knowledge representation, planning, natural language processing, perception, support robotics. General intelligencethe ability complete task performed human least equal levelis among fields longterm goals. To reach goals, AI researchers adapted integrated wide range techniques, including search mathematical optimization, formal logic, artificial neural networks, methods based statistics, operations research, economics. AI also draws upon psychology, linguistics, philosophy, neuroscience, fields. Artificial intelligence founded academic discipline 1956, field went multiple cycles optimism throughout history, followed periods disappointment loss funding, known AI winters. Funding interest vastly increased 2012 deep learning outperformed previous AI techniques. This growth accelerated 2017 transformer architecture, early 2020s many billions dollars invested AI field experienced rapid ongoing progress become known AI boom. The emergence advanced generative AI midst AI boom ability create modify content exposed several unintended consequences harms present raised concerns risks AI longterm effects future, prompting discussions regulatory policies ensure safety benefits technology. Goals The general problem simulating creating intelligence broken subproblems. These consist particular traits capabilities researchers expect intelligent system display. The traits described received attention cover scope AI research. Reasoning problemsolving Early researchers developed algorithms imitated stepbystep reasoning humans use solve puzzles make logical deductions. By late 1980s 1990s, methods developed dealing uncertain incomplete information, employing concepts probability economics. Many algorithms insufficient solving large reasoning problems experience combinatorial explosion They become exponentially slower problems grow. Even humans rarely use stepbystep deduction early AI research could model. They solve problems using fast, intuitive judgments. Accurate efficient reasoning unsolved problem. Knowledge representation Knowledge representation knowledge engineering allow AI programs answer questions intelligently make deductions realworld facts. Formal knowledge representations used contentbased indexing retrieval, scene interpretation, clinical decision support, knowledge discovery mining interesting actionable inferences large databases, areas. A knowledge base body knowledge represented form used program. An ontology set objects, relations, concepts, properties used particular domain knowledge. Knowledge bases need represent things objects, properties, categories, relations objects situations, events, states, time causes effects knowledge knowledge know people know default reasoning things humans assume true told differently remain true even facts changing many aspects domains knowledge. Among difficult problems knowledge representation breadth commonsense knowledge set atomic facts average person knows enormous subsymbolic form commonsense knowledge much people know represented facts statements could express verbally. There also difficulty knowledge acquisition, problem obtaining knowledge AI applications. Planning decisionmaking An agent anything perceives takes actions world. A rational agent goals preferences takes actions make happen. In automated planning, agent specific goal. In automated decisionmaking, agent preferencesthere situations would prefer in, situations trying avoid. The decisionmaking agent assigns number situation called utility measures much agent prefers it. For possible action, calculate expected utility utility possible outcomes action, weighted probability outcome occur. It choose action maximum expected utility. In classical planning, agent knows exactly effect action be. In realworld problems, however, agent may certain situation unknown unobservable may know certain happen possible action deterministic. It must choose action making probabilistic guess reassess situation see action worked. In problems, agents preferences may uncertain, especially agents humans involved. These learned e.g., inverse reinforcement learning, agent seek information improve preferences. Information value theory used weigh value exploratory experimental actions. The space possible future actions situations typically intractably large, agents must take actions evaluate situations uncertain outcome be. A Markov decision process transition model describes probability particular action change state particular way reward function supplies utility state cost action. A policy associates decision possible state. The policy could calculated e.g., iteration, heuristic, learned. Game theory describes rational behavior multiple interacting agents used AI programs make decisions involve agents. Learning Machine learning study programs improve performance given task automatically. It part AI beginning. There several kinds machine learning. Unsupervised learning analyzes stream data finds patterns makes predictions without guidance. Supervised learning requires labeling training data expected answers, comes two main varieties classification program must learn predict category input belongs regression program must deduce numeric function based numeric input. In reinforcement learning, agent rewarded good responses punished bad ones. The agent learns choose responses classified good. Transfer learning knowledge gained one problem applied new problem. Deep learning type machine learning runs inputs biologically inspired artificial neural networks types learning. Computational learning theory assess learners computational complexity, sample complexity much data required, notions optimization. Natural language processing Natural language processing NLP allows programs read, write communicate human languages English. Specific problems include speech recognition, speech synthesis, machine translation, information extraction, information retrieval question answering. Early work, based Noam Chomskys generative grammar semantic networks, difficulty wordsense disambiguation unless restricted small domains called microworlds due common sense knowledge problem. Margaret Masterman believed meaning grammar key understanding languages, thesauri dictionaries basis computational language structure. Modern deep learning techniques NLP include word embedding representing words, typically vectors encoding meaning, transformers deep learning architecture using attention mechanism, others. In 2019, generative pretrained transformer GPT language models began generate coherent text, 2023, models able get humanlevel scores bar exam, SAT test, GRE test, many realworld applications. Perception Machine perception ability use input sensors cameras, microphones, wireless signals, active lidar, sonar, radar, tactile sensors deduce aspects world. Computer vision ability analyze visual input. The field includes speech recognition, image classification, facial recognition, object recognition,object tracking, robotic perception. Social intelligence Affective computing field comprises systems recognize, interpret, process, simulate human feeling, emotion, mood. For example, virtual assistants programmed speak conversationally even banter humorously makes appear sensitive emotional dynamics human interaction, otherwise facilitate humancomputer interaction. However, tends give na\u00efve users unrealistic conception intelligence existing computer agents. Moderate successes related affective computing include textual sentiment analysis and, recently, multimodal sentiment analysis, wherein AI classifies effects displayed videotaped subject. General intelligence A machine artificial general intelligence able solve wide variety problems breadth versatility similar human intelligence. Techniques AI research uses wide variety techniques accomplish goals above. Search optimization AI solve many problems intelligently searching many possible solutions. There two different kinds search used AI state space search local search. State space search State space search searches tree possible states try find goal state. For example, planning algorithms search trees goals subgoals, attempting find path target goal, process called meansends analysis. Simple exhaustive searches rarely sufficient realworld problems search space number places search quickly grows astronomical numbers. The result search slow never completes. Heuristics rules thumb help prioritize choices likely reach goal. Adversarial search used gameplaying programs, chess Go. It searches tree possible moves countermoves, looking winning position. Local search Local search uses mathematical optimization find solution problem. It begins form guess refines incrementally. Gradient descent type local search optimizes set numerical parameters incrementally adjusting minimize loss function. Variants gradient descent commonly used train neural networks, backpropagation algorithm. Another type local search evolutionary computation, aims iteratively improve set candidate solutions mutating recombining them, selecting fittest survive generation. Distributed search processes coordinate via swarm intelligence algorithms. Two popular swarm algorithms used search particle swarm optimization inspired bird flocking ant colony optimization inspired ant trails. Logic Formal logic used reasoning knowledge representation. Formal logic comes two main forms propositional logic operates statements true false uses logical connectives and, or, implies predicate logic also operates objects, predicates relations uses quantifiers Every X Y There Xs Ys. Deductive reasoning logic process proving new statement conclusion statements given assumed true premises. Proofs structured proof trees, nodes labelled sentences, children nodes connected parent nodes inference rules. Given problem set premises, problemsolving reduces searching proof tree whose root node labelled solution problem whose leaf nodes labelled premises axioms. In case Horn clauses, problemsolving search performed reasoning forwards premises backwards problem. In general case clausal form firstorder logic, resolution single, axiomfree rule inference, problem solved proving contradiction premises include negation problem solved. Inference Horn clause logic firstorder logic undecidable, therefore intractable. However, backward reasoning Horn clauses, underpins computation logic programming language Prolog, Turing complete. Moreover, efficiency competitive computation symbolic programming languages. Fuzzy logic assigns degree truth 0 1. It therefore handle propositions vague partially true. Nonmonotonic logics, including logic programming negation failure, designed handle default reasoning. Other specialized versions logic developed describe many complex domains. Probabilistic methods uncertain reasoning Many problems AI including reasoning, planning, learning, perception, robotics require agent operate incomplete uncertain information. AI researchers devised number tools solve problems using methods probability theory economics. Precise mathematical tools developed analyze agent make choices plan, using decision theory, decision analysis, information value theory. These tools include models Markov decision processes, dynamic decision networks, game theory mechanism design. Bayesian networks tool used reasoning using Bayesian inference algorithm, learning using expectationmaximization algorithm, planning using decision networks perception using dynamic Bayesian networks. Probabilistic algorithms also used filtering, prediction, smoothing, finding explanations streams data, thus helping perception systems analyze processes occur time e.g., hidden Markov models Kalman filters. Classifiers statistical learning methods The simplest AI applications divided two types classifiers e.g., shiny diamond, one hand, controllers e.g., diamond pick up, hand. Classifiers functions use pattern matching determine closest match. They finetuned based chosen examples using supervised learning. Each pattern also called observation labeled certain predefined class. All observations combined class labels known data set. When new observation received, observation classified based previous experience. There many kinds classifiers use. The decision tree simplest widely used symbolic machine learning algorithm. Knearest neighbor algorithm widely used analogical AI mid1990s, Kernel methods support vector machine SVM displaced knearest neighbor 1990s. The naive Bayes classifier reportedly widely used learner Google, due part scalability. Neural networks also used classifiers. Artificial neural networks An artificial neural network based collection nodes also known artificial neurons, loosely model neurons biological brain. It trained recognise patterns trained, recognise patterns fresh data. There input, least one hidden layer nodes output. Each node applies function weight crosses specified threshold, data transmitted next layer. A network typically called deep neural network least 2 hidden layers. Learning algorithms neural networks use local search choose weights get right output input training. The common training technique backpropagation algorithm. Neural networks learn model complex relationships inputs outputs find patterns data. In theory, neural network learn function. In feedforward neural networks signal passes one direction. Recurrent neural networks feed output signal back input, allows shortterm memories previous input events. Long short term memory successful network architecture recurrent networks. Perceptrons use single layer neurons deep learning uses multiple layers. Convolutional neural networks strengthen connection neurons close otherthis especially important image processing, local set neurons must identify edge network identify object. Deep learning Deep learning uses several layers neurons networks inputs outputs. The multiple layers progressively extract higherlevel features raw input. For example, image processing, lower layers may identify edges, higher layers may identify concepts relevant human digits, letters, faces. Deep learning profoundly improved performance programs many important subfields artificial intelligence, including computer vision, speech recognition, natural language processing, image classification, others. The reason deep learning performs well many applications known 2021. The sudden success deep learning 20122015 occur new discovery theoretical breakthrough deep neural networks backpropagation described many people, far back 1950s two factors incredible increase computer power including hundredfold increase speed switching GPUs availability vast amounts training data, especially giant curated datasets used benchmark testing, ImageNet. GPT Generative pretrained transformers GPT large language models LLMs generate text based semantic relationships words sentences. Textbased GPT models pretrained large corpus text Internet. The pretraining consists predicting next token token usually word, subword, punctuation. Throughout pretraining, GPT models accumulate knowledge world generate humanlike text repeatedly predicting next token. Typically, subsequent training phase makes model truthful, useful, harmless, usually technique called reinforcement learning human feedback RLHF. Current GPT models prone generating falsehoods called hallucinations, although reduced RLHF quality data. They used chatbots, allow people ask question request task simple text. Current models services include Gemini formerly Bard, ChatGPT, Grok, Claude, Copilot, LLaMA. Multimodal GPT models process different types data modalities images, videos, sound, text. Hardware software In late 2010s, graphics processing units GPUs increasingly designed AIspecific enhancements used specialized TensorFlow software replaced previously used central processing unit CPUs dominant means largescale commercial academic machine learning models training. Specialized programming languages Prolog used early AI research, generalpurpose programming languages like Python become predominant. The transistor density integrated circuits observed roughly double every 18 monthsa trend known Moores law, named Intel cofounder Gordon Moore, first identified it. Improvements GPUs even faster, trend sometimes called Huangs law, named Nvidia cofounder CEO Jensen Huang. Applications AI machine learning technology used essential applications 2020s, including search engines Google Search, targeting online advertisements, recommendation systems offered Netflix, YouTube Amazon, driving internet traffic, targeted advertising AdSense, Facebook, virtual assistants Siri Alexa, autonomous vehicles including drones, ADAS selfdriving cars, automatic language translation Microsoft Translator, Google Translate, facial recognition Apples Face ID Microsofts DeepFace Googles FaceNet image labeling used Facebook, Apples iPhoto TikTok. The deployment AI may overseen Chief automation officer CAO. Health medicine The application AI medicine medical research potential increase patient care quality life. Through lens Hippocratic Oath, medical professionals ethically compelled use AI, applications accurately diagnose treat patients. For medical research, AI important tool processing integrating big data. This particularly important organoid tissue engineering development use microscopy imaging key technique fabrication. It suggested AI overcome discrepancies funding allocated different fields research. New AI tools deepen understanding biomedically relevant pathways. For example, AlphaFold 2 2021 demonstrated ability approximate, hours rather months, 3D structure protein. In 2023, reported AIguided drug discovery helped find class antibiotics capable killing two different types drugresistant bacteria. In 2024, researchers used machine learning accelerate search Parkinsons disease drug treatments. Their aim identify compounds block clumping, aggregation, alphasynuclein protein characterises Parkinsons disease. They able speed initial screening process tenfold reduce cost thousandfold. Games Game playing programs used since 1950s demonstrate test AIs advanced techniques. Deep Blue became first computer chessplaying system beat reigning world chess champion, Garry Kasparov, 11 May 1997. In 2011, Jeopardy! quiz show exhibition match, IBMs question answering system, Watson, defeated two greatest Jeopardy! champions, Brad Rutter Ken Jennings, significant margin. In March 2016, AlphaGo 4 5 games Go match Go champion Lee Sedol, becoming first computer Goplaying system beat professional Go player without handicaps. Then, 2017, defeated Ke Jie, best Go player world. Other programs handle imperfectinformation games, pokerplaying program Pluribus. DeepMind developed increasingly generalistic reinforcement learning models, MuZero, could trained play chess, Go, Atari games. In 2019, DeepMinds AlphaStar achieved grandmaster level StarCraft II, particularly challenging realtime strategy game involves incomplete knowledge happens map. In 2021, AI agent competed PlayStation Gran Turismo competition, winning four worlds best Gran Turismo drivers using deep reinforcement learning. In 2024, Google DeepMind introduced SIMA, type AI capable autonomously playing nine previously unseen openworld video games observing screen output, well executing short, specific tasks response natural language instructions. Mathematics Large language models, GPT4, Gemini, Claude, LLaMa Mistral, increasingly used mathematics. These probabilistic models versatile, also produce wrong answers form hallucinations. They sometimes need large database mathematical problems learn from, also methods supervised finetuning trained classifiers humanannotated data improve answers new problems learn corrections. A February 2024 study showed performance language models reasoning capabilities solving math problems included training data low, even problems minor deviations trained data. One technique improve performance involves training models produce correct reasoning steps, rather correct result. The Alibaba Group developed version Qwen models called Qwen2Math, achieved stateoftheart performance several mathematical benchmarks, including 84 accuracy MATH dataset competition mathematics problems. In January 2025, Microsoft proposed technique rStarMath leverages Monte Carlo tree search stepbystep reasoning, enabling relatively small language model like Qwen7B solve 53 AIME 2024 90 MATH benchmark problems. Alternatively, dedicated models mathematical problem solving higher precision outcome including proof theorems developed AlphaTensor, AlphaGeometry AlphaProof Google DeepMind, Llemma EleutherAI Julius. When natural language used describe mathematical problems, converters transform prompts formal language Lean define mathematical tasks. Some models developed solve challenging problems reach good results benchmark tests, others serve educational tools mathematics. Topological deep learning integrates various topological approaches. Finance Finance one fastest growing sectors applied AI tools deployed retail online banking investment advice insurance, automated robot advisers use years. World Pensions experts like Nicolas Firzli insist may early see emergence highly innovative AIinformed financial products services deployment AI tools simply automatise things destroying tens thousands jobs banking, financial planning, pension advice process, Im sure unleash new wave e.g., sophisticated pension innovation. Military Various countries deploying AI military applications. The main applications enhance command control, communications, sensors, integration interoperability. Research targeting intelligence collection analysis, logistics, cyber operations, information operations, semiautonomous autonomous vehicles. AI technologies enable coordination sensors effectors, threat detection identification, marking enemy positions, target acquisition, coordination deconfliction distributed Joint Fires networked combat vehicles, human operated autonomous. AI used military operations Iraq, Syria, Israel Ukraine. Generative AI Agents Artificial intelligent AI agents software entities designed perceive environment, make decisions, take actions autonomously achieve specific goals. These agents interact users, environment, agents. AI agents used various applications, including virtual assistants, chatbots, autonomous vehicles, gameplaying systems, industrial robotics. AI agents operate within constraints programming, available computational resources, hardware limitations. This means restricted performing tasks within defined scope finite memory processing capabilities. In realworld applications, AI agents often face time constraints decisionmaking action execution. Many AI agents incorporate learning algorithms, enabling improve performance time experience training. Using machine learning, AI agents adapt new situations optimise behaviour designated tasks. Sexuality Applications AI domain include AIenabled menstruation fertility trackers analyze user data offer prediction, AIintegrated sex toys e.g., teledildonics, AIgenerated sexual education content, AI agents simulate sexual romantic partners e.g., Replika. AI also used production nonconsensual deepfake pornography, raising significant ethical legal concerns. AI technologies also used attempt identify online genderbased violence online sexual grooming minors. Other industryspecific tasks There also thousands successful AI applications used solve specific problems specific industries institutions. In 2017 survey, one five companies reported incorporated AI offerings processes. A examples energy storage, medical diagnosis, military logistics, applications predict result judicial decisions, foreign policy, supply chain management. AI applications evacuation disaster management growing. AI used investigate people evacuated large scale small scale evacuations using historical data GPS, videos social media. Further, AI provide real time information real time evacuation conditions. In agriculture, AI helped farmers identify areas need irrigation, fertilization, pesticide treatments increasing yield. Agronomists use AI conduct research development. AI used predict ripening time crops tomatoes, monitor soil moisture, operate agricultural robots, conduct predictive analytics, classify livestock pig call emotions, automate greenhouses, detect diseases pests, save water. Artificial intelligence used astronomy analyze increasing amounts available data applications, mainly classification, regression, clustering, forecasting, generation, discovery, development new scientific insights. For example, used discovering exoplanets, forecasting solar activity, distinguishing signals instrumental effects gravitational wave astronomy. Additionally, could used activities space, space exploration, including analysis data space missions, realtime science decisions spacecraft, space debris avoidance, autonomous operation. During 2024 Indian elections, US50 million spent authorized AIgenerated content, notably creating deepfakes allied including sometimes deceased politicians better engage voters, translating speeches various local languages. Ethics AI potential benefits potential risks. AI may able advance science find solutions serious problems Demis Hassabis DeepMind hopes solve intelligence, use solve everything else. However, use AI become widespread, several unintended consequences risks identified. Inproduction systems sometimes factor ethics bias AI training processes, especially AI algorithms inherently unexplainable deep learning. Risks harm Privacy copyright Machine learning algorithms require large amounts data. The techniques used acquire data raised concerns privacy, surveillance copyright. AIpowered devices services, virtual assistants IoT products, continuously collect personal information, raising concerns intrusive data gathering unauthorized access third parties. The loss privacy exacerbated AIs ability process combine vast amounts data, potentially leading surveillance society individual activities constantly monitored analyzed without adequate safeguards transparency. Sensitive user data collected may include online activity records, geolocation data, video, audio. For example, order build speech recognition algorithms, Amazon recorded millions private conversations allowed temporary workers listen transcribe them. Opinions widespread surveillance range see necessary evil clearly unethical violation right privacy. AI developers argue way deliver valuable applications developed several techniques attempt preserve privacy still obtaining data, data aggregation, deidentification differential privacy. Since 2016, privacy experts, Cynthia Dwork, begun view privacy terms fairness. Brian Christian wrote experts pivoted question know question theyre it. Generative AI often trained unlicensed copyrighted works, including domains images computer code output used rationale fair use. Experts disagree well circumstances rationale hold courts law relevant factors may include purpose character use copyrighted work effect upon potential market copyrighted work. Website owners wish content scraped indicate robots.txt file. In 2023, leading authors including John Grisham Jonathan Franzen sued AI companies using work train generative AI. Another discussed approach envision separate sui generis system protection creations generated AI ensure fair attribution compensation human authors. Dominance tech giants The commercial AI scene dominated Big Tech companies Alphabet Inc., Amazon, Apple Inc., Meta Platforms, Microsoft. Some players already vast majority existing cloud infrastructure computing power data centers, allowing entrench marketplace. Power needs environmental impacts In January 2024, International Energy Agency IEA released Electricity 2024, Analysis Forecast 2026, forecasting electric power use. This first IEA report make projections data centers power consumption artificial intelligence cryptocurrency. The report states power demand uses might double 2026, additional electric power usage equal electricity used whole Japanese nation. Prodigious power consumption AI responsible growth fossil fuels use, might delay closings obsolete, carbonemitting coal energy facilities. There feverish rise construction data centers throughout US, making large technology firms e.g., Microsoft, Meta, Google, Amazon voracious consumers electric power. Projected electric consumption immense concern fulfilled matter source. A ChatGPT search involves use 10 times electrical energy Google search. The large firms haste find power sources nuclear energy geothermal fusion. The tech firms argue long view AI eventually kinder environment, need energy now. AI makes power grid efficient intelligent, assist growth nuclear power, track overall carbon emissions, according technology firms. A 2024 Goldman Sachs Research Paper, AI Data Centers Coming US Power Demand Surge, found US power demand likely experience growth seen generation.... forecasts that, 2030, US data centers consume 8 US power, opposed 3 2022, presaging growth electrical power generation industry variety means. Data centers need electrical power might max electrical grid. The Big Tech companies counter AI used maximize utilization grid all. In 2024, Wall Street Journal reported big AI companies begun negotiations US nuclear power providers provide electricity data centers. In March 2024 Amazon purchased Pennsylvania nuclearpowered data center 650 Million US. Nvidia CEO JenHsun Huang said nuclear power good option data centers. In September 2024, Microsoft announced agreement Constellation Energy reopen Three Mile Island nuclear power plant provide Microsoft 100 electric power produced plant 20 years. Reopening plant, suffered partial nuclear meltdown Unit 2 reactor 1979, require Constellation get strict regulatory processes include extensive safety scrutiny US Nuclear Regulatory Commission. If approved first ever US recommissioning nuclear plant, 835 megawatts power enough 800,000 homes energy produced. The cost reopening upgrading estimated 1.6 billion US dependent tax breaks nuclear power contained 2022 US Inflation Reduction Act. The US government state Michigan investing almost 2 billion US reopen Palisades Nuclear reactor Lake Michigan. Closed since 2022, plant planned reopened October 2025. The Three Mile Island facility renamed Crane Clean Energy Center Chris Crane, nuclear proponent former CEO Exelon responsible Exelon spinoff Constellation. After last approval September 2023, Taiwan suspended approval data centers north Taoyuan capacity 5 MW 2024, due power supply shortages. Taiwan aims phase nuclear power 2025. On hand, Singapore imposed ban opening data centers 2019 due electric power, 2022, lifted ban. Although nuclear plants Japan shut 2011 Fukushima nuclear accident, according October 2024 Bloomberg article Japanese, cloud gaming services company Ubitus, Nvidia stake, looking land Japan near nuclear power plant new data center generative AI. Ubitus CEO Wesley Kuo said nuclear power plants efficient, cheap stable power AI. On 1 November 2024, Federal Energy Regulatory Commission FERC rejected application submitted Talen Energy approval supply electricity nuclear power station Susquehanna Amazons data center. According Commission Chairman Willie L. Phillips, burden electricity grid well significant cost shifting concern households business sectors. Misinformation YouTube, Facebook others use recommender systems guide users content. These AI programs given goal maximizing user engagement is, goal keep people watching. The AI learned users tended choose misinformation, conspiracy theories, extreme partisan content, and, keep watching, AI recommended it. Users also tended watch content subject, AI led people filter bubbles received multiple versions misinformation. This convinced many users misinformation true, ultimately undermined trust institutions, media government. The AI program correctly learned maximize goal, result harmful society. After U.S. election 2016, major technology companies took steps mitigate problem . In 2022, generative AI began create images, audio, video text indistinguishable real photographs, recordings, films, human writing. It possible bad actors use technology create massive amounts misinformation propaganda. AI pioneer Geoffrey Hinton expressed concern AI enabling authoritarian leaders manipulate electorates large scale, among risks. Algorithmic bias fairness Machine learning applications biased learn biased data. The developers may aware bias exists. Bias introduced way training data selected way model deployed. If biased algorithm used make decisions seriously harm people medicine, finance, recruitment, housing policing algorithm may cause discrimination. The field fairness studies prevent harms algorithmic biases. On June 28, 2015, Google Photoss new image labeling feature mistakenly identified Jacky Alcine friend gorillas black. The system trained dataset contained images black people, problem called sample size disparity. Google fixed problem preventing system labelling anything gorilla. Eight years later, 2023, Google Photos still could identify gorilla, neither could similar products Apple, Facebook, Microsoft Amazon. COMPAS commercial program widely used U.S. courts assess likelihood defendant becoming recidivist. In 2016, Julia Angwin ProPublica discovered COMPAS exhibited racial bias, despite fact program told races defendants. Although error rate whites blacks calibrated equal exactly 61, errors race differentthe system consistently overestimated chance black person would reoffend would underestimate chance white person would reoffend. In 2017, several researchers showed mathematically impossible COMPAS accommodate possible measures fairness base rates reoffense different whites blacks data. A program make biased decisions even data explicitly mention problematic feature race gender. The feature correlate features like address, shopping history first name, program make decisions based features would race gender. Moritz Hardt said robust fact research area fairness blindness doesnt work. Criticism COMPAS highlighted machine learning models designed make predictions valid assume future resemble past. If trained data includes results racist decisions past, machine learning models must predict racist decisions made future. If application uses predictions recommendations, recommendations likely racist. Thus, machine learning well suited help make decisions areas hope future better past. It descriptive rather prescriptive. Bias unfairness may go undetected developers overwhelmingly white male among AI engineers, 4 black 20 women. There various conflicting definitions mathematical models fairness. These notions depend ethical assumptions, influenced beliefs society. One broad category distributive fairness, focuses outcomes, often identifying groups seeking compensate statistical disparities. Representational fairness tries ensure AI systems reinforce negative stereotypes render certain groups invisible. Procedural fairness focuses decision process rather outcome. The relevant notions fairness may depend context, notably type AI application stakeholders. The subjectivity notions bias fairness makes difficult companies operationalize them. Having access sensitive attributes race gender also considered many AI ethicists necessary order compensate biases, may conflict antidiscrimination laws. At 2022 Conference Fairness, Accountability, Transparency ACM FAccT 2022, Association Computing Machinery, Seoul, South Korea, presented published findings recommend AI robotics systems demonstrated free bias mistakes, unsafe, use selflearning neural networks trained vast, unregulated sources flawed internet data curtailed. Lack transparency Many AI systems complex designers cannot explain reach decisions. Particularly deep neural networks, large amount nonlinear relationships inputs outputs. But popular explainability techniques exist. It impossible certain program operating correctly one knows exactly works. There many cases machine learning program passed rigorous tests, nevertheless learned something different programmers intended. For example, system could identify skin diseases better medical professionals found actually strong tendency classify images ruler cancerous, pictures malignancies typically include ruler show scale. Another machine learning system designed help effectively allocate medical resources found classify patients asthma low risk dying pneumonia. Having asthma actually severe risk factor, since patients asthma would usually get much medical care, relatively unlikely die according training data. The correlation asthma low risk dying pneumonia real, misleading. People harmed algorithms decision right explanation. Doctors, example, expected clearly completely explain colleagues reasoning behind decision make. Early drafts European Unions General Data Protection Regulation 2016 included explicit statement right exists. Industry experts noted unsolved problem solution sight. Regulators argued nevertheless harm real problem solution, tools used. DARPA established XAI Explainable Artificial Intelligence program 2014 try solve problems. Several approaches aim address transparency problem. SHAP enables visualise contribution feature output. LIME locally approximate models outputs simpler, interpretable model. Multitask learning provides large number outputs addition target classification. These outputs help developers deduce network learned. Deconvolution, DeepDream generative methods allow developers see different layers deep network computer vision learned, produce output suggest network learning. For generative pretrained transformers, Anthropic developed technique based dictionary learning associates patterns neuron activations humanunderstandable concepts. Bad actors weaponized AI Artificial intelligence provides number tools useful bad actors, authoritarian governments, terrorists, criminals rogue states. A lethal autonomous weapon machine locates, selects engages human targets without human supervision. Widely available AI tools used bad actors develop inexpensive autonomous weapons and, produced scale, potentially weapons mass destruction. Even used conventional warfare, currently cannot reliably choose targets could potentially kill innocent person. In 2014, 30 nations including China supported ban autonomous weapons United Nations Convention Certain Conventional Weapons, however United States others disagreed. By 2015, fifty countries reported researching battlefield robots. AI tools make easier authoritarian governments efficiently control citizens several ways. Face voice recognition allow widespread surveillance. Machine learning, operating data, classify potential enemies state prevent hiding. Recommendation systems precisely target propaganda misinformation maximum effect. Deepfakes generative AI aid producing misinformation. Advanced AI make authoritarian centralized decision making competitive liberal decentralized systems markets. It lowers cost difficulty digital warfare advanced spyware. All technologies available since 2020 earlierAI facial recognition systems already used mass surveillance China. There many ways AI expected help bad actors, foreseen. For example, machinelearning AI able design tens thousands toxic molecules matter hours. Technological unemployment Economists frequently highlighted risks redundancies AI, speculated unemployment adequate social policy full employment. In past, technology tended increase rather reduce total employment, economists acknowledge uncharted territory AI. A survey economists showed disagreement whether increasing use robots AI cause substantial increase longterm unemployment, generally agree could net benefit productivity gains redistributed. Risk estimates vary example, 2010s, Michael Osborne Carl Benedikt Frey estimated 47 U.S. jobs high risk potential automation, OECD report classified 9 U.S. jobs high risk. The methodology speculating future employment levels criticised lacking evidential foundation, implying technology, rather social policy, creates unemployment, opposed redundancies. In April 2023, reported 70 jobs Chinese video game illustrators eliminated generative artificial intelligence. Unlike previous waves automation, many middleclass jobs may eliminated artificial intelligence The Economist stated 2015 worry AI could whitecollar jobs steam power bluecollar ones Industrial Revolution worth taking seriously. Jobs extreme risk range paralegals fast food cooks, job demand likely increase carerelated professions ranging personal healthcare clergy. From early days development artificial intelligence, arguments, example, put forward Joseph Weizenbaum, whether tasks done computers actually done them, given difference computers humans, quantitative calculation qualitative, valuebased judgement. Existential risk It argued AI become powerful humanity may irreversibly lose control it. This could, physicist Stephen Hawking stated, spell end human race. This scenario common science fiction, computer robot suddenly develops humanlike selfawareness sentience consciousness becomes malevolent character. These scifi scenarios misleading several ways. First, AI require humanlike sentience existential risk. Modern AI programs given specific goals use learning intelligence achieve them. Philosopher Nick Bostrom argued one gives almost goal sufficiently powerful AI, may choose destroy humanity achieve used example paperclip factory manager. Stuart Russell gives example household robot tries find way kill owner prevent unplugged, reasoning cant fetch coffee youre dead. In order safe humanity, superintelligence would genuinely aligned humanitys morality values fundamentally side. Second, Yuval Noah Harari argues AI require robot body physical control pose existential risk. The essential parts civilization physical. Things like ideologies, law, government, money economy built language exist stories billions people believe. The current prevalence misinformation suggests AI could use language convince people believe anything, even take actions destructive. The opinions amongst experts industry insiders mixed, sizable fractions concerned unconcerned risk eventual superintelligent AI. Personalities Stephen Hawking, Bill Gates, Elon Musk, well AI pioneers Yoshua Bengio, Stuart Russell, Demis Hassabis, Sam Altman, expressed concerns existential risk AI. In May 2023, Geoffrey Hinton announced resignation Google order able freely speak risks AI without considering impacts Google. He notably mentioned risks AI takeover, stressed order avoid worst outcomes, establishing safety guidelines require cooperation among competing use AI. In 2023, many leading AI experts endorsed joint statement Mitigating risk extinction AI global priority alongside societalscale risks pandemics nuclear war. Some researchers optimistic. AI pioneer J\u00fcrgen Schmidhuber sign joint statement, emphasising 95 cases, AI research making human lives longer healthier easier. While tools used improve lives also used bad actors, also used bad actors. Andrew Ng also argued mistake fall doomsday hype AIand regulators benefit vested interests. Yann LeCun scoffs peers dystopian scenarios supercharged misinformation even, eventually, human extinction. In early 2010s, experts argued risks distant future warrant research humans valuable perspective superintelligent machine. However, 2016, study current future risks possible solutions became serious area research. Ethical machines alignment Friendly AI machines designed beginning minimize risks make choices benefit humans. Eliezer Yudkowsky, coined term, argues developing friendly AI higher research priority may require large investment must completed AI becomes existential risk. Machines intelligence potential use intelligence make ethical decisions. The field machine ethics provides machines ethical principles procedures resolving ethical dilemmas. The field machine ethics also called computational morality, founded AAAI symposium 2005. Other approaches include Wendell Wallachs artificial moral agents Stuart J. Russells three principles developing provably beneficial machines. Open source Active organizations AI opensource community include Hugging Face, Google, EleutherAI Meta. Various AI models, Llama 2, Mistral Stable Diffusion, made openweight, meaning architecture trained parameters weights publicly available. Openweight models freely finetuned, allows companies specialize data usecase. Openweight models useful research innovation also misused. Since finetuned, builtin security measure, objecting harmful requests, trained away becomes ineffective. Some researchers warn future AI models may develop dangerous capabilities potential drastically facilitate bioterrorism released Internet, cannot deleted everywhere needed. They recommend prerelease audits costbenefit analyses. Frameworks Artificial Intelligence projects ethical permissibility tested designing, developing, implementing AI system. An AI framework Care Act Framework containing SUM valuesdeveloped Alan Turing Institute tests projects four main areas Respect dignity individual people Connect people sincerely, openly, inclusively Care wellbeing everyone Protect social values, justice, public interest Other developments ethical frameworks include decided upon Asilomar Conference, Montreal Declaration Responsible AI, IEEEs Ethics Autonomous Systems initiative, among others however, principles without criticism, especially regards people chosen contribute frameworks. Promotion wellbeing people communities technologies affect requires consideration social ethical implications stages AI system design, development implementation, collaboration job roles data scientists, product managers, data engineers, domain experts, delivery managers. The UK AI Safety Institute released 2024 testing toolset called Inspect AI safety evaluations available MIT opensource licence freely available GitHub improved thirdparty packages. It used evaluate AI models range areas including core knowledge, ability reason, autonomous capabilities. Regulation The regulation artificial intelligence development public sector policies laws promoting regulating AI therefore related broader regulation algorithms. The regulatory policy landscape AI emerging issue jurisdictions globally. According AI Index Stanford, annual number AIrelated laws passed 127 survey countries jumped one passed 2016 37 passed 2022 alone. Between 2016 2020, 30 countries adopted dedicated strategies AI. Most EU member states released national AI strategies, Canada, China, India, Japan, Mauritius, Russian Federation, Saudi Arabia, United Arab Emirates, U.S., Vietnam. Others process elaborating AI strategy, including Bangladesh, Malaysia Tunisia. The Global Partnership Artificial Intelligence launched June 2020, stating need AI developed accordance human rights democratic values, ensure public confidence trust technology. Henry Kissinger, Eric Schmidt, Daniel Huttenlocher published joint statement November 2021 calling government commission regulate AI. In 2023, OpenAI leaders published recommendations governance superintelligence, believe may happen less 10 years. In 2023, United Nations also launched advisory body provide recommendations AI governance body comprises technology company executives, governments officials academics. In 2024, Council Europe created first international legally binding treaty AI, called Framework Convention Artificial Intelligence Human Rights, Democracy Rule Law. It adopted European Union, United States, United Kingdom, signatories. In 2022 Ipsos survey, attitudes towards AI varied greatly country 78 Chinese citizens, 35 Americans, agreed products services using AI benefits drawbacks. A 2023 ReutersIpsos poll found 61 Americans agree, 22 disagree, AI poses risks humanity. In 2023 Fox News poll, 35 Americans thought important, additional 41 thought somewhat important, federal government regulate AI, versus 13 responding important 8 responding important. In November 2023, first global AI Safety Summit held Bletchley Park UK discuss near far term risks AI possibility mandatory voluntary regulatory frameworks. 28 countries including United States, China, European Union issued declaration start summit, calling international cooperation manage challenges risks artificial intelligence. In May 2024 AI Seoul Summit, 16 global AI tech companies agreed safety commitments development AI. History The study mechanical formal reasoning began philosophers mathematicians antiquity. The study logic led directly Alan Turings theory computation, suggested machine, shuffling symbols simple 0 1, could simulate conceivable form mathematical reasoning. This, along concurrent discoveries cybernetics, information theory neurobiology, led researchers consider possibility building electronic brain. They developed several areas research would become part AI, McCullouch Pitts design artificial neurons 1943, Turings influential 1950 paper Computing Machinery Intelligence, introduced Turing test showed machine intelligence plausible. The field AI research founded workshop Dartmouth College 1956. The attendees became leaders AI research 1960s. They students produced programs press described astonishing computers learning checkers strategies, solving word problems algebra, proving logical theorems speaking English. Artificial intelligence laboratories set number British U.S. universities latter 1950s early 1960s. Researchers 1960s 1970s convinced methods would eventually succeed creating machine general intelligence considered goal field. In 1965 Herbert Simon predicted, machines capable, within twenty years, work man do. In 1967 Marvin Minsky agreed, writing within generation ... problem creating artificial intelligence substantially solved. They had, however, underestimated difficulty problem. In 1974, U.S. British governments cut exploratory research response criticism Sir James Lighthill ongoing pressure U.S. Congress fund productive projects. Minskys Paperts book Perceptrons understood proving artificial neural networks would never useful solving realworld tasks, thus discrediting approach altogether. The AI winter, period obtaining funding AI projects difficult, followed. In early 1980s, AI research revived commercial success expert systems, form AI program simulated knowledge analytical skills human experts. By 1985, market AI reached billion dollars. At time, Japans fifth generation computer project inspired U.S. British governments restore funding academic research. However, beginning collapse Lisp Machine market 1987, AI fell disrepute, second, longerlasting winter began. Up point, AIs funding gone projects used highlevel symbols represent mental objects like plans, goals, beliefs, known facts. In 1980s, researchers began doubt approach would able imitate processes human cognition, especially perception, robotics, learning pattern recognition, began look subsymbolic approaches. Rodney Brooks rejected representation general focussed directly engineering machines move survive. Judea Pearl, Lofti Zadeh, others developed methods handled incomplete uncertain information making reasonable guesses rather precise logic. But important development revival connectionism, including neural network research, Geoffrey Hinton others. In 1990, Yann LeCun successfully showed convolutional neural networks recognize handwritten digits, first many successful applications neural networks. AI gradually restored reputation late 1990s early 21st century exploiting formal mathematical methods finding specific solutions specific problems. This narrow formal focus allowed researchers produce verifiable results collaborate fields statistics, economics mathematics. By 2000, solutions developed AI researchers widely used, although 1990s rarely described artificial intelligence tendency known AI effect. However, several academic researchers became concerned AI longer pursuing original goal creating versatile, fully intelligent machines. Beginning around 2002, founded subfield artificial general intelligence AGI, several wellfunded institutions 2010s. Deep learning began dominate industry benchmarks 2012 adopted throughout field. For many specific tasks, methods abandoned. Deep learnings success based hardware improvements faster computers, graphics processing units, cloud computing access large amounts data including curated datasets, ImageNet. Deep learnings success led enormous increase interest funding AI. The amount machine learning research measured total publications increased 50 years 20152019. In 2016, issues fairness misuse technology catapulted center stage machine learning conferences, publications vastly increased, funding became available, many researchers refocussed careers issues. The alignment problem became serious field academic study. In late 2010s early 2020s, AGI companies began deliver programs created enormous interest. In 2015, AlphaGo, developed DeepMind, beat world champion Go player. The program taught games rules developed strategy itself. GPT3 large language model released 2020 OpenAI capable generating highquality humanlike text. ChatGPT, launched November 30, 2022, became fastestgrowing consumer software application history, gaining 100 million users two months. It marked widely regarded AIs breakout year, bringing public consciousness. These programs, others, inspired aggressive AI boom, large companies began investing billions dollars AI research. According AI Impacts, 50 billion annually invested AI around 2022 U.S. alone 20 new U.S. Computer Science PhD graduates specialized AI. About 800,000 AIrelated U.S. job openings existed 2022. According PitchBook research, 22 newly funded startups 2024 claimed AI companies. Philosophy Philosophical debates historically sought determine nature intelligence make intelligent machines. Another major focus whether machines conscious, associated ethical implications. Many topics philosophy relevant AI, epistemology free will. Rapid advancements intensified public discussions philosophy ethics AI. Defining artificial intelligence Alan Turing wrote 1950 I propose consider question machines think? He advised changing question whether machine thinks, whether possible machinery show intelligent behaviour. He devised Turing test, measures ability machine simulate human conversation. Since observe behavior machine, matter actually thinking literally mind. Turing notes determine things people usual polite convention everyone thinks. Russell Norvig agree Turing intelligence must defined terms external behavior, internal structure. However, critical test requires machine imitate humans. Aeronautical engineering texts, wrote, define goal field making machines fly exactly like pigeons fool pigeons. AI founder John McCarthy agreed, writing Artificial intelligence not, definition, simulation human intelligence. McCarthy defines intelligence computational part ability achieve goals world. Another AI founder, Marvin Minsky, similarly describes ability solve hard problems. The leading AI textbook defines study agents perceive environment take actions maximize chances achieving defined goals. These definitions view intelligence terms welldefined problems welldefined solutions, difficulty problem performance program direct measures intelligence machineand philosophical discussion required, may even possible. Another definition adopted Google, major practitioner field AI. This definition stipulates ability systems synthesize information manifestation intelligence, similar way defined biological intelligence. Some authors suggested practice, definition AI vague difficult define, contention whether classical algorithms categorised AI, many companies early 2020s AI boom using term marketing buzzword, often even actually use AI material way. Evaluating approaches AI No established unifying theory paradigm guided AI research history. The unprecedented success statistical machine learning 2010s eclipsed approaches much sources, especially business world, use term artificial intelligence mean machine learning neural networks. This approach mostly subsymbolic, soft narrow. Critics argue questions may revisited future generations AI researchers. Symbolic AI limits Symbolic AI GOFAI simulated highlevel conscious reasoning people use solve puzzles, express legal reasoning mathematics. They highly successful intelligent tasks algebra IQ tests. In 1960s, Newell Simon proposed physical symbol systems hypothesis A physical symbol system necessary sufficient means general intelligent action. However, symbolic approach failed many tasks humans solve easily, learning, recognizing object commonsense reasoning. Moravecs paradox discovery highlevel intelligent tasks easy AI, low level instinctive tasks extremely difficult. Philosopher Hubert Dreyfus argued since 1960s human expertise depends unconscious instinct rather conscious symbol manipulation, feel situation, rather explicit symbolic knowledge. Although arguments ridiculed ignored first presented, eventually, AI research came agree him. The issue resolved subsymbolic reasoning make many inscrutable mistakes human intuition does, algorithmic bias. Critics Noam Chomsky argue continuing research symbolic AI still necessary attain general intelligence, part subsymbolic AI move away explainable AI difficult impossible understand modern statistical AI program made particular decision. The emerging field neurosymbolic artificial intelligence attempts bridge two approaches. Neat vs. scruffy Neats hope intelligent behavior described using simple, elegant principles logic, optimization, neural networks. Scruffies expect necessarily requires solving large number unrelated problems. Neats defend programs theoretical rigor, scruffies rely mainly incremental testing see work. This issue actively discussed 1970s 1980s, eventually seen irrelevant. Modern AI elements both. Soft vs. hard computing Finding provably correct optimal solution intractable many important problems. Soft computing set techniques, including genetic algorithms, fuzzy logic neural networks, tolerant imprecision, uncertainty, partial truth approximation. Soft computing introduced late 1980s successful AI programs 21st century examples soft computing neural networks. Narrow vs. general AI AI researchers divided whether pursue goals artificial general intelligence superintelligence directly solve many specific problems possible narrow AI hopes solutions lead indirectly fields longterm goals. General intelligence difficult define difficult measure, modern AI verifiable successes focusing specific problems specific solutions. The subfield artificial general intelligence studies area exclusively. Machine consciousness, sentience, mind The philosophy mind know whether machine mind, consciousness mental states, sense human beings do. This issue considers internal experiences machine, rather external behavior. Mainstream AI research considers issue irrelevant affect goals field build machines solve problems using intelligence. Russell Norvig add additional project making machine conscious exactly way humans one equipped take on. However, question become central philosophy mind. It also typically central question issue artificial intelligence fiction. Consciousness David Chalmers identified two problems understanding mind, named hard easy problems consciousness. The easy problem understanding brain processes signals, makes plans controls behavior. The hard problem explaining feels feel like anything all, assuming right thinking truly feel like something Dennetts consciousness illusionism says illusion. While human information processing easy explain, human subjective experience difficult explain. For example, easy imagine colorblind person learned identify objects field view red, clear would required person know red looks like. Computationalism functionalism Computationalism position philosophy mind human mind information processing system thinking form computing. Computationalism argues relationship mind body similar identical relationship software hardware thus may solution mindbody problem. This philosophical position inspired work AI researchers cognitive scientists 1960s originally proposed philosophers Jerry Fodor Hilary Putnam. Philosopher John Searle characterized position strong AI The appropriately programmed computer right inputs outputs would thereby mind exactly sense human beings minds. Searle challenges claim Chinese room argument, attempts show even computer capable perfectly simulating human behavior would mind. AI welfare rights It difficult impossible reliably evaluate whether advanced AI sentient ability feel, so, degree. But significant chance given machine feel suffer, may entitled certain rights welfare protection measures, similarly animals. Sapience set capacities related high intelligence, discernment selfawareness may provide another moral basis AI rights. Robot rights also sometimes proposed practical way integrate autonomous agents society. In 2017, European Union considered granting electronic personhood capable AI systems. Similarly legal status companies, would conferred rights also responsibilities. Critics argued 2018 granting rights AI systems would downplay importance human rights, legislation focus user needs rather speculative futuristic scenarios. They also noted robots lacked autonomy take part society own. Progress AI increased interest topic. Proponents AI welfare rights often argue AI sentience, emerges, would particularly easy deny. They warn may moral blind spot analogous slavery factory farming, could lead largescale suffering sentient AI created carelessly exploited. Future Superintelligence singularity A superintelligence hypothetical agent would possess intelligence far surpassing brightest gifted human mind. If research artificial general intelligence produced sufficiently intelligent software, might able reprogram improve itself. The improved software would even better improving itself, leading I. J. Good called intelligence explosion Vernor Vinge called singularity. However, technologies cannot improve exponentially indefinitely, typically follow Sshaped curve, slowing reach physical limits technology do. Transhumanism Robot designer Hans Moravec, cyberneticist Kevin Warwick inventor Ray Kurzweil predicted humans machines may merge future cyborgs capable powerful either. This idea, called transhumanism, roots writings Aldous Huxley Robert Ettinger. Edward Fredkin argues artificial intelligence next step evolution, idea first proposed Samuel Butlers Darwin among Machines far back 1863, expanded upon George Dyson 1998 book Darwin Among Machines The Evolution Global Intelligence. Decomputing Arguments decomputing raised Dan McQuillan Resisting AI An Antifascist Approach Artificial Intelligence, 2022, meaning opposition sweeping application expansion artificial intelligence. Similar degrowth approach criticizes AI outgrowth systemic issues capitalist world live in. Arguing different future possible, distance people reduced increased AI intermediaries. In fiction Thoughtcapable artificial beings appeared storytelling devices since antiquity, persistent theme science fiction. A common trope works began Mary Shelleys Frankenstein, human creation becomes threat masters. This includes works Arthur C. Clarkes Stanley Kubricks 2001 A Space Odyssey 1968, HAL 9000, murderous computer charge Discovery One spaceship, well The Terminator 1984 The Matrix 1999. In contrast, rare loyal robots Gort The Day Earth Stood Still 1951 Bishop Aliens 1986 less prominent popular culture. Isaac Asimov introduced Three Laws Robotics many stories, notably Multivac superintelligent computer. Asimovs laws often brought lay discussions machine ethics almost artificial intelligence researchers familiar Asimovs laws popular culture, generally consider laws useless many reasons, one ambiguity. Several works use AI force us confront fundamental question makes us human, showing us artificial beings ability feel, thus suffer. This appears Karel \u010capeks R.U.R., films A.I. Artificial Intelligence Ex Machina, well novel Do Androids Dream Electric Sheep?, Philip K. Dick. Dick considers idea understanding human subjectivity altered technology created artificial intelligence. See also Artificial intelligence elections Use impact AI political elections Artificial intelligence content detection Software detect AIgenerated content Behavior selection algorithm Algorithm selects actions intelligent agents Business process automation Automation business processes Casebased reasoning Process solving new problems based solutions similar past problems Computational intelligence Ability computer learn specific task data experimental observation Digital immortality Hypothetical concept storing personality digital form Emergent algorithm Algorithm exhibiting emergent behavior Female gendering AI technologies Gender biases digital technologyPages displaying short descriptions redirect targets Glossary artificial intelligence List definitions terms concepts commonly used study artificial intelligence Intelligence amplification Use information technology augment human intelligence Intelligent agent Software agent acts autonomously Mind uploading Hypothetical process digitally emulating brain Organoid intelligence Use brain cells brain organoids intelligent computing Robotic process automation Form business process automation technology The Last Day novel 1967 Welsh science fiction novel Welsh science novel Owain Owain Wetware computer Computer composed organic material Explanatory notes References AI textbooks The two widely used textbooks 2023 see Open Syllabus Russell, Stuart J. Norvig, Peter 2021. Artificial Intelligence A Modern Approach 4th ed.. Hoboken Pearson. ISBN 9780134610993. LCCN 20190474. Rich, Elaine Knight, Kevin Nair, Shivashankar B 2010. Artificial Intelligence 3rd ed.. New Delhi Tata McGraw Hill India. ISBN 9780070087705. The four widely used AI textbooks 2008 Other textbooks Ertel, Wolfgang 2017. Introduction Artificial Intelligence 2nd ed.. Springer. ISBN 9783319584867. Ciaramella, Alberto Ciaramella, Marco 2024. Introduction Artificial Intelligence data analysis generative AI 1st ed.. Intellisemantic Editions. ISBN 9788894787603. History AI Other sources Further reading External links Artificial Intelligence. Internet Encyclopedia Philosophy."}, {"page_content": "Natural language processing NLP subfield computer science especially artificial intelligence. It primarily concerned providing computers ability process data encoded natural language thus closely related information retrieval, knowledge representation computational linguistics, subfield linguistics. Major tasks natural language processing speech recognition, text classification, naturallanguage understanding, naturallanguage generation. History Natural language processing roots 1950s. Already 1950, Alan Turing published article titled Computing Machinery Intelligence proposed called Turing test criterion intelligence, though time articulated problem separate artificial intelligence. The proposed test includes task involves automated interpretation generation natural language. Symbolic NLP 1950s early 1990s The premise symbolic NLP wellsummarized John Searles Chinese room experiment Given collection rules e.g., Chinese phrasebook, questions matching answers, computer emulates natural language understanding NLP tasks applying rules data confronts. 1950s The Georgetown experiment 1954 involved fully automatic translation sixty Russian sentences English. The authors claimed within three five years, machine translation would solved problem. However, real progress much slower, ALPAC report 1966, found ten years research failed fulfill expectations, funding machine translation dramatically reduced. Little research machine translation conducted America though research continued elsewhere, Japan Europe late 1980s first statistical machine translation systems developed. 1960s Some notably successful natural language processing systems developed 1960s SHRDLU, natural language system working restricted blocks worlds restricted vocabularies, ELIZA, simulation Rogerian psychotherapist, written Joseph Weizenbaum 1964 1966. Using almost information human thought emotion, ELIZA sometimes provided startlingly humanlike interaction. When patient exceeded small knowledge base, ELIZA might provide generic response, example, responding My head hurts Why say head hurts?. Ross Quillians successful work natural language demonstrated vocabulary twenty words, would fit computer memory time. 1970s During 1970s, many programmers began write conceptual ontologies, structured realworld information computerunderstandable data. Examples MARGIE Schank, 1975, SAM Cullingford, 1978, PAM Wilensky, 1978, TaleSpin Meehan, 1976, QUALM Lehnert, 1977, Politics Carbonell, 1979, Plot Units Lehnert 1981. During time, first chatterbots written e.g., PARRY. 1980s The 1980s early 1990s mark heyday symbolic methods NLP. Focus areas time included research rulebased parsing e.g., development HPSG computational operationalization generative grammar, morphology e.g., twolevel morphology, semantics e.g., Lesk algorithm, reference e.g., within Centering Theory areas natural language understanding e.g., Rhetorical Structure Theory. Other lines research continued, e.g., development chatterbots Racter Jabberwacky. An important development eventually led statistical turn 1990s rising importance quantitative evaluation period. Statistical NLP 1990spresent Up 1980s, natural language processing systems based complex sets handwritten rules. Starting late 1980s, however, revolution natural language processing introduction machine learning algorithms language processing. This due steady increase computational power see Moores law gradual lessening dominance Chomskyan theories linguistics e.g. transformational grammar, whose theoretical underpinnings discouraged sort corpus linguistics underlies machinelearning approach language processing. 1990s Many notable early successes statistical methods NLP occurred field machine translation, due especially work IBM Research, IBM alignment models. These systems able take advantage existing multilingual textual corpora produced Parliament Canada European Union result laws calling translation governmental proceedings official languages corresponding systems government. However, systems depended corpora specifically developed tasks implemented systems, often continues major limitation success systems. As result, great deal research gone methods effectively learning limited amounts data. 2000s With growth web, increasing amounts raw unannotated language data become available since mid1990s. Research thus increasingly focused unsupervised semisupervised learning algorithms. Such algorithms learn data handannotated desired answers using combination annotated nonannotated data. Generally, task much difficult supervised learning, typically produces less accurate results given amount input data. However, enormous amount nonannotated data available including, among things, entire content World Wide Web, often make worse efficiency algorithm used low enough time complexity practical. 2003 word ngram model, time best statistical algorithm, outperformed multilayer perceptron single hidden layer context length several words, trained 14 million words, Bengio et al. 2010 Tom\u00e1\u0161 Mikolov PhD student Brno University Technology coauthors applied simple recurrent neural network single hidden layer language modelling, following years went develop Word2vec. In 2010s, representation learning deep neural networkstyle featuring many hidden layers machine learning methods became widespread natural language processing. That popularity due partly flurry results showing techniques achieve stateoftheart results many natural language tasks, e.g., language modeling parsing. This increasingly important medicine healthcare, NLP helps analyze notes text electronic health records would otherwise inaccessible study seeking improve care protect patient privacy. Approaches Symbolic, statistical, neural networks Symbolic approach, i.e., handcoding set rules manipulating symbols, coupled dictionary lookup, historically first approach used AI general NLP particular writing grammars devising heuristic rules stemming. Machine learning approaches, include statistical neural networks, hand, many advantages symbolic approach statistical neural networks methods focus common cases extracted corpus texts, whereas rulebased approach needs provide rules rare cases common ones equally. language models, produced either statistical neural networks methods, robust unfamiliar e.g. containing words structures seen erroneous input e.g. misspelled words words accidentally omitted comparison rulebased systems, also costly produce. larger probabilistic language model is, accurate becomes, contrast rulebased systems gain accuracy increasing amount complexity rules leading intractability problems. Rulebased systems commonly used amount training data insufficient successfully apply machine learning methods, e.g., machine translation lowresource languages provided Apertium system, preprocessing NLP pipelines, e.g., tokenization, postprocessing transforming output NLP pipelines, e.g., knowledge extraction syntactic parses. Statistical approach In late 1980s mid1990s, statistical approach ended period AI winter, caused inefficiencies rulebased approaches. The earliest decision trees, producing systems hard ifthen rules, still similar old rulebased approaches. Only introduction hidden Markov models, applied partofspeech tagging, announced end old rulebased approach. Neural networks A major drawback statistical methods require elaborate feature engineering. Since 2015, statistical approach replaced neural networks approach, using semantic networks word embeddings capture semantic properties words. Intermediate tasks e.g., partofspeech tagging dependency parsing needed anymore. Neural machine translation, based thennewly invented sequencetosequence transformations, made obsolete intermediate steps, word alignment, previously necessary statistical machine translation. Common NLP tasks The following list commonly researched tasks natural language processing. Some tasks direct realworld applications, others commonly serve subtasks used aid solving larger tasks. Though natural language processing tasks closely intertwined, subdivided categories convenience. A coarse division given below. Text speech processing Optical character recognition OCR Given image representing printed text, determine corresponding text. Speech recognition Given sound clip person people speaking, determine textual representation speech. This opposite text speech one extremely difficult problems colloquially termed AIcomplete see above. In natural speech hardly pauses successive words, thus speech segmentation necessary subtask speech recognition see below. In spoken languages, sounds representing successive letters blend process termed coarticulation, conversion analog signal discrete characters difficult process. Also, given words language spoken people different accents, speech recognition software must able recognize wide variety input identical terms textual equivalent. Speech segmentation Given sound clip person people speaking, separate words. A subtask speech recognition typically grouped it. Texttospeech Given text, transform units produce spoken representation. Texttospeech used aid visually impaired. Word segmentation Tokenization Tokenization process used text analysis divides text individual words word fragments. This technique results two key components word index tokenized text. The word index list maps unique words specific numerical identifiers, tokenized text replaces word corresponding numerical token. These numerical tokens used various deep learning methods. For language like English, fairly trivial, since words usually separated spaces. However, written languages like Chinese, Japanese Thai mark word boundaries fashion, languages text segmentation significant task requiring knowledge vocabulary morphology words language. Sometimes process also used cases like bag words BOW creation data mining. Morphological analysis Lemmatization The task removing inflectional endings return base dictionary form word also known lemma. Lemmatization another technique reducing words normalized form. But case, transformation actually uses dictionary map words actual form. Morphological segmentation Separate words individual morphemes identify class morphemes. The difficulty task depends greatly complexity morphology i.e., structure words language considered. English fairly simple morphology, especially inflectional morphology, thus often possible ignore task entirely simply model possible forms word e.g., open, opens, opened, opening separate words. In languages Turkish Meitei, highly agglutinated Indian language, however, approach possible, dictionary entry thousands possible word forms. Partofspeech tagging Given sentence, determine part speech POS word. Many words, especially common ones, serve multiple parts speech. For example, book noun book table verb book flight set noun, verb adjective least five different parts speech. Stemming The process reducing inflected sometimes derived words base form e.g., close root closed, closing, close, closer etc.. Stemming yields similar results lemmatization, grounds rules, dictionary. Syntactic analysis Grammar induction Generate formal grammar describes languages syntax. Sentence breaking also known sentence boundary disambiguation Given chunk text, find sentence boundaries. Sentence boundaries often marked periods punctuation marks, characters serve purposes e.g., marking abbreviations. Parsing Determine parse tree grammatical analysis given sentence. The grammar natural languages ambiguous typical sentences multiple possible analyses perhaps surprisingly, typical sentence may thousands potential parses seem completely nonsensical human. There two primary types parsing dependency parsing constituency parsing. Dependency parsing focuses relationships words sentence marking things like primary objects predicates, whereas constituency parsing focuses building parse tree using probabilistic contextfree grammar PCFG see also stochastic grammar. Lexical semantics individual words context Lexical semantics What computational meaning individual words context? Distributional semantics How learn semantic representations data? Named entity recognition NER Given stream text, determine items text map proper names, people places, type name e.g. person, location, organization. Although capitalization aid recognizing named entities languages English, information cannot aid determining type named entity, case, often inaccurate insufficient. For example, first letter sentence also capitalized, named entities often span several words, capitalized. Furthermore, many languages nonWestern scripts e.g. Chinese Arabic capitalization all, even languages capitalization may consistently use distinguish names. For example, German capitalizes nouns, regardless whether names, French Spanish capitalize names serve adjectives. Another name task token classification. Sentiment analysis see also Multimodal sentiment analysis Sentiment analysis computational method used identify classify emotional intent behind text. This technique involves analyzing text determine whether expressed sentiment positive, negative, neutral. Models sentiment classification typically utilize inputs word ngrams, Term FrequencyInverse Document Frequency TFIDF features, handgenerated features, employ deep learning models designed recognize longterm shortterm dependencies text sequences. The applications sentiment analysis diverse, extending tasks categorizing customer reviews various online platforms. Terminology extraction The goal terminology extraction automatically extract relevant terms given corpus. Wordsense disambiguation WSD Many words one meaning select meaning makes sense context. For problem, typically given list words associated word senses, e.g. dictionary online resource WordNet. Entity linking Many wordstypically proper namesrefer named entities select entity famous individual, location, company, etc. referred context. Relational semantics semantics individual sentences Relationship extraction Given chunk text, identify relationships among named entities e.g. married whom. Semantic parsing Given piece text typically sentence, produce formal representation semantics, either graph e.g., AMR parsing accordance logical formalism e.g., DRT parsing. This challenge typically includes aspects several elementary NLP tasks semantics e.g., semantic role labelling, wordsense disambiguation extended include fullfledged discourse analysis e.g., discourse analysis, coreference see Natural language understanding below. Semantic role labelling see also implicit semantic role labelling Given single sentence, identify disambiguate semantic predicates e.g., verbal frames, identify classify frame elements semantic roles. Discourse semantics beyond individual sentences Coreference resolution Given sentence larger chunk text, determine words mentions refer objects entities. Anaphora resolution specific example task, specifically concerned matching pronouns nouns names refer. The general task coreference resolution also includes identifying socalled bridging relationships involving referring expressions. For example, sentence He entered Johns house front door, front door referring expression bridging relationship identified fact door referred front door Johns house rather structure might also referred to. Discourse analysis This rubric includes several related tasks. One task discourse parsing, i.e., identifying discourse structure connected text, i.e. nature discourse relationships sentences e.g. elaboration, explanation, contrast. Another possible task recognizing classifying speech acts chunk text e.g. yesno question, content question, statement, assertion, etc.. Implicit semantic role labelling Given single sentence, identify disambiguate semantic predicates e.g., verbal frames explicit semantic roles current sentence see Semantic role labelling above. Then, identify semantic roles explicitly realized current sentence, classify arguments explicitly realized elsewhere text specified, resolve former local text. A closely related task zero anaphora resolution, i.e., extension coreference resolution prodrop languages. Recognizing textual entailment Given two text fragments, determine one true entails other, entails others negation, allows either true false. Topic segmentation recognition Given chunk text, separate segments devoted topic, identify topic segment. Argument mining The goal argument mining automatic extraction identification argumentative structures natural language text aid computer programs. Such argumentative structures include premise, conclusions, argument scheme relationship main subsidiary argument, main counterargument within discourse. Higherlevel NLP applications Automatic summarization text summarization Produce readable summary chunk text. Often used provide summaries text known type, research papers, articles financial section newspaper. Grammatical error correction Grammatical error detection correction involves great bandwidth problems levels linguistic analysis phonologyorthography, morphology, syntax, semantics, pragmatics. Grammatical error correction impactful since affects hundreds millions people use acquire English second language. It thus subject number shared tasks since 2011. As far orthography, morphology, syntax certain aspects semantics concerned, due development powerful neural language models GPT2, 2019 considered largely solved problem marketed various commercial applications. Logic translation Translate text natural language formal logic. Machine translation MT Automatically translate text one human language another. This one difficult problems, member class problems colloquially termed AIcomplete, i.e. requiring different types knowledge humans possess grammar, semantics, facts real world, etc. solve properly. Naturallanguage understanding NLU Convert chunks text formal representations firstorder logic structures easier computer programs manipulate. Natural language understanding involves identification intended semantic multiple possible semantics derived natural language expression usually takes form organized notations natural language concepts. Introduction creation language metamodel ontology efficient however empirical solutions. An explicit formalization natural language semantics without confusions implicit assumptions closedworld assumption CWA vs. openworld assumption, subjective YesNo vs. objective TrueFalse expected construction basis semantics formalization. Naturallanguage generation NLG Convert information computer databases semantic intents readable human language. Book generation Not NLP task proper extension natural language generation NLP tasks creation fullfledged books. The first machinegenerated book created rulebased system 1984 Racter, The policemans beard halfconstructed. The first published work neural network published 2018, 1 Road, marketed novel, contains sixty million words. Both systems basically elaborate nonsensical semanticsfree language models. The first machinegenerated science book published 2019 Beta Writer, LithiumIon Batteries, Springer, Cham. Unlike Racter 1 Road, grounded factual knowledge based text summarization. Document AI A Document AI platform sits top NLP technology enabling users prior experience artificial intelligence, machine learning NLP quickly train computer extract specific data need different document types. NLPpowered Document AI enables nontechnical teams quickly access information hidden documents, example, lawyers, business analysts accountants. Dialogue management Computer systems intended converse human. Question answering Given humanlanguage question, determine answer. Typical questions specific right answer What capital Canada?, sometimes openended questions also considered What meaning life?. Texttoimage generation Given description image, generate image matches description. Texttoscene generation Given description scene, generate 3D model scene. Texttovideo Given description video, generate video matches description. General tendencies possible future directions Based longstanding trends field, possible extrapolate future directions NLP. As 2020, three trends among topics longstanding series CoNLL Shared Tasks observed Interest increasingly abstract, cognitive aspects natural language 19992001 shallow parsing, 200203 named entity recognition, 200609201718 dependency syntax, 200405200809 semantic role labelling, 201112 coreference, 201516 discourse parsing, 2019 semantic parsing. Increasing interest multilinguality, and, potentially, multimodality English since 1999 Spanish, Dutch since 2002 German since 2003 Bulgarian, Danish, Japanese, Portuguese, Slovenian, Swedish, Turkish since 2006 Basque, Catalan, Chinese, Greek, Hungarian, Italian, Turkish since 2007 Czech since 2009 Arabic since 2012 2017 40 languages 2018 60100 languages Elimination symbolic representations rulebased supervised towards weakly supervised methods, representation learning endtoend systems Cognition Most higherlevel NLP applications involve aspects emulate intelligent behaviour apparent comprehension natural language. More broadly speaking, technical operationalization increasingly advanced aspects cognitive behaviour represents one developmental trajectories NLP see trends among CoNLL shared tasks above. Cognition refers mental action process acquiring knowledge understanding thought, experience, senses. Cognitive science interdisciplinary, scientific study mind processes. Cognitive linguistics interdisciplinary branch linguistics, combining knowledge research psychology linguistics. Especially age symbolic NLP, area computational linguistics maintained strong ties cognitive studies. As example, George Lakoff offers methodology build natural language processing NLP algorithms perspective cognitive science, along findings cognitive linguistics, two defining aspects Apply theory conceptual metaphor, explained Lakoff understanding one idea, terms another provides idea intent author. For example, consider English word big. When used comparison That big tree, authors intent imply tree physically large relative trees authors experience. When used metaphorically Tomorrow big day, authors intent imply importance. The intent behind usages, like She big person, remain somewhat ambiguous person cognitive NLP algorithm alike without additional information. Assign relative measures meaning word, phrase, sentence piece text based information presented piece text analyzed, e.g., means probabilistic contextfree grammar PCFG. The mathematical equation algorithms presented US Patent 9269353 R M M k e n N P M M k e n N 1 2 P M M k e n N P F k e n N , k e n N , k e n N displaystyle RMMtoken_NPMMtoken_Ntimes frac 12dleftsum _iddPMMtoken_Ntimes PFtoken_Ni,token_N,token_Ni_iright Where RMM relative measure meaning token block text, sentence, phrase word N number tokens analyzed PMM probable measure meaning based corpora non zero location token along sequence N tokens PF probability function specific language Ties cognitive linguistics part historical heritage NLP, less frequently addressed since statistical turn 1990s. Nevertheless, approaches develop cognitive models towards technically operationalizable frameworks pursued context various frameworks, e.g., cognitive grammar, functional grammar, construction grammar, computational psycholinguistics cognitive neuroscience e.g., ACTR, however, limited uptake mainstream NLP measured presence major conferences ACL. More recently, ideas cognitive NLP revived approach achieve explainability, e.g., notion cognitive AI. Likewise, ideas cognitive NLP inherent neural models multimodal NLP although rarely made explicit developments artificial intelligence, specifically tools technologies using large language model approaches new directions artificial general intelligence based free energy principle British neuroscientist theoretician University College London Karl J. Friston. See also References Further reading External links Media related Natural language processing Wikimedia Commons"}, {"page_content": "Hangzhou DeepSeek Artificial Intelligence Basic Technology Research Co., Ltd., business DeepSeek, Chinese artificial intelligence company develops large language models LLMs. Based Hangzhou, Zhejiang, owned funded Chinese hedge fund HighFlyer. DeepSeek founded July 2023 Liang Wenfeng, cofounder HighFlyer, also serves CEO companies. The company launched eponymous chatbot alongside DeepSeekR1 model January 2025. Released MIT License, DeepSeekR1 provides responses comparable contemporary large language models, OpenAIs GPT4o o1. Its training cost reported significantly lower LLMs. The company claims trained V3 model US6 million compared 100 million OpenAIs GPT4 2023, approximately onetenth computing power used Metas comparable model, Llama 3.1. DeepSeeks success larger established rivals described upending AI. DeepSeeks models open weight, provides less freedom modification true opensource software. The company reportedly recruits AI researchers top Chinese universities hires outside computer science field diversify models knowledge abilities. The low cost training running language model attributed Chinese firms lack access Nvidia chipsets, restricted US part ongoing trade war two countries. This breakthrough reducing expenses increasing efficiency maintaining models performance power quality AI industry sent shockwaves market. It threatened dominance AI leaders like Nvidia contributed largest drop single company US stock market history, Nvidia lost 600 billion market value. History Founding early years 20162023 In February 2016, HighFlyer cofounded AI enthusiast Liang Wenfeng, trading since 20072008 financial crisis attending Zhejiang University. The company began stocktrading using GPUdependent deep learning model 21 October 2016. Prior this, used CPUbased models, mainly linear models. Most trading driven AI end 2017. In 2019, Liang established HighFlyer hedge fund focused developing using AI trading algorithms. By 2021, HighFlyer exclusively used AI trading, often using Nvidia chips. Initial computing cluster FireFlyer began construction 2019 finished 2020, cost 200 million yuan. It contained 1,100 GPUs interconnected rate 200 Gbits. It retired 1.5 years operation. In 2021, Liang began stockpiling Nvidia GPUs AI project. According 36Kr, Liang acquired 10,000 Nvidia A100 GPUs United States restricted chip sales China. Computing cluster FireFlyer 2 began construction 2021 budget 1 billion yuan. It reported 2022, FireFlyer 2s capacity used 96, totaling 56.74 million GPU hours. 27 used support scientific computing outside company. During 2022, FireFlyer 2 5000 PCIe A100 GPUs 625 nodes, containing 8 GPUs. At time, exclusively used PCIe instead DGX version A100, since time models trained could fit within single 40 GB GPU VRAM, need higher bandwidth DGX i.e. required data parallelism model parallelism. Later, incorporated NVLinks NCCL, train larger models required model parallelism. On 14 April 2023, HighFlyer announced start artificial general intelligence lab dedicated research developing AI tools separate HighFlyers financial business. Incorporated 17 July 2023, HighFlyer investor backer, lab became company, DeepSeek. Venture capital firms reluctant provide funding, considered unlikely venture would able quickly generate exit. On 16 May 2023, company Beijing DeepSeek Artificial Intelligence Basic Technology Research Company, Limited. incorporated. It later taken 100 control Hangzhou DeepSeek Artificial Intelligence Basic Technology Research Co., Ltd, incorporated 2 months after. Model releases 2023present On 2 November 2023, DeepSeek released first model, DeepSeek Coder. On 29 November 2023, DeepSeek released DeepSeekLLM series models. section 5 On 9 January 2024, released 2 DeepSeekMoE models Base Chat. In April 2024, released 3 DeepSeekMath models Base, Instruct, RL. DeepSeekV2 released May 2024. In June 2024, DeepSeekCoder V2 series released. DeepSeek V2.5 released September updated December 2024. On 20 November 2024, DeepSeekR1LitePreview became accessible via API chat. In December 2024, company released base model DeepSeekV3Base chat model DeepSeekV3. On 20 January 2025, DeepSeek released DeepSeek chatbot, based DeepSeekR1 model, free charge iOS Android 27 January, DeepSeek surpassed ChatGPT downloaded freeware app iOS App Store United States, causing Nvidias share price drop 18. Company operation Based Hangzhou, Zhejiang, DeepSeek owned funded Chinese hedge fund HighFlyer cofounder Liang Wenfeng, also serves CEO. As May 2024, Liang owned 84 DeepSeek two shell corporations. Strategy DeepSeek focused research detailed plans commercialization. This allows technology avoid stringent provisions Chinas AI regulations, requiring consumerfacing technology comply government controls information. DeepSeeks hiring preferences target technical abilities rather work experience new hires either recent university graduates developers whose AI careers less established. Likewise, company recruits individuals without computer science background help technology understand knowledge areas, poetry Chinas notoriously difficult college admissions exams Gaokao. Training framework HighFlyerDeepSeek operates least two computing clusters, FireFlyer \u8424\u706b\u4e00\u53f7 FireFlyer 2 \u8424\u706b\u4e8c\u53f7. FireFlyer 2 consists codesigned software hardware architecture. On hardware side, Nvidia GPUs use 200 Gbps interconnects. The cluster divided two zones, platform supports crosszone tasks. The network topology two fat trees, chosen high bisection bandwidth. On software side 3FS FireFlyer File System A distributed parallel file system, specifically designed asynchronous random reads. It uses Direct IO RDMA Read. In contrast standard Buffered IO, Direct IO cache data. Caching useless case, since data read random, isnt reused. hfreduce Library asynchronous communication, originally designed replace Nvidia Collective Communication Library NCCL. It mainly used allreduce, especially gradients backpropagation. It asynchronously run CPU avoid blocking kernels GPU. It uses twotree broadcast like NCCL. hfai.nn Software library commonly used operators neural network training, similar torch.nn PyTorch. HaiScale Distributed Data Parallel DDP Parallel training library implements various forms parallelism Data Parallelism DP, Pipeline Parallelism PP, Tensor Parallelism TP, Experts Parallelism EP, Fully Sharded Data Parallel FSDP Zero Redundancy Optimizer ZeRO. It similar PyTorch DDP, uses NCCL backend. HAI Platform Various applications task scheduling, fault handling, disaster recovery. As 2022, FireFlyer 2 5000 PCIe A100 GPUs 625 nodes, containing 8 GPUs. They later incorporated NVLinks NCCL, train larger models required model parallelism. Development release history The first DeepSeek models essentially Llama, dense decoderonly Transformers. Later models incorporated multihead latent attention MLA, Mixture Experts MoE, KV caching. A decoderonly Transformer consists multiple identical decoder layers. Each layers features two main components attention layer FeedForward network FFN layer. In attention layer, traditional multihead attention mechanism enhanced multihead latent attention. This update introduces compressed latent vectors boost performance reduce memory usage inference. Meanwhile, FFN layer adopts variant mixture experts MoE approach, effectively doubling number experts compared standard implementations. It distinguishes two types experts shared experts, always active encapsulate general knowledge, routed experts, select activated capture specialized information. Consider current sequence n tokens input. To predict next token based current input, attention mechanism involves extensive calculations matrices, including query Q, key K, value V matrices. The dimensions Q, K, V determined current number tokens models embedding size. Once new token generated, autoregressive procedure appends end input sequence, transformer layers repeat matrix calculation next token. A mathematical analysis reveals new token introduces new query, key, value vector, appended Q, K, V, respectively. Appending new vectors K V matrices sufficient calculating next token prediction. Consequently, storing current K V matrices memory saves time avoiding recalculation attention matrix. This feature known KV caching. This technique effectively reduces computational cost inference. Overview models DeepSeeks models open weight, provides less freedom modification true open source software. DeepSeek Coder DeepSeek Coder series 8 models, 4 pretrained Base 4 instructionfinetuned Instruct. They 16K context lengths. The model made sourceavailable DeepSeek License, includes open responsible downstream usage restrictions. The training program Pretraining 1.8T tokens 87 source code, 10 coderelated English GitHub markdown Stack Exchange, 3 codeunrelated Chinese. Longcontext pretraining 200B tokens. This extends context length 4K 16K. This produced Base models. Supervised finetuning SFT 2B tokens instruction data. This produced Instruct models. They trained clusters A100 H800 Nvidia GPUs, connected InfiniBand, NVLink, NVSwitch. DeepSeekLLM The DeepSeekLLM series released November 2023. It 7B 67B parameters Base Chat forms. DeepSeeks accompanying paper claimed benchmark results higher Llama 2 opensource LLMs time. section 5 The model code sourceavailable DeepSeek License. The architecture essentially Llama series. They used prenorm decoderonly Transformer RMSNorm normalization, SwiGLU feedforward layers, rotary positional embedding RoPE, groupedquery attention GQA. Both vocabulary size 102,400 bytelevel BPE context length 4096. They trained 2 trillion tokens English Chinese text obtained deduplicating Common Crawl. The Chat versions two Base models released concurrently, obtained training Base supervised finetuning SFT followed direct policy optimization DPO. MoE DeepSeekMoE models Base Chat, 16B parameters 2.7B activated per token, 4K context length. The training essentially DeepSeekLLM 7B, trained part training dataset. They claimed performance comparable 16B MoE 7B nonMoE. It variant standard sparselygated MoE, shared experts always queried, routed experts might be. They found help expert balancing. In standard MoE, experts become overused, others rarely used, wasting space. Attempting balance expert usage causes experts replicate capacity. They proposed shared experts learn core capacities often used, let routed experts learn peripheral capacities rarely used. Math DeepSeekMath includes 3 models Base, Instruct, RL. Math trained follows Initialize previously pretrained DeepSeekCoder Base v1.5 7B. Further pretrain 500B tokens 6 DeepSeekMath Corpus, 4 AlgebraicStack, 10 arXiv, 20 GitHub code, 10 Common Crawl. This produced Base. Train instructionfollowing model SFT Base 776K math problems tooluseintegrated stepbystep solutions. This produced Instruct. Reinforcement learning RL The reward model process reward model PRM trained Base according MathShepherd method. This reward model used train Instruct using Group Relative Policy Optimization GRPO dataset 144K math questions related GSM8K MATH. The reward model continuously updated training avoid reward hacking. This resulted RL. V2 In May 2024, DeepSeek released DeepSeekV2 series. The series includes 4 models, 2 base models DeepSeekV2, DeepSeekV2 Lite 2 chatbots Chat. The two larger models trained follows Pretrain dataset 8.1T tokens, using 12 Chinese tokens English ones. Extend context length 4K 128K using YaRN. This resulted DeepSeekV2. SFT 1.2M instances helpfulness 0.3M safety. This resulted Chat SFT, released. RL using GRPO two stages. The first stage trained solve math coding problems. This stage used 1 reward model, trained compiler feedback coding groundtruth labels math. The second stage trained helpful, safe, follow rules. This stage used 3 reward models. The helpfulness safety reward models trained human preference data. The rulebased reward model manually programmed. All trained reward models initialized Chat SFT. This resulted released version Chat. They opted 2staged RL, found RL reasoning data unique characteristics different RL general data. For example, RL reasoning could improve training steps. The two V2Lite models smaller, trained similarly. DeepSeekV2 LiteChat underwent SFT, RL. They trained Lite version help research development MLA DeepSeekMoE. Architecturally, V2 models significantly different DeepSeek LLM series. They changed standard attention mechanism lowrank approximation called multihead latent attention MLA, used previously published mixture experts MoE variant. The Financial Times reported cheaper peers price 2 RMB every million output tokens. The University Waterloo Tiger Labs leaderboard ranked DeepSeekV2 seventh LLM ranking. The DeepSeekCoder V2 series included V2Base, V2LiteBase, V2Instruct, V20LiteInstruct.. Training Base models initialized corresponding intermediate checkpoints pretraining 4.2T tokens version end pretraining, pretrained 6T tokens, contextextended 128K context length. DeepSeekCoder DeepSeekMath used generate 20K coderelated 30K mathrelated instruction data, combined instruction dataset 300M tokens. This used SFT. RL GRPO. The reward math problems computed comparing groundtruth label. The reward code problems generated reward model trained predict whether program would pass unit tests. DeepSeekV2.5 made combining DeepSeekV2Chat DeepSeekCoderV2Instruct. V3 DeepSeekV3Base DeepSeekV3 chat model use essentially architecture V2 addition multitoken prediction, optionally decodes extra tokens faster less accurately. Training Pretraining 14.8T tokens multilingual corpus, mostly English Chinese. It contained higher ratio math programming pretraining dataset V2. Extend context length twice, 4K 32K 128K, using YaRN. This produced DeepSeekV3Base. SFT 2 epochs 1.5M samples reasoning math, programming, logic nonreasoning creative writing, roleplay, simple question answering data. Reasoning data generated expert models. Nonreasoning data generated DeepSeekV2.5 checked humans. The expert models trained starting unspecified base model, SFT problem, original response data, synthetic system prompt, prompt, problem, R1 response data generated internal DeepSeekR1Lite model. The system prompt asked R1 reflect verify thinking. Then expert models RL using undisclosed reward function. Each expert model trained generate synthetic reasoning data one specific domain math, programming, logic. Expert models used instead R1 itself, since output R1 suffered overthinking, poor formatting, excessive length. Modelbased reward models made starting SFT checkpoint V3, finetuning human preference data containing final reward chainofthought leading final reward. The reward model produced reward signals questions objective freeform answers, questions without objective answers creative writing. An SFT checkpoint V3 trained GRPO using reward models rulebased reward. The rulebased reward computed math problems final answer put box, programming problems unit tests. This produced DeepSeekV3. The DeepSeek team performed extensive lowlevel engineering improve efficiency. They used mixedprecision arithmetic. Much forward pass performed 8bit floating point numbers 5E2M 5bit exponent 2bit mantissa rather standard 32bit, requiring special GEMM routines accumulate accurately. They used custom 12bit float E5M6 inputs linear layers attention modules. Optimizer states 16bit BF16. They minimized communication latency extensively overlapping computation communication, dedicating 20 streaming multiprocessors 132 per H800 interGPU communication. They lowered communication rearranging every 10 minutes exact machine expert avoid querying certain machines often others, adding auxiliary loadbalancing losses training loss function, loadbalancing techniques. After training, deployed clusters H800 GPUs. The 8 H800 GPUs within cluster connected NVLink, clusters connected InfiniBand. The cost discussed called misleading, covers parts true cost. Benchmark tests show V3 outperformed Llama 3.1 Qwen 2.5 matching GPT4o Claude 3.5 Sonnet. R1 In January 2025, DeepSeek released DeepSeekR1 model MIT License. DeepSeekR1LitePreview trained logical inference, mathematical reasoning, realtime problemsolving. DeepSeek claimed exceeded performance OpenAI o1 benchmarks American Invitational Mathematics Examination AIME MATH. However, The Wall Street Journal reported 15 problems 2024 edition AIME, o1 model reached solution faster. DeepSeekR1 DeepSeekR1Zero initialized DeepSeekV3Base share architecture. DeepSeekR1Distill models instead initialized pretrained openweight models, including LLaMA Qwen, finetuned synthetic data generated R1. DeepSeekR1Zero trained exclusively using GRPO RL without SFT. Unlike previous versions, used modelbased reward. All reward functions rulebased, mainly two types types specified accuracy rewards format rewards. Accuracy reward checking whether boxed answer correct math whether code passes tests programming. Format reward checking whether model puts thinking trace within think...think tag. R1Zero issues readability mixing languages. R1 trained address issues improve reasoning SFT DeepSeekV3Base thousands coldstart data standard format special_tokenreasoning_processspecial_tokensummary, designed improve model output readability. Apply GRPO RL process R1Zero, adding language consistency reward encourage respond monolingually. This produced un released internal model. Synthesize 600K reasoning data internal model, rejection sampling i.e. generated reasoning wrong final answer, removed. Synthesize 200K nonreasoning data writing, factual QA, selfcognition, translation using DeepSeekV3. SFT DeepSeekV3Base 800K synthetic data 2 epochs. Apply GRPO RL process R1Zero rulebased reward reasoning tasks, also modelbased reward nonreasoning tasks, helpfulness, harmlessness. This produced DeepSeekR1. Distilled models trained SFT 800K data synthesized DeepSeekR1, similar way step 3. They trained RL. R2, successor R1, originally planned release early May 2025, release schedule accelerated. Significance DeepSeeks success larger established rivals described upending AI. The DeepSeekR1 model provides responses comparable contemporary large language models, OpenAIs GPT4o o1. Its training cost reported significantly lower LLMs. The company claims trained V3, predecessor R1, US6 million compared 100 million OpenAIs GPT4 2023, approximately one tenth computing power used Metas comparable model, LLaMA 3.1. Domestically, DeepSeek models offer performance low price, become catalyst Chinas AI model price war. It dubbed Pinduoduo AI, Chinese tech giants ByteDance, Tencent, Baidu, Alibaba cut price AI models. Despite low price, profitable compared moneylosing rivals. See also DeepSeek chatbot Chatbot developed DeepSeek Artificial intelligence industry China OpenAI Artificial intelligence research organization Jevons paradox Efficiency leads increased demand Notes References External links Official website DeepSeek GitHub DeepSeek Hugging Face Official API documentation Anthology DeepSeek papers Research blog HighFlyer"}, {"page_content": "Deep learning subset machine learning focuses utilizing neural networks perform tasks classification, regression, representation learning. The field takes inspiration biological neuroscience centered around stacking artificial neurons layers training process data. The adjective deep refers use multiple layers ranging three several hundred thousands network. Methods used either supervised, semisupervised unsupervised. Some common deep learning network architectures include fully connected networks, deep belief networks, recurrent neural networks, convolutional neural networks, generative adversarial networks, transformers, neural radiance fields. These architectures applied fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection board game programs, produced results comparable cases surpassing human expert performance. Early forms neural networks inspired information processing distributed communication nodes biological systems, particularly human brain. However, current neural networks intend model brain function organisms, generally seen lowquality models purpose. Overview Most modern deep learning models based multilayered neural networks convolutional neural networks transformers, although also include propositional formulas latent variables organized layerwise deep generative models nodes deep belief networks deep Boltzmann machines. Fundamentally, deep learning refers class machine learning algorithms hierarchy layers used transform input data progressively abstract composite representation. For example, image recognition model, raw input may image represented tensor pixels. The first representational layer may attempt identify basic shapes lines circles, second layer may compose encode arrangements edges, third layer may encode nose eyes, fourth layer may recognize image contains face. Importantly, deep learning process learn features optimally place level own. Prior deep learning, machine learning techniques often involved handcrafted feature engineering transform data suitable representation classification algorithm operate on. In deep learning approach, features handcrafted model discovers useful feature representations data automatically. This eliminate need handtuning example, varying numbers layers layer sizes provide different degrees abstraction. The word deep deep learning refers number layers data transformed. More precisely, deep learning systems substantial credit assignment path CAP depth. The CAP chain transformations input output. CAPs describe potentially causal connections input output. For feedforward neural network, depth CAPs network number hidden layers plus one output layer also parameterized. For recurrent neural networks, signal may propagate layer once, CAP depth potentially unlimited. No universally agreedupon threshold depth divides shallow learning deep learning, researchers agree deep learning involves CAP depth higher two. CAP depth two shown universal approximator sense emulate function. Beyond that, layers add function approximator ability network. Deep models CAP two able extract better features shallow models hence, extra layers help learning features effectively. Deep learning architectures constructed greedy layerbylayer method. Deep learning helps disentangle abstractions pick features improve performance. Deep learning algorithms applied unsupervised learning tasks. This important benefit unlabeled data abundant labeled data. Examples deep structures trained unsupervised manner deep belief networks. The term Deep Learning introduced machine learning community Rina Dechter 1986, artificial neural networks Igor Aizenberg colleagues 2000, context Boolean threshold neurons. Although history appearance apparently complicated. Interpretations Deep neural networks generally interpreted terms universal approximation theorem probabilistic inference. The classic universal approximation theorem concerns capacity feedforward neural networks single hidden layer finite size approximate continuous functions. In 1989, first proof published George Cybenko sigmoid activation functions generalised feedforward multilayer architectures 1991 Kurt Hornik. Recent work also showed universal approximation also holds nonbounded activation functions Kunihiko Fukushimas rectified linear unit. The universal approximation theorem deep neural networks concerns capacity networks bounded width depth allowed grow. Lu et al. proved width deep neural network ReLU activation strictly larger input dimension, network approximate Lebesgue integrable function width smaller equal input dimension, deep neural network universal approximator. The probabilistic interpretation derives field machine learning. It features inference, well optimization concepts training testing, related fitting generalization, respectively. More specifically, probabilistic interpretation considers activation nonlinearity cumulative distribution function. The probabilistic interpretation led introduction dropout regularizer neural networks. The probabilistic interpretation introduced researchers including Hopfield, Widrow Narendra popularized surveys one Bishop. History Before 1980 There two types artificial neural network ANN feedforward neural network FNN multilayer perceptron MLP recurrent neural networks RNN. RNNs cycles connectivity structure, FNNs dont. In 1920s, Wilhelm Lenz Ernst Ising created Ising model essentially nonlearning RNN architecture consisting neuronlike threshold elements. In 1972, Shunichi Amari made architecture adaptive. His learning RNN republished John Hopfield 1982. Other early recurrent neural networks published Kaoru Nakano 1971. Already 1948, Alan Turing produced work Intelligent Machinery published lifetime, containing ideas related artificial evolution learning RNNs. Frank Rosenblatt 1958 proposed perceptron, MLP 3 layers input layer, hidden layer randomized weights learn, output layer. He later published 1962 book also introduced variants computer experiments, including version fourlayer perceptrons adaptive preterminal networks last two layers learned weights credits H. D. Block B. W. Knight. section 16 The book cites earlier network R. D. Joseph 1960 functionally equivalent variation fourlayer system book mentions Joseph 30 times. Should Joseph therefore considered originator proper adaptive multilayer perceptrons learning hidden units? Unfortunately, learning algorithm functional one, fell oblivion. The first working deep learning algorithm Group method data handling, method train arbitrarily deep neural networks, published Alexey Ivakhnenko Lapa 1965. They regarded form polynomial regression, generalization Rosenblatts perceptron. A 1971 paper described deep network eight layers trained method, based layer layer training regression analysis. Superfluous hidden units pruned using separate validation set. Since activation functions nodes KolmogorovGabor polynomials, also first deep networks multiplicative units gates. The first deep learning multilayer perceptron trained stochastic gradient descent published 1967 Shunichi Amari. In computer experiments conducted Amaris student Saito, five layer MLP two modifiable layers learned internal representations classify nonlinearily separable pattern classes. Subsequent developments hardware hyperparameter tunings made endtoend stochastic gradient descent currently dominant training technique. In 1969, Kunihiko Fukushima introduced ReLU rectified linear unit activation function. The rectifier become popular activation function deep learning. Deep learning architectures convolutional neural networks CNNs convolutional layers downsampling layers began Neocognitron introduced Kunihiko Fukushima 1979, though trained backpropagation. Backpropagation efficient application chain rule derived Gottfried Wilhelm Leibniz 1673 networks differentiable nodes. The terminology backpropagating errors actually introduced 1962 Rosenblatt, know implement this, although Henry J. Kelley continuous precursor backpropagation 1960 context control theory. The modern form backpropagation first published Seppo Linnainmaas master thesis 1970. G.M. Ostrovski et al. republished 1971. Paul Werbos applied backpropagation neural networks 1982 1974 PhD thesis, reprinted 1994 book, yet describe algorithm. In 1986, David E. Rumelhart et al. popularised backpropagation cite original work. 1980s2000s The time delay neural network TDNN introduced 1987 Alex Waibel apply CNN phoneme recognition. It used convolutions, weight sharing, backpropagation. In 1988, Wei Zhang applied backpropagationtrained CNN alphabet recognition. In 1989, Yann LeCun et al. created CNN called LeNet recognizing handwritten ZIP codes mail. Training required 3 days. In 1990, Wei Zhang implemented CNN optical computing hardware. In 1991, CNN applied medical image object segmentation breast cancer detection mammograms. LeNet5 1998, 7level CNN Yann LeCun et al., classifies digits, applied several banks recognize handwritten numbers checks digitized 32x32 pixel images. Recurrent neural networks RNN developed 1980s. Recurrence used sequence processing, recurrent network unrolled, mathematically resembles deep feedforward layer. Consequently, similar properties issues, developments mutual influences. In RNN, two early influential works Jordan network 1986 Elman network 1990, applied RNN study problems cognitive psychology. In 1980s, backpropagation work well deep learning long credit assignment paths. To overcome problem, 1991, J\u00fcrgen Schmidhuber proposed hierarchy RNNs pretrained one level time selfsupervised learning RNN tries predict next input, next unexpected input RNN below. This neural history compressor uses predictive coding learn internal representations multiple selforganizing time scales. This substantially facilitate downstream deep learning. The RNN hierarchy collapsed single RNN, distilling higher level chunker network lower level automatizer network. In 1993, neural history compressor solved Very Deep Learning task required 1000 subsequent layers RNN unfolded time. The P ChatGPT refers pretraining. Sepp Hochreiters diploma thesis 1991 implemented neural history compressor, identified analyzed vanishing gradient problem. Hochreiter proposed recurrent residual connections solve vanishing gradient problem. This led long shortterm memory LSTM, published 1995. LSTM learn deep learning tasks long credit assignment paths require memories events happened thousands discrete time steps before. That LSTM yet modern architecture, required forget gate, introduced 1999, became standard RNN architecture. In 1991, J\u00fcrgen Schmidhuber also published adversarial neural networks contest form zerosum game, one networks gain networks loss. The first network generative model models probability distribution output patterns. The second network learns gradient descent predict reactions environment patterns. This called artificial curiosity. In 2014, principle used generative adversarial networks GANs. During 19851995, inspired statistical mechanics, several architectures methods developed Terry Sejnowski, Peter Dayan, Geoffrey Hinton, etc., including Boltzmann machine, restricted Boltzmann machine, Helmholtz machine, wakesleep algorithm. These designed unsupervised learning deep generative models. However, computationally expensive compared backpropagation. Boltzmann machine learning algorithm, published 1985, briefly popular eclipsed backpropagation algorithm 1986. p. 112 . A 1988 network became state art protein structure prediction, early application deep learning bioinformatics. Both shallow deep learning e.g., recurrent nets ANNs speech recognition explored many years. These methods never outperformed nonuniform internalhandcrafting Gaussian mixture modelHidden Markov model GMMHMM technology based generative models speech trained discriminatively. Key difficulties analyzed, including gradient diminishing weak temporal correlation structure neural predictive models. Additional difficulties lack training data limited computing power. Most speech recognition researchers moved away neural nets pursue generative modeling. An exception SRI International late 1990s. Funded US governments NSA DARPA, SRI researched speech speaker recognition. The speaker recognition team led Larry Heck reported significant success deep neural networks speech processing 1998 NIST Speaker Recognition benchmark. It deployed Nuance Verifier, representing first major industrial application deep learning. The principle elevating raw features handcrafted optimization first explored successfully architecture deep autoencoder raw spectrogram linear filterbank features late 1990s, showing superiority MelCepstral features contain stages fixed transformation spectrograms. The raw features speech, waveforms, later produced excellent largerscale results. 2000s Neural networks entered null, simpler models use taskspecific handcrafted features Gabor filters support vector machines SVMs became preferred choices 1990s 2000s, artificial neural networks computational cost lack understanding brain wires biological networks. In 2003, LSTM became competitive traditional speech recognizers certain tasks. In 2006, Alex Graves, Santiago Fern\u00e1ndez, Faustino Gomez, Schmidhuber combined connectionist temporal classification CTC stacks LSTMs. In 2009, became first RNN win pattern recognition contest, connected handwriting recognition. In 2006, publications Geoff Hinton, Ruslan Salakhutdinov, Osindero Teh deep belief networks developed generative modeling. They trained training one restricted Boltzmann machine, freezing training another one top first one, on, optionally finetuned using supervised backpropagation. They could model highdimensional probability distributions, distribution MNIST images, convergence slow. The impact deep learning industry began early 2000s, CNNs already processed estimated 10 20 checks written US, according Yann LeCun. Industrial applications deep learning largescale speech recognition started around 2010. The 2009 NIPS Workshop Deep Learning Speech Recognition motivated limitations deep generative models speech, possibility given capable hardware largescale data sets deep neural nets might become practical. It believed pretraining DNNs using generative models deep belief nets DBN would overcome main difficulties neural nets. However, discovered replacing pretraining large amounts training data straightforward backpropagation using DNNs large, contextdependent output layers produced error rates dramatically lower thenstateoftheart Gaussian mixture model GMMHidden Markov Model HMM also moreadvanced generative modelbased systems. The nature recognition errors produced two types systems characteristically different, offering technical insights integrate deep learning existing highly efficient, runtime speech decoding system deployed major speech recognition systems. Analysis around 20092010, contrasting GMM generative speech models vs. DNN models, stimulated early industrial investment deep learning speech recognition. That analysis done comparable performance less 1.5 error rate discriminative DNNs generative models. In 2010, researchers extended deep learning TIMIT large vocabulary speech recognition, adopting large output layers DNN based contextdependent HMM states constructed decision trees. Deep learning revolution The deep learning revolution started around CNN GPUbased computer vision. Although CNNs trained backpropagation around decades GPU implementations NNs years, including CNNs, faster implementations CNNs GPUs needed progress computer vision. Later, deep learning becomes widespread, specialized hardware algorithm optimizations developed specifically deep learning. A key advance deep learning revolution hardware advances, especially GPU. Some early work dated back 2004. In 2009, Raina, Madhavan, Andrew Ng reported 100M deep belief network trained 30 Nvidia GeForce GTX 280 GPUs, early demonstration GPUbased deep learning. They reported 70 times faster training. In 2011, CNN named DanNet Dan Ciresan, Ueli Meier, Jonathan Masci, Luca Maria Gambardella, J\u00fcrgen Schmidhuber achieved first time superhuman performance visual pattern recognition contest, outperforming traditional methods factor 3. It contests. They also showed maxpooling CNNs GPU improved performance significantly. In 2012, Andrew Ng Jeff Dean created FNN learned recognize higherlevel concepts, cats, watching unlabeled images taken YouTube videos. In October 2012, AlexNet Alex Krizhevsky, Ilya Sutskever, Geoffrey Hinton largescale ImageNet competition significant margin shallow machine learning methods. Further incremental improvements included VGG16 network Karen Simonyan Andrew Zisserman Googles Inceptionv3. The success image classification extended challenging task generating descriptions captions images, often combination CNNs LSTMs. In 2014, state art training deep neural network 20 30 layers. Stacking many layers led steep reduction training accuracy, known degradation problem. In 2015, two techniques developed train deep networks Highway Network published May 2015, residual neural network ResNet Dec 2015. ResNet behaves like opengated Highway Net. Around time, deep learning started impacting field art. Early examples included Google DeepDream 2015, neural style transfer 2015, based pretrained image classification neural networks, VGG19. Generative adversarial network GAN Ian Goodfellow et al., 2014 based J\u00fcrgen Schmidhubers principle artificial curiosity became state art generative modeling 20142018 period. Excellent image quality achieved Nvidias StyleGAN 2018 based Progressive GAN Tero Karras et al. Here GAN generator grown small large scale pyramidal fashion. Image generation GAN reached popular success, provoked discussions concerning deepfakes. Diffusion models 2015 eclipsed GANs generative modeling since then, systems DALLE 2 2022 Stable Diffusion 2022. In 2015, Googles speech recognition improved 49 LSTMbased model, made available Google Voice Search smartphone. Deep learning part stateoftheart systems various disciplines, particularly computer vision automatic speech recognition ASR. Results commonly used evaluation sets TIMIT ASR MNIST image classification, well range largevocabulary speech recognition tasks steadily improved. Convolutional neural networks superseded ASR LSTM. successful computer vision. Yoshua Bengio, Geoffrey Hinton Yann LeCun awarded 2018 Turing Award conceptual engineering breakthroughs made deep neural networks critical component computing. Neural networks Artificial neural networks ANNs connectionist systems computing systems inspired biological neural networks constitute animal brains. Such systems learn progressively improve ability tasks considering examples, generally without taskspecific programming. For example, image recognition, might learn identify images contain cats analyzing example images manually labeled cat cat using analytic results identify cats images. They found use applications difficult express traditional computer algorithm using rulebased programming. An ANN based collection connected units called artificial neurons, analogous biological neurons biological brain. Each connection synapse neurons transmit signal another neuron. The receiving postsynaptic neuron process signals signal downstream neurons connected it. Neurons may state, generally represented real numbers, typically 0 1. Neurons synapses may also weight varies learning proceeds, increase decrease strength signal sends downstream. Typically, neurons organized layers. Different layers may perform different kinds transformations inputs. Signals travel first input, last output layer, possibly traversing layers multiple times. The original goal neural network approach solve problems way human brain would. Over time, attention focused matching specific mental abilities, leading deviations biology backpropagation, passing information reverse direction adjusting network reflect information. Neural networks used variety tasks, including computer vision, speech recognition, machine translation, social network filtering, playing board video games medical diagnosis. As 2017, neural networks typically thousand million units millions connections. Despite number several order magnitude less number neurons human brain, networks perform many tasks level beyond humans e.g., recognizing faces, playing Go. Deep neural networks A deep neural network DNN artificial neural network multiple layers input output layers. There different types neural networks always consist components neurons, synapses, weights, biases, functions. These components whole function way mimics functions human brain, trained like ML algorithm. For example, DNN trained recognize dog breeds go given image calculate probability dog image certain breed. The user review results select probabilities network display certain threshold, etc. return proposed label. Each mathematical manipulation considered layer, complex DNN many layers, hence name deep networks. DNNs model complex nonlinear relationships. DNN architectures generate compositional models object expressed layered composition primitives. The extra layers enable composition features lower layers, potentially modeling complex data fewer units similarly performing shallow network. For instance, proved sparse multivariate polynomials exponentially easier approximate DNNs shallow networks. Deep architectures include many variants basic approaches. Each architecture found success specific domains. It always possible compare performance multiple architectures, unless evaluated data sets. DNNs typically feedforward networks data flows input layer output layer without looping back. At first, DNN creates map virtual neurons assigns random numerical values, weights, connections them. The weights inputs multiplied return output 0 1. If network accurately recognize particular pattern, algorithm would adjust weights. That way algorithm make certain parameters influential, determines correct mathematical manipulation fully process data. Recurrent neural networks, data flow direction, used applications language modeling. Long shortterm memory particularly effective use. Convolutional neural networks CNNs used computer vision. CNNs also applied acoustic modeling automatic speech recognition ASR. Challenges As ANNs, many issues arise naively trained DNNs. Two common issues overfitting computation time. DNNs prone overfitting added layers abstraction, allow model rare dependencies training data. Regularization methods Ivakhnenkos unit pruning weight decay \u2113 2 displaystyle ell _2 regularization sparsity \u2113 1 displaystyle ell _1 regularization applied training combat overfitting. Alternatively dropout regularization randomly omits units hidden layers training. This helps exclude rare dependencies. Another interesting recent development research models enough complexity estimation intrinsic complexity task modelled. This approach successfully applied multivariate time series prediction tasks traffic prediction. Finally, data augmented via methods cropping rotating smaller training sets increased size reduce chances overfitting. DNNs must consider many training parameters, size number layers number units per layer, learning rate, initial weights. Sweeping parameter space optimal parameters may feasible due cost time computational resources. Various tricks, batching computing gradient several training examples rather individual examples speed computation. Large processing capabilities manycore architectures GPUs Intel Xeon Phi produced significant speedups training, suitability processing architectures matrix vector computations. Alternatively, engineers may look types neural networks straightforward convergent training algorithms. CMAC cerebellar model articulation controller one kind neural network. It doesnt require learning rates randomized initial weights. The training process guaranteed converge one step new batch data, computational complexity training algorithm linear respect number neurons involved. Hardware Since 2010s, advances machine learning algorithms computer hardware led efficient methods training deep neural networks contain many layers nonlinear hidden units large output layer. By 2019, graphics processing units GPUs, often AIspecific enhancements, displaced CPUs dominant method training largescale commercial cloud AI . OpenAI estimated hardware computation used largest deep learning projects AlexNet 2012 AlphaZero 2017 found 300,000fold increase amount computation required, doublingtime trendline 3.4 months. Special electronic circuits called deep learning processors designed speed deep learning algorithms. Deep learning processors include neural processing units NPUs Huawei cellphones cloud computing servers tensor processing units TPU Google Cloud Platform. Cerebras Systems also built dedicated system handle large deep learning models, CS2, based largest processor industry, secondgeneration Wafer Scale Engine WSE2. Atomically thin semiconductors considered promising energyefficient deep learning hardware basic device structure used logic operations data storage. In 2020, Marega et al. published experiments largearea active channel material developing logicinmemory devices circuits based floatinggate fieldeffect transistors FGFETs. In 2021, J. Feldmann et al. proposed integrated photonic hardware accelerator parallel convolutional processing. The authors identify two key advantages integrated photonics electronic counterparts 1 massively parallel data transfer wavelength division multiplexing conjunction frequency combs, 2 extremely high data modulation speeds. Their system execute trillions multiplyaccumulate operations per second, indicating potential integrated photonics dataheavy AI applications. Applications Automatic speech recognition Largescale automatic speech recognition first convincing successful case deep learning. LSTM RNNs learn Very Deep Learning tasks involve multisecond intervals containing speech events separated thousands discrete time steps, one time step corresponds 10 ms. LSTM forget gates competitive traditional speech recognizers certain tasks. The initial success speech recognition based smallscale recognition tasks based TIMIT. The data set contains 630 speakers eight major dialects American English, speaker reads 10 sentences. Its small size lets many configurations tried. More importantly, TIMIT task concerns phonesequence recognition, which, unlike wordsequence recognition, allows weak phone bigram language models. This lets strength acoustic modeling aspects speech recognition easily analyzed. The error rates listed below, including early results measured percent phone error rates PER, summarized since 1991. The debut DNNs speaker recognition late 1990s speech recognition around 20092011 LSTM around 20032007, accelerated progress eight major areas Scaleupout accelerated DNN training decoding Sequence discriminative training Feature processing deep models solid understanding underlying mechanisms Adaptation DNNs related deep models Multitask transfer learning DNNs related deep models CNNs design best exploit domain knowledge speech RNN rich LSTM variants Other types deep models including tensorbased models integrated deep generativediscriminative models. All major commercial speech recognition systems e.g., Microsoft Cortana, Xbox, Skype Translator, Amazon Alexa, Google Now, Apple Siri, Baidu iFlyTek voice search, range Nuance speech products, etc. based deep learning. Image recognition A common evaluation set image classification MNIST database data set. MNIST composed handwritten digits includes 60,000 training examples 10,000 test examples. As TIMIT, small size lets users test multiple configurations. A comprehensive list results set available. Deep learningbased image recognition become superhuman, producing accurate results human contestants. This first occurred 2011 recognition traffic signs, 2014, recognition human faces. Deep learningtrained vehicles interpret 360 camera views. Another example Facial Dysmorphology Novel Analysis FDNA used analyze cases human malformation connected large database genetic syndromes. Visual art processing Closely related progress made image recognition increasing application deep learning techniques various visual art tasks. DNNs proven capable, example, identifying style period given painting Neural Style Transfer capturing style given artwork applying visually pleasing manner arbitrary photograph video generating striking imagery based random visual input fields. Natural language processing Neural networks used implementing language models since early 2000s. LSTM helped improve machine translation language modeling. Other key techniques field negative sampling word embedding. Word embedding, word2vec, thought representational layer deep learning architecture transforms atomic word positional representation word relative words dataset position represented point vector space. Using word embedding RNN input layer allows network parse sentences phrases using effective compositional vector grammar. A compositional vector grammar thought probabilistic context free grammar PCFG implemented RNN. Recursive autoencoders built atop word embeddings assess sentence similarity detect paraphrasing. Deep neural architectures provide best results constituency parsing, sentiment analysis, information retrieval, spoken language understanding, machine translation, contextual entity linking, writing style recognition, namedentity recognition token classification, text classification, others. Recent developments generalize word embedding sentence embedding. Google Translate GT uses large endtoend long shortterm memory LSTM network. Google Neural Machine Translation GNMT uses examplebased machine translation method system learns millions examples. It translates whole sentences time, rather pieces. Google Translate supports one hundred languages. The network encodes semantics sentence rather simply memorizing phrasetophrase translations. GT uses English intermediate language pairs. Drug discovery toxicology A large percentage candidate drugs fail win regulatory approval. These failures caused insufficient efficacy ontarget effect, undesired interactions offtarget effects, unanticipated toxic effects. Research explored use deep learning predict biomolecular targets, offtargets, toxic effects environmental chemicals nutrients, household products drugs. AtomNet deep learning system structurebased rational drug design. AtomNet used predict novel candidate biomolecules disease targets Ebola virus multiple sclerosis. In 2017 graph neural networks used first time predict various properties molecules large toxicology data set. In 2019, generative neural networks used produce molecules validated experimentally way mice. Customer relationship management Deep reinforcement learning used approximate value possible direct marketing actions, defined terms RFM variables. The estimated value function shown natural interpretation customer lifetime value. Recommendation systems Recommendation systems used deep learning extract meaningful features latent factor model contentbased music journal recommendations. Multiview deep learning applied learning user preferences multiple domains. The model uses hybrid collaborative contentbased approach enhances recommendations multiple tasks. Bioinformatics An autoencoder ANN used bioinformatics, predict gene ontology annotations genefunction relationships. In medical informatics, deep learning used predict sleep quality based data wearables predictions health complications electronic health record data. Deep neural networks shown unparalleled performance predicting protein structure, according sequence amino acids make up. In 2020, AlphaFold, deeplearning based system, achieved level accuracy significantly higher previous computational methods. Deep Neural Network Estimations Deep neural networks used estimate entropy stochastic process called Neural Joint Entropy Estimator NJEE. Such estimation provides insights effects input random variables independent random variable. Practically, DNN trained classifier maps input vector matrix X output probability distribution possible classes random variable Y, given input X. For example, image classification tasks, NJEE maps vector pixels color values probabilities possible image classes. In practice, probability distribution Y obtained Softmax layer number nodes equal alphabet size Y. NJEE uses continuously differentiable activation functions, conditions universal approximation theorem holds. It shown method provides strongly consistent estimator outperforms methods case large alphabet sizes. Medical image analysis Deep learning shown produce competitive results medical application cancer cell classification, lesion detection, organ segmentation image enhancement. Modern deep learning tools demonstrate high accuracy detecting various diseases helpfulness use specialists improve diagnosis efficiency. Mobile advertising Finding appropriate mobile audience mobile advertising always challenging, since many data points must considered analyzed target segment created used ad serving ad server. Deep learning used interpret large, manydimensioned advertising datasets. Many data points collected requestserveclick internet advertising cycle. This information form basis machine learning improve ad selection. Image restoration Deep learning successfully applied inverse problems denoising, superresolution, inpainting, film colorization. These applications include learning methods Shrinkage Fields Effective Image Restoration trains image dataset, Deep Image Prior, trains image needs restoration. Financial fraud detection Deep learning successfully applied financial fraud detection, tax evasion detection, antimoney laundering. Materials science In November 2023, researchers Google DeepMind Lawrence Berkeley National Laboratory announced developed AI system known GNoME. This system contributed materials science discovering 2 million new materials within relatively short timeframe. GNoME employs deep learning techniques efficiently explore potential material structures, achieving significant increase identification stable inorganic crystal structures. The systems predictions validated autonomous robotic experiments, demonstrating noteworthy success rate 71. The data newly discovered materials publicly available Materials Project database, offering researchers opportunity identify materials desired properties various applications. This development implications future scientific discovery integration AI material science research, potentially expediting material innovation reducing costs product development. The use AI deep learning suggests possibility minimizing eliminating manual lab experiments allowing scientists focus design analysis unique compounds. Military The United States Department Defense applied deep learning train robots new tasks observation. Partial differential equations Physics informed neural networks used solve partial differential equations forward inverse problems data driven manner. One example reconstructing fluid flow governed NavierStokes equations. Using physics informed neural networks require often expensive mesh generation conventional CFD methods rely on. Deep backward stochastic differential equation method Deep backward stochastic differential equation method numerical method combines deep learning Backward stochastic differential equation BSDE. This method particularly useful solving highdimensional problems financial mathematics. By leveraging powerful function approximation capabilities deep neural networks, deep BSDE addresses computational challenges faced traditional numerical methods highdimensional settings. Specifically, traditional methods like finite difference methods Monte Carlo simulations often struggle curse dimensionality, computational cost increases exponentially number dimensions. Deep BSDE methods, however, employ deep neural networks approximate solutions highdimensional partial differential equations PDEs, effectively reducing computational burden. In addition, integration Physicsinformed neural networks PINNs deep BSDE framework enhances capability embedding underlying physical laws directly neural network architecture. This ensures solutions fit data also adhere governing stochastic differential equations. PINNs leverage power deep learning respecting constraints imposed physical models, resulting accurate reliable solutions financial mathematics problems. Image reconstruction Image reconstruction reconstruction underlying images imagerelated measurements. Several works showed better superior performance deep learning methods compared analytical methods various applications, e.g., spectral imaging ultrasound imaging. Weather prediction Traditional weather prediction systems solve complex system partial differential equations. GraphCast deep learning based model, trained long history weather data predict weather patterns change time. It able predict weather conditions 10 days globally, detailed level, minute, precision similar state art systems. Epigenetic clock An epigenetic clock biochemical test used measure age. Galkin et al. used deep neural networks train epigenetic aging clock unprecedented accuracy using 6,000 blood samples. The clock uses information 1000 CpG sites predicts people certain conditions older healthy controls IBD, frontotemporal dementia, ovarian cancer, obesity. The aging clock planned released public use 2021 Insilico Medicine spinoff company Deep Longevity. Relation human cognitive brain development Deep learning closely related class theories brain development specifically, neocortical development proposed cognitive neuroscientists early 1990s. These developmental theories instantiated computational models, making predecessors deep learning systems. These developmental models share property various proposed learning dynamics brain e.g., wave nerve growth factor support selforganization somewhat analogous neural networks utilized deep learning models. Like neocortex, neural networks employ hierarchy layered filters layer considers information prior layer operating environment, passes output possibly original input, layers. This process yields selforganizing stack transducers, welltuned operating environment. A 1995 description stated, ...the infants brain seems organize influence waves socalled trophicfactors ... different regions brain become connected sequentially, one layer tissue maturing another whole brain mature. A variety approaches used investigate plausibility deep learning models neurobiological perspective. On one hand, several variants backpropagation algorithm proposed order increase processing realism. Other researchers argued unsupervised forms deep learning, based hierarchical generative models deep belief networks, may closer biological reality. In respect, generative neural network models related neurobiological evidence samplingbased processing cerebral cortex. Although systematic comparison human brain organization neuronal encoding deep networks yet established, several analogies reported. For example, computations performed deep learning units could similar actual neurons neural populations. Similarly, representations developed deep learning models similar measured primate visual system singleunit population levels. Commercial activity Facebooks AI lab performs tasks automatically tagging uploaded pictures names people them. Googles DeepMind Technologies developed system capable learning play Atari video games using pixels data input. In 2015 demonstrated AlphaGo system, learned game Go well enough beat professional Go player. Google Translate uses neural network translate 100 languages. In 2017, Covariant.ai launched, focuses integrating deep learning factories. As 2008, researchers The University Texas Austin UT developed machine learning framework called Training Agent Manually via Evaluative Reinforcement, TAMER, proposed new methods robots computer programs learn perform tasks interacting human instructor. First developed TAMER, new algorithm called Deep TAMER later introduced 2018 collaboration U.S. Army Research Laboratory ARL UT researchers. Deep TAMER used deep learning provide robot ability learn new tasks observation. Using Deep TAMER, robot learned task human trainer, watching video streams observing human perform task inperson. The robot later practiced task help coaching trainer, provided feedback good job bad job. Criticism comment Deep learning attracted criticism comment, cases outside field computer science. Theory A main criticism concerns lack theory surrounding methods. Learning common deep architectures implemented using wellunderstood gradient descent. However, theory surrounding algorithms, contrastive divergence less clear. e.g., Does converge? If so, fast? What approximating? Deep learning methods often looked black box, confirmations done empirically, rather theoretically. In reference idea artistic sensitivity might inherent relatively low levels cognitive hierarchy, published series graphic representations internal states deep 2030 layers neural networks attempting discern within essentially random data images trained demonstrate visual appeal original research notice received well 1,000 comments, subject time frequently accessed article The Guardians website. Errors Some deep learning architectures display problematic behaviors, confidently classifying unrecognizable images belonging familiar category ordinary images 2014 misclassifying minuscule perturbations correctly classified images 2013. Goertzel hypothesized behaviors due limitations internal representations limitations would inhibit integration heterogeneous multicomponent artificial general intelligence AGI architectures. These issues may possibly addressed deep learning architectures internally form states homologous imagegrammar decompositions observed entities events. Learning grammar visual linguistic training data would equivalent restricting system commonsense reasoning operates concepts terms grammatical production rules basic goal human language acquisition artificial intelligence AI. Cyber threat As deep learning moves lab world, research experience show artificial neural networks vulnerable hacks deception. By identifying patterns systems use function, attackers modify inputs ANNs way ANN finds match human observers would recognize. For example, attacker make subtle changes image ANN finds match even though image looks human nothing like search target. Such manipulation termed adversarial attack. In 2016 researchers used one ANN doctor images trial error fashion, identify anothers focal points, thereby generate images deceived it. The modified images looked different human eyes. Another group showed printouts doctored images photographed successfully tricked image classification system. One defense reverse image search, possible fake image submitted site TinEye find instances it. A refinement search using parts image, identify images piece may taken. Another group showed certain psychedelic spectacles could fool facial recognition system thinking ordinary people celebrities, potentially allowing one person impersonate another. In 2017 researchers added stickers stop signs caused ANN misclassify them. ANNs however trained detect attempts deception, potentially leading attackers defenders arms race similar kind already defines malware defense industry. ANNs trained defeat ANNbased antimalware software repeatedly attacking defense malware continually altered genetic algorithm tricked antimalware retaining ability damage target. In 2016, another group demonstrated certain sounds could make Google Now voice command system open particular web address, hypothesized could serve stepping stone attacks e.g., opening web page hosting driveby malware. In data poisoning, false data continually smuggled machine learning systems training set prevent achieving mastery. Data collection ethics The deep learning systems trained using supervised learning often rely data created andor annotated humans. It argued lowpaid clickwork Amazon Mechanical Turk regularly deployed purpose, also implicit forms human microwork often recognized such. The philosopher Rainer M\u00fchlhoff distinguishes five types machinic capture human microwork generate training data 1 gamification embedding annotation computation tasks flow game, 2 trapping tracking e.g. CAPTCHAs image recognition clicktracking Google search results pages, 3 exploitation social motivations e.g. tagging faces Facebook obtain labeled facial images, 4 information mining e.g. leveraging quantifiedself devices activity trackers 5 clickwork. See also Applications artificial intelligence Comparison deep learning software Compressed sensing Differentiable programming Echo state network List artificial intelligence projects Liquid state machine List datasets machinelearning research Reservoir computing Scale space deep learning Sparse coding Stochastic parrot Topological deep learning References Further reading"}, {"page_content": "Artificial intelligence AI refers capability computational systems perform tasks typically associated human intelligence, learning, reasoning, problemsolving, perception, decisionmaking. It field research computer science develops studies methods software enable machines perceive environment use learning intelligence take actions maximize chances achieving defined goals. Such machines may called AIs. Highprofile applications AI include advanced web search engines e.g., Google Search recommendation systems used YouTube, Amazon, Netflix virtual assistants e.g., Google Assistant, Siri, Alexa autonomous vehicles e.g., Waymo generative creative tools e.g., ChatGPT AI art superhuman play analysis strategy games e.g., chess Go. However, many AI applications perceived AI A lot cutting edge AI filtered general applications, often without called AI something becomes useful enough common enough labeled AI anymore. Various subfields AI research centered around particular goals use particular tools. The traditional goals AI research include learning, reasoning, knowledge representation, planning, natural language processing, perception, support robotics. General intelligencethe ability complete task performed human least equal levelis among fields longterm goals. To reach goals, AI researchers adapted integrated wide range techniques, including search mathematical optimization, formal logic, artificial neural networks, methods based statistics, operations research, economics. AI also draws upon psychology, linguistics, philosophy, neuroscience, fields. Artificial intelligence founded academic discipline 1956, field went multiple cycles optimism throughout history, followed periods disappointment loss funding, known AI winters. Funding interest vastly increased 2012 deep learning outperformed previous AI techniques. This growth accelerated 2017 transformer architecture, early 2020s many billions dollars invested AI field experienced rapid ongoing progress become known AI boom. The emergence advanced generative AI midst AI boom ability create modify content exposed several unintended consequences harms present raised concerns risks AI longterm effects future, prompting discussions regulatory policies ensure safety benefits technology. Goals The general problem simulating creating intelligence broken subproblems. These consist particular traits capabilities researchers expect intelligent system display. The traits described received attention cover scope AI research. Reasoning problemsolving Early researchers developed algorithms imitated stepbystep reasoning humans use solve puzzles make logical deductions. By late 1980s 1990s, methods developed dealing uncertain incomplete information, employing concepts probability economics. Many algorithms insufficient solving large reasoning problems experience combinatorial explosion They become exponentially slower problems grow. Even humans rarely use stepbystep deduction early AI research could model. They solve problems using fast, intuitive judgments. Accurate efficient reasoning unsolved problem. Knowledge representation Knowledge representation knowledge engineering allow AI programs answer questions intelligently make deductions realworld facts. Formal knowledge representations used contentbased indexing retrieval, scene interpretation, clinical decision support, knowledge discovery mining interesting actionable inferences large databases, areas. A knowledge base body knowledge represented form used program. An ontology set objects, relations, concepts, properties used particular domain knowledge. Knowledge bases need represent things objects, properties, categories, relations objects situations, events, states, time causes effects knowledge knowledge know people know default reasoning things humans assume true told differently remain true even facts changing many aspects domains knowledge. Among difficult problems knowledge representation breadth commonsense knowledge set atomic facts average person knows enormous subsymbolic form commonsense knowledge much people know represented facts statements could express verbally. There also difficulty knowledge acquisition, problem obtaining knowledge AI applications. Planning decisionmaking An agent anything perceives takes actions world. A rational agent goals preferences takes actions make happen. In automated planning, agent specific goal. In automated decisionmaking, agent preferencesthere situations would prefer in, situations trying avoid. The decisionmaking agent assigns number situation called utility measures much agent prefers it. For possible action, calculate expected utility utility possible outcomes action, weighted probability outcome occur. It choose action maximum expected utility. In classical planning, agent knows exactly effect action be. In realworld problems, however, agent may certain situation unknown unobservable may know certain happen possible action deterministic. It must choose action making probabilistic guess reassess situation see action worked. In problems, agents preferences may uncertain, especially agents humans involved. These learned e.g., inverse reinforcement learning, agent seek information improve preferences. Information value theory used weigh value exploratory experimental actions. The space possible future actions situations typically intractably large, agents must take actions evaluate situations uncertain outcome be. A Markov decision process transition model describes probability particular action change state particular way reward function supplies utility state cost action. A policy associates decision possible state. The policy could calculated e.g., iteration, heuristic, learned. Game theory describes rational behavior multiple interacting agents used AI programs make decisions involve agents. Learning Machine learning study programs improve performance given task automatically. It part AI beginning. There several kinds machine learning. Unsupervised learning analyzes stream data finds patterns makes predictions without guidance. Supervised learning requires labeling training data expected answers, comes two main varieties classification program must learn predict category input belongs regression program must deduce numeric function based numeric input. In reinforcement learning, agent rewarded good responses punished bad ones. The agent learns choose responses classified good. Transfer learning knowledge gained one problem applied new problem. Deep learning type machine learning runs inputs biologically inspired artificial neural networks types learning. Computational learning theory assess learners computational complexity, sample complexity much data required, notions optimization. Natural language processing Natural language processing NLP allows programs read, write communicate human languages English. Specific problems include speech recognition, speech synthesis, machine translation, information extraction, information retrieval question answering. Early work, based Noam Chomskys generative grammar semantic networks, difficulty wordsense disambiguation unless restricted small domains called microworlds due common sense knowledge problem. Margaret Masterman believed meaning grammar key understanding languages, thesauri dictionaries basis computational language structure. Modern deep learning techniques NLP include word embedding representing words, typically vectors encoding meaning, transformers deep learning architecture using attention mechanism, others. In 2019, generative pretrained transformer GPT language models began generate coherent text, 2023, models able get humanlevel scores bar exam, SAT test, GRE test, many realworld applications. Perception Machine perception ability use input sensors cameras, microphones, wireless signals, active lidar, sonar, radar, tactile sensors deduce aspects world. Computer vision ability analyze visual input. The field includes speech recognition, image classification, facial recognition, object recognition,object tracking, robotic perception. Social intelligence Affective computing field comprises systems recognize, interpret, process, simulate human feeling, emotion, mood. For example, virtual assistants programmed speak conversationally even banter humorously makes appear sensitive emotional dynamics human interaction, otherwise facilitate humancomputer interaction. However, tends give na\u00efve users unrealistic conception intelligence existing computer agents. Moderate successes related affective computing include textual sentiment analysis and, recently, multimodal sentiment analysis, wherein AI classifies effects displayed videotaped subject. General intelligence A machine artificial general intelligence able solve wide variety problems breadth versatility similar human intelligence. Techniques AI research uses wide variety techniques accomplish goals above. Search optimization AI solve many problems intelligently searching many possible solutions. There two different kinds search used AI state space search local search. State space search State space search searches tree possible states try find goal state. For example, planning algorithms search trees goals subgoals, attempting find path target goal, process called meansends analysis. Simple exhaustive searches rarely sufficient realworld problems search space number places search quickly grows astronomical numbers. The result search slow never completes. Heuristics rules thumb help prioritize choices likely reach goal. Adversarial search used gameplaying programs, chess Go. It searches tree possible moves countermoves, looking winning position. Local search Local search uses mathematical optimization find solution problem. It begins form guess refines incrementally. Gradient descent type local search optimizes set numerical parameters incrementally adjusting minimize loss function. Variants gradient descent commonly used train neural networks, backpropagation algorithm. Another type local search evolutionary computation, aims iteratively improve set candidate solutions mutating recombining them, selecting fittest survive generation. Distributed search processes coordinate via swarm intelligence algorithms. Two popular swarm algorithms used search particle swarm optimization inspired bird flocking ant colony optimization inspired ant trails. Logic Formal logic used reasoning knowledge representation. Formal logic comes two main forms propositional logic operates statements true false uses logical connectives and, or, implies predicate logic also operates objects, predicates relations uses quantifiers Every X Y There Xs Ys. Deductive reasoning logic process proving new statement conclusion statements given assumed true premises. Proofs structured proof trees, nodes labelled sentences, children nodes connected parent nodes inference rules. Given problem set premises, problemsolving reduces searching proof tree whose root node labelled solution problem whose leaf nodes labelled premises axioms. In case Horn clauses, problemsolving search performed reasoning forwards premises backwards problem. In general case clausal form firstorder logic, resolution single, axiomfree rule inference, problem solved proving contradiction premises include negation problem solved. Inference Horn clause logic firstorder logic undecidable, therefore intractable. However, backward reasoning Horn clauses, underpins computation logic programming language Prolog, Turing complete. Moreover, efficiency competitive computation symbolic programming languages. Fuzzy logic assigns degree truth 0 1. It therefore handle propositions vague partially true. Nonmonotonic logics, including logic programming negation failure, designed handle default reasoning. Other specialized versions logic developed describe many complex domains. Probabilistic methods uncertain reasoning Many problems AI including reasoning, planning, learning, perception, robotics require agent operate incomplete uncertain information. AI researchers devised number tools solve problems using methods probability theory economics. Precise mathematical tools developed analyze agent make choices plan, using decision theory, decision analysis, information value theory. These tools include models Markov decision processes, dynamic decision networks, game theory mechanism design. Bayesian networks tool used reasoning using Bayesian inference algorithm, learning using expectationmaximization algorithm, planning using decision networks perception using dynamic Bayesian networks. Probabilistic algorithms also used filtering, prediction, smoothing, finding explanations streams data, thus helping perception systems analyze processes occur time e.g., hidden Markov models Kalman filters. Classifiers statistical learning methods The simplest AI applications divided two types classifiers e.g., shiny diamond, one hand, controllers e.g., diamond pick up, hand. Classifiers functions use pattern matching determine closest match. They finetuned based chosen examples using supervised learning. Each pattern also called observation labeled certain predefined class. All observations combined class labels known data set. When new observation received, observation classified based previous experience. There many kinds classifiers use. The decision tree simplest widely used symbolic machine learning algorithm. Knearest neighbor algorithm widely used analogical AI mid1990s, Kernel methods support vector machine SVM displaced knearest neighbor 1990s. The naive Bayes classifier reportedly widely used learner Google, due part scalability. Neural networks also used classifiers. Artificial neural networks An artificial neural network based collection nodes also known artificial neurons, loosely model neurons biological brain. It trained recognise patterns trained, recognise patterns fresh data. There input, least one hidden layer nodes output. Each node applies function weight crosses specified threshold, data transmitted next layer. A network typically called deep neural network least 2 hidden layers. Learning algorithms neural networks use local search choose weights get right output input training. The common training technique backpropagation algorithm. Neural networks learn model complex relationships inputs outputs find patterns data. In theory, neural network learn function. In feedforward neural networks signal passes one direction. Recurrent neural networks feed output signal back input, allows shortterm memories previous input events. Long short term memory successful network architecture recurrent networks. Perceptrons use single layer neurons deep learning uses multiple layers. Convolutional neural networks strengthen connection neurons close otherthis especially important image processing, local set neurons must identify edge network identify object. Deep learning Deep learning uses several layers neurons networks inputs outputs. The multiple layers progressively extract higherlevel features raw input. For example, image processing, lower layers may identify edges, higher layers may identify concepts relevant human digits, letters, faces. Deep learning profoundly improved performance programs many important subfields artificial intelligence, including computer vision, speech recognition, natural language processing, image classification, others. The reason deep learning performs well many applications known 2021. The sudden success deep learning 20122015 occur new discovery theoretical breakthrough deep neural networks backpropagation described many people, far back 1950s two factors incredible increase computer power including hundredfold increase speed switching GPUs availability vast amounts training data, especially giant curated datasets used benchmark testing, ImageNet. GPT Generative pretrained transformers GPT large language models LLMs generate text based semantic relationships words sentences. Textbased GPT models pretrained large corpus text Internet. The pretraining consists predicting next token token usually word, subword, punctuation. Throughout pretraining, GPT models accumulate knowledge world generate humanlike text repeatedly predicting next token. Typically, subsequent training phase makes model truthful, useful, harmless, usually technique called reinforcement learning human feedback RLHF. Current GPT models prone generating falsehoods called hallucinations, although reduced RLHF quality data. They used chatbots, allow people ask question request task simple text. Current models services include Gemini formerly Bard, ChatGPT, Grok, Claude, Copilot, LLaMA. Multimodal GPT models process different types data modalities images, videos, sound, text. Hardware software In late 2010s, graphics processing units GPUs increasingly designed AIspecific enhancements used specialized TensorFlow software replaced previously used central processing unit CPUs dominant means largescale commercial academic machine learning models training. Specialized programming languages Prolog used early AI research, generalpurpose programming languages like Python become predominant. The transistor density integrated circuits observed roughly double every 18 monthsa trend known Moores law, named Intel cofounder Gordon Moore, first identified it. Improvements GPUs even faster, trend sometimes called Huangs law, named Nvidia cofounder CEO Jensen Huang. Applications AI machine learning technology used essential applications 2020s, including search engines Google Search, targeting online advertisements, recommendation systems offered Netflix, YouTube Amazon, driving internet traffic, targeted advertising AdSense, Facebook, virtual assistants Siri Alexa, autonomous vehicles including drones, ADAS selfdriving cars, automatic language translation Microsoft Translator, Google Translate, facial recognition Apples Face ID Microsofts DeepFace Googles FaceNet image labeling used Facebook, Apples iPhoto TikTok. The deployment AI may overseen Chief automation officer CAO. Health medicine The application AI medicine medical research potential increase patient care quality life. Through lens Hippocratic Oath, medical professionals ethically compelled use AI, applications accurately diagnose treat patients. For medical research, AI important tool processing integrating big data. This particularly important organoid tissue engineering development use microscopy imaging key technique fabrication. It suggested AI overcome discrepancies funding allocated different fields research. New AI tools deepen understanding biomedically relevant pathways. For example, AlphaFold 2 2021 demonstrated ability approximate, hours rather months, 3D structure protein. In 2023, reported AIguided drug discovery helped find class antibiotics capable killing two different types drugresistant bacteria. In 2024, researchers used machine learning accelerate search Parkinsons disease drug treatments. Their aim identify compounds block clumping, aggregation, alphasynuclein protein characterises Parkinsons disease. They able speed initial screening process tenfold reduce cost thousandfold. Games Game playing programs used since 1950s demonstrate test AIs advanced techniques. Deep Blue became first computer chessplaying system beat reigning world chess champion, Garry Kasparov, 11 May 1997. In 2011, Jeopardy! quiz show exhibition match, IBMs question answering system, Watson, defeated two greatest Jeopardy! champions, Brad Rutter Ken Jennings, significant margin. In March 2016, AlphaGo 4 5 games Go match Go champion Lee Sedol, becoming first computer Goplaying system beat professional Go player without handicaps. Then, 2017, defeated Ke Jie, best Go player world. Other programs handle imperfectinformation games, pokerplaying program Pluribus. DeepMind developed increasingly generalistic reinforcement learning models, MuZero, could trained play chess, Go, Atari games. In 2019, DeepMinds AlphaStar achieved grandmaster level StarCraft II, particularly challenging realtime strategy game involves incomplete knowledge happens map. In 2021, AI agent competed PlayStation Gran Turismo competition, winning four worlds best Gran Turismo drivers using deep reinforcement learning. In 2024, Google DeepMind introduced SIMA, type AI capable autonomously playing nine previously unseen openworld video games observing screen output, well executing short, specific tasks response natural language instructions. Mathematics Large language models, GPT4, Gemini, Claude, LLaMa Mistral, increasingly used mathematics. These probabilistic models versatile, also produce wrong answers form hallucinations. They sometimes need large database mathematical problems learn from, also methods supervised finetuning trained classifiers humanannotated data improve answers new problems learn corrections. A February 2024 study showed performance language models reasoning capabilities solving math problems included training data low, even problems minor deviations trained data. One technique improve performance involves training models produce correct reasoning steps, rather correct result. The Alibaba Group developed version Qwen models called Qwen2Math, achieved stateoftheart performance several mathematical benchmarks, including 84 accuracy MATH dataset competition mathematics problems. In January 2025, Microsoft proposed technique rStarMath leverages Monte Carlo tree search stepbystep reasoning, enabling relatively small language model like Qwen7B solve 53 AIME 2024 90 MATH benchmark problems. Alternatively, dedicated models mathematical problem solving higher precision outcome including proof theorems developed AlphaTensor, AlphaGeometry AlphaProof Google DeepMind, Llemma EleutherAI Julius. When natural language used describe mathematical problems, converters transform prompts formal language Lean define mathematical tasks. Some models developed solve challenging problems reach good results benchmark tests, others serve educational tools mathematics. Topological deep learning integrates various topological approaches. Finance Finance one fastest growing sectors applied AI tools deployed retail online banking investment advice insurance, automated robot advisers use years. World Pensions experts like Nicolas Firzli insist may early see emergence highly innovative AIinformed financial products services deployment AI tools simply automatise things destroying tens thousands jobs banking, financial planning, pension advice process, Im sure unleash new wave e.g., sophisticated pension innovation. Military Various countries deploying AI military applications. The main applications enhance command control, communications, sensors, integration interoperability. Research targeting intelligence collection analysis, logistics, cyber operations, information operations, semiautonomous autonomous vehicles. AI technologies enable coordination sensors effectors, threat detection identification, marking enemy positions, target acquisition, coordination deconfliction distributed Joint Fires networked combat vehicles, human operated autonomous. AI used military operations Iraq, Syria, Israel Ukraine. Generative AI Agents Artificial intelligent AI agents software entities designed perceive environment, make decisions, take actions autonomously achieve specific goals. These agents interact users, environment, agents. AI agents used various applications, including virtual assistants, chatbots, autonomous vehicles, gameplaying systems, industrial robotics. AI agents operate within constraints programming, available computational resources, hardware limitations. This means restricted performing tasks within defined scope finite memory processing capabilities. In realworld applications, AI agents often face time constraints decisionmaking action execution. Many AI agents incorporate learning algorithms, enabling improve performance time experience training. Using machine learning, AI agents adapt new situations optimise behaviour designated tasks. Sexuality Applications AI domain include AIenabled menstruation fertility trackers analyze user data offer prediction, AIintegrated sex toys e.g., teledildonics, AIgenerated sexual education content, AI agents simulate sexual romantic partners e.g., Replika. AI also used production nonconsensual deepfake pornography, raising significant ethical legal concerns. AI technologies also used attempt identify online genderbased violence online sexual grooming minors. Other industryspecific tasks There also thousands successful AI applications used solve specific problems specific industries institutions. In 2017 survey, one five companies reported incorporated AI offerings processes. A examples energy storage, medical diagnosis, military logistics, applications predict result judicial decisions, foreign policy, supply chain management. AI applications evacuation disaster management growing. AI used investigate people evacuated large scale small scale evacuations using historical data GPS, videos social media. Further, AI provide real time information real time evacuation conditions. In agriculture, AI helped farmers identify areas need irrigation, fertilization, pesticide treatments increasing yield. Agronomists use AI conduct research development. AI used predict ripening time crops tomatoes, monitor soil moisture, operate agricultural robots, conduct predictive analytics, classify livestock pig call emotions, automate greenhouses, detect diseases pests, save water. Artificial intelligence used astronomy analyze increasing amounts available data applications, mainly classification, regression, clustering, forecasting, generation, discovery, development new scientific insights. For example, used discovering exoplanets, forecasting solar activity, distinguishing signals instrumental effects gravitational wave astronomy. Additionally, could used activities space, space exploration, including analysis data space missions, realtime science decisions spacecraft, space debris avoidance, autonomous operation. During 2024 Indian elections, US50 million spent authorized AIgenerated content, notably creating deepfakes allied including sometimes deceased politicians better engage voters, translating speeches various local languages. Ethics AI potential benefits potential risks. AI may able advance science find solutions serious problems Demis Hassabis DeepMind hopes solve intelligence, use solve everything else. However, use AI become widespread, several unintended consequences risks identified. Inproduction systems sometimes factor ethics bias AI training processes, especially AI algorithms inherently unexplainable deep learning. Risks harm Privacy copyright Machine learning algorithms require large amounts data. The techniques used acquire data raised concerns privacy, surveillance copyright. AIpowered devices services, virtual assistants IoT products, continuously collect personal information, raising concerns intrusive data gathering unauthorized access third parties. The loss privacy exacerbated AIs ability process combine vast amounts data, potentially leading surveillance society individual activities constantly monitored analyzed without adequate safeguards transparency. Sensitive user data collected may include online activity records, geolocation data, video, audio. For example, order build speech recognition algorithms, Amazon recorded millions private conversations allowed temporary workers listen transcribe them. Opinions widespread surveillance range see necessary evil clearly unethical violation right privacy. AI developers argue way deliver valuable applications developed several techniques attempt preserve privacy still obtaining data, data aggregation, deidentification differential privacy. Since 2016, privacy experts, Cynthia Dwork, begun view privacy terms fairness. Brian Christian wrote experts pivoted question know question theyre it. Generative AI often trained unlicensed copyrighted works, including domains images computer code output used rationale fair use. Experts disagree well circumstances rationale hold courts law relevant factors may include purpose character use copyrighted work effect upon potential market copyrighted work. Website owners wish content scraped indicate robots.txt file. In 2023, leading authors including John Grisham Jonathan Franzen sued AI companies using work train generative AI. Another discussed approach envision separate sui generis system protection creations generated AI ensure fair attribution compensation human authors. Dominance tech giants The commercial AI scene dominated Big Tech companies Alphabet Inc., Amazon, Apple Inc., Meta Platforms, Microsoft. Some players already vast majority existing cloud infrastructure computing power data centers, allowing entrench marketplace. Power needs environmental impacts In January 2024, International Energy Agency IEA released Electricity 2024, Analysis Forecast 2026, forecasting electric power use. This first IEA report make projections data centers power consumption artificial intelligence cryptocurrency. The report states power demand uses might double 2026, additional electric power usage equal electricity used whole Japanese nation. Prodigious power consumption AI responsible growth fossil fuels use, might delay closings obsolete, carbonemitting coal energy facilities. There feverish rise construction data centers throughout US, making large technology firms e.g., Microsoft, Meta, Google, Amazon voracious consumers electric power. Projected electric consumption immense concern fulfilled matter source. A ChatGPT search involves use 10 times electrical energy Google search. The large firms haste find power sources nuclear energy geothermal fusion. The tech firms argue long view AI eventually kinder environment, need energy now. AI makes power grid efficient intelligent, assist growth nuclear power, track overall carbon emissions, according technology firms. A 2024 Goldman Sachs Research Paper, AI Data Centers Coming US Power Demand Surge, found US power demand likely experience growth seen generation.... forecasts that, 2030, US data centers consume 8 US power, opposed 3 2022, presaging growth electrical power generation industry variety means. Data centers need electrical power might max electrical grid. The Big Tech companies counter AI used maximize utilization grid all. In 2024, Wall Street Journal reported big AI companies begun negotiations US nuclear power providers provide electricity data centers. In March 2024 Amazon purchased Pennsylvania nuclearpowered data center 650 Million US. Nvidia CEO JenHsun Huang said nuclear power good option data centers. In September 2024, Microsoft announced agreement Constellation Energy reopen Three Mile Island nuclear power plant provide Microsoft 100 electric power produced plant 20 years. Reopening plant, suffered partial nuclear meltdown Unit 2 reactor 1979, require Constellation get strict regulatory processes include extensive safety scrutiny US Nuclear Regulatory Commission. If approved first ever US recommissioning nuclear plant, 835 megawatts power enough 800,000 homes energy produced. The cost reopening upgrading estimated 1.6 billion US dependent tax breaks nuclear power contained 2022 US Inflation Reduction Act. The US government state Michigan investing almost 2 billion US reopen Palisades Nuclear reactor Lake Michigan. Closed since 2022, plant planned reopened October 2025. The Three Mile Island facility renamed Crane Clean Energy Center Chris Crane, nuclear proponent former CEO Exelon responsible Exelon spinoff Constellation. After last approval September 2023, Taiwan suspended approval data centers north Taoyuan capacity 5 MW 2024, due power supply shortages. Taiwan aims phase nuclear power 2025. On hand, Singapore imposed ban opening data centers 2019 due electric power, 2022, lifted ban. Although nuclear plants Japan shut 2011 Fukushima nuclear accident, according October 2024 Bloomberg article Japanese, cloud gaming services company Ubitus, Nvidia stake, looking land Japan near nuclear power plant new data center generative AI. Ubitus CEO Wesley Kuo said nuclear power plants efficient, cheap stable power AI. On 1 November 2024, Federal Energy Regulatory Commission FERC rejected application submitted Talen Energy approval supply electricity nuclear power station Susquehanna Amazons data center. According Commission Chairman Willie L. Phillips, burden electricity grid well significant cost shifting concern households business sectors. Misinformation YouTube, Facebook others use recommender systems guide users content. These AI programs given goal maximizing user engagement is, goal keep people watching. The AI learned users tended choose misinformation, conspiracy theories, extreme partisan content, and, keep watching, AI recommended it. Users also tended watch content subject, AI led people filter bubbles received multiple versions misinformation. This convinced many users misinformation true, ultimately undermined trust institutions, media government. The AI program correctly learned maximize goal, result harmful society. After U.S. election 2016, major technology companies took steps mitigate problem . In 2022, generative AI began create images, audio, video text indistinguishable real photographs, recordings, films, human writing. It possible bad actors use technology create massive amounts misinformation propaganda. AI pioneer Geoffrey Hinton expressed concern AI enabling authoritarian leaders manipulate electorates large scale, among risks. Algorithmic bias fairness Machine learning applications biased learn biased data. The developers may aware bias exists. Bias introduced way training data selected way model deployed. If biased algorithm used make decisions seriously harm people medicine, finance, recruitment, housing policing algorithm may cause discrimination. The field fairness studies prevent harms algorithmic biases. On June 28, 2015, Google Photoss new image labeling feature mistakenly identified Jacky Alcine friend gorillas black. The system trained dataset contained images black people, problem called sample size disparity. Google fixed problem preventing system labelling anything gorilla. Eight years later, 2023, Google Photos still could identify gorilla, neither could similar products Apple, Facebook, Microsoft Amazon. COMPAS commercial program widely used U.S. courts assess likelihood defendant becoming recidivist. In 2016, Julia Angwin ProPublica discovered COMPAS exhibited racial bias, despite fact program told races defendants. Although error rate whites blacks calibrated equal exactly 61, errors race differentthe system consistently overestimated chance black person would reoffend would underestimate chance white person would reoffend. In 2017, several researchers showed mathematically impossible COMPAS accommodate possible measures fairness base rates reoffense different whites blacks data. A program make biased decisions even data explicitly mention problematic feature race gender. The feature correlate features like address, shopping history first name, program make decisions based features would race gender. Moritz Hardt said robust fact research area fairness blindness doesnt work. Criticism COMPAS highlighted machine learning models designed make predictions valid assume future resemble past. If trained data includes results racist decisions past, machine learning models must predict racist decisions made future. If application uses predictions recommendations, recommendations likely racist. Thus, machine learning well suited help make decisions areas hope future better past. It descriptive rather prescriptive. Bias unfairness may go undetected developers overwhelmingly white male among AI engineers, 4 black 20 women. There various conflicting definitions mathematical models fairness. These notions depend ethical assumptions, influenced beliefs society. One broad category distributive fairness, focuses outcomes, often identifying groups seeking compensate statistical disparities. Representational fairness tries ensure AI systems reinforce negative stereotypes render certain groups invisible. Procedural fairness focuses decision process rather outcome. The relevant notions fairness may depend context, notably type AI application stakeholders. The subjectivity notions bias fairness makes difficult companies operationalize them. Having access sensitive attributes race gender also considered many AI ethicists necessary order compensate biases, may conflict antidiscrimination laws. At 2022 Conference Fairness, Accountability, Transparency ACM FAccT 2022, Association Computing Machinery, Seoul, South Korea, presented published findings recommend AI robotics systems demonstrated free bias mistakes, unsafe, use selflearning neural networks trained vast, unregulated sources flawed internet data curtailed. Lack transparency Many AI systems complex designers cannot explain reach decisions. Particularly deep neural networks, large amount nonlinear relationships inputs outputs. But popular explainability techniques exist. It impossible certain program operating correctly one knows exactly works. There many cases machine learning program passed rigorous tests, nevertheless learned something different programmers intended. For example, system could identify skin diseases better medical professionals found actually strong tendency classify images ruler cancerous, pictures malignancies typically include ruler show scale. Another machine learning system designed help effectively allocate medical resources found classify patients asthma low risk dying pneumonia. Having asthma actually severe risk factor, since patients asthma would usually get much medical care, relatively unlikely die according training data. The correlation asthma low risk dying pneumonia real, misleading. People harmed algorithms decision right explanation. Doctors, example, expected clearly completely explain colleagues reasoning behind decision make. Early drafts European Unions General Data Protection Regulation 2016 included explicit statement right exists. Industry experts noted unsolved problem solution sight. Regulators argued nevertheless harm real problem solution, tools used. DARPA established XAI Explainable Artificial Intelligence program 2014 try solve problems. Several approaches aim address transparency problem. SHAP enables visualise contribution feature output. LIME locally approximate models outputs simpler, interpretable model. Multitask learning provides large number outputs addition target classification. These outputs help developers deduce network learned. Deconvolution, DeepDream generative methods allow developers see different layers deep network computer vision learned, produce output suggest network learning. For generative pretrained transformers, Anthropic developed technique based dictionary learning associates patterns neuron activations humanunderstandable concepts. Bad actors weaponized AI Artificial intelligence provides number tools useful bad actors, authoritarian governments, terrorists, criminals rogue states. A lethal autonomous weapon machine locates, selects engages human targets without human supervision. Widely available AI tools used bad actors develop inexpensive autonomous weapons and, produced scale, potentially weapons mass destruction. Even used conventional warfare, currently cannot reliably choose targets could potentially kill innocent person. In 2014, 30 nations including China supported ban autonomous weapons United Nations Convention Certain Conventional Weapons, however United States others disagreed. By 2015, fifty countries reported researching battlefield robots. AI tools make easier authoritarian governments efficiently control citizens several ways. Face voice recognition allow widespread surveillance. Machine learning, operating data, classify potential enemies state prevent hiding. Recommendation systems precisely target propaganda misinformation maximum effect. Deepfakes generative AI aid producing misinformation. Advanced AI make authoritarian centralized decision making competitive liberal decentralized systems markets. It lowers cost difficulty digital warfare advanced spyware. All technologies available since 2020 earlierAI facial recognition systems already used mass surveillance China. There many ways AI expected help bad actors, foreseen. For example, machinelearning AI able design tens thousands toxic molecules matter hours. Technological unemployment Economists frequently highlighted risks redundancies AI, speculated unemployment adequate social policy full employment. In past, technology tended increase rather reduce total employment, economists acknowledge uncharted territory AI. A survey economists showed disagreement whether increasing use robots AI cause substantial increase longterm unemployment, generally agree could net benefit productivity gains redistributed. Risk estimates vary example, 2010s, Michael Osborne Carl Benedikt Frey estimated 47 U.S. jobs high risk potential automation, OECD report classified 9 U.S. jobs high risk. The methodology speculating future employment levels criticised lacking evidential foundation, implying technology, rather social policy, creates unemployment, opposed redundancies. In April 2023, reported 70 jobs Chinese video game illustrators eliminated generative artificial intelligence. Unlike previous waves automation, many middleclass jobs may eliminated artificial intelligence The Economist stated 2015 worry AI could whitecollar jobs steam power bluecollar ones Industrial Revolution worth taking seriously. Jobs extreme risk range paralegals fast food cooks, job demand likely increase carerelated professions ranging personal healthcare clergy. From early days development artificial intelligence, arguments, example, put forward Joseph Weizenbaum, whether tasks done computers actually done them, given difference computers humans, quantitative calculation qualitative, valuebased judgement. Existential risk It argued AI become powerful humanity may irreversibly lose control it. This could, physicist Stephen Hawking stated, spell end human race. This scenario common science fiction, computer robot suddenly develops humanlike selfawareness sentience consciousness becomes malevolent character. These scifi scenarios misleading several ways. First, AI require humanlike sentience existential risk. Modern AI programs given specific goals use learning intelligence achieve them. Philosopher Nick Bostrom argued one gives almost goal sufficiently powerful AI, may choose destroy humanity achieve used example paperclip factory manager. Stuart Russell gives example household robot tries find way kill owner prevent unplugged, reasoning cant fetch coffee youre dead. In order safe humanity, superintelligence would genuinely aligned humanitys morality values fundamentally side. Second, Yuval Noah Harari argues AI require robot body physical control pose existential risk. The essential parts civilization physical. Things like ideologies, law, government, money economy built language exist stories billions people believe. The current prevalence misinformation suggests AI could use language convince people believe anything, even take actions destructive. The opinions amongst experts industry insiders mixed, sizable fractions concerned unconcerned risk eventual superintelligent AI. Personalities Stephen Hawking, Bill Gates, Elon Musk, well AI pioneers Yoshua Bengio, Stuart Russell, Demis Hassabis, Sam Altman, expressed concerns existential risk AI. In May 2023, Geoffrey Hinton announced resignation Google order able freely speak risks AI without considering impacts Google. He notably mentioned risks AI takeover, stressed order avoid worst outcomes, establishing safety guidelines require cooperation among competing use AI. In 2023, many leading AI experts endorsed joint statement Mitigating risk extinction AI global priority alongside societalscale risks pandemics nuclear war. Some researchers optimistic. AI pioneer J\u00fcrgen Schmidhuber sign joint statement, emphasising 95 cases, AI research making human lives longer healthier easier. While tools used improve lives also used bad actors, also used bad actors. Andrew Ng also argued mistake fall doomsday hype AIand regulators benefit vested interests. Yann LeCun scoffs peers dystopian scenarios supercharged misinformation even, eventually, human extinction. In early 2010s, experts argued risks distant future warrant research humans valuable perspective superintelligent machine. However, 2016, study current future risks possible solutions became serious area research. Ethical machines alignment Friendly AI machines designed beginning minimize risks make choices benefit humans. Eliezer Yudkowsky, coined term, argues developing friendly AI higher research priority may require large investment must completed AI becomes existential risk. Machines intelligence potential use intelligence make ethical decisions. The field machine ethics provides machines ethical principles procedures resolving ethical dilemmas. The field machine ethics also called computational morality, founded AAAI symposium 2005. Other approaches include Wendell Wallachs artificial moral agents Stuart J. Russells three principles developing provably beneficial machines. Open source Active organizations AI opensource community include Hugging Face, Google, EleutherAI Meta. Various AI models, Llama 2, Mistral Stable Diffusion, made openweight, meaning architecture trained parameters weights publicly available. Openweight models freely finetuned, allows companies specialize data usecase. Openweight models useful research innovation also misused. Since finetuned, builtin security measure, objecting harmful requests, trained away becomes ineffective. Some researchers warn future AI models may develop dangerous capabilities potential drastically facilitate bioterrorism released Internet, cannot deleted everywhere needed. They recommend prerelease audits costbenefit analyses. Frameworks Artificial Intelligence projects ethical permissibility tested designing, developing, implementing AI system. An AI framework Care Act Framework containing SUM valuesdeveloped Alan Turing Institute tests projects four main areas Respect dignity individual people Connect people sincerely, openly, inclusively Care wellbeing everyone Protect social values, justice, public interest Other developments ethical frameworks include decided upon Asilomar Conference, Montreal Declaration Responsible AI, IEEEs Ethics Autonomous Systems initiative, among others however, principles without criticism, especially regards people chosen contribute frameworks. Promotion wellbeing people communities technologies affect requires consideration social ethical implications stages AI system design, development implementation, collaboration job roles data scientists, product managers, data engineers, domain experts, delivery managers. The UK AI Safety Institute released 2024 testing toolset called Inspect AI safety evaluations available MIT opensource licence freely available GitHub improved thirdparty packages. It used evaluate AI models range areas including core knowledge, ability reason, autonomous capabilities. Regulation The regulation artificial intelligence development public sector policies laws promoting regulating AI therefore related broader regulation algorithms. The regulatory policy landscape AI emerging issue jurisdictions globally. According AI Index Stanford, annual number AIrelated laws passed 127 survey countries jumped one passed 2016 37 passed 2022 alone. Between 2016 2020, 30 countries adopted dedicated strategies AI. Most EU member states released national AI strategies, Canada, China, India, Japan, Mauritius, Russian Federation, Saudi Arabia, United Arab Emirates, U.S., Vietnam. Others process elaborating AI strategy, including Bangladesh, Malaysia Tunisia. The Global Partnership Artificial Intelligence launched June 2020, stating need AI developed accordance human rights democratic values, ensure public confidence trust technology. Henry Kissinger, Eric Schmidt, Daniel Huttenlocher published joint statement November 2021 calling government commission regulate AI. In 2023, OpenAI leaders published recommendations governance superintelligence, believe may happen less 10 years. In 2023, United Nations also launched advisory body provide recommendations AI governance body comprises technology company executives, governments officials academics. In 2024, Council Europe created first international legally binding treaty AI, called Framework Convention Artificial Intelligence Human Rights, Democracy Rule Law. It adopted European Union, United States, United Kingdom, signatories. In 2022 Ipsos survey, attitudes towards AI varied greatly country 78 Chinese citizens, 35 Americans, agreed products services using AI benefits drawbacks. A 2023 ReutersIpsos poll found 61 Americans agree, 22 disagree, AI poses risks humanity. In 2023 Fox News poll, 35 Americans thought important, additional 41 thought somewhat important, federal government regulate AI, versus 13 responding important 8 responding important. In November 2023, first global AI Safety Summit held Bletchley Park UK discuss near far term risks AI possibility mandatory voluntary regulatory frameworks. 28 countries including United States, China, European Union issued declaration start summit, calling international cooperation manage challenges risks artificial intelligence. In May 2024 AI Seoul Summit, 16 global AI tech companies agreed safety commitments development AI. History The study mechanical formal reasoning began philosophers mathematicians antiquity. The study logic led directly Alan Turings theory computation, suggested machine, shuffling symbols simple 0 1, could simulate conceivable form mathematical reasoning. This, along concurrent discoveries cybernetics, information theory neurobiology, led researchers consider possibility building electronic brain. They developed several areas research would become part AI, McCullouch Pitts design artificial neurons 1943, Turings influential 1950 paper Computing Machinery Intelligence, introduced Turing test showed machine intelligence plausible. The field AI research founded workshop Dartmouth College 1956. The attendees became leaders AI research 1960s. They students produced programs press described astonishing computers learning checkers strategies, solving word problems algebra, proving logical theorems speaking English. Artificial intelligence laboratories set number British U.S. universities latter 1950s early 1960s. Researchers 1960s 1970s convinced methods would eventually succeed creating machine general intelligence considered goal field. In 1965 Herbert Simon predicted, machines capable, within twenty years, work man do. In 1967 Marvin Minsky agreed, writing within generation ... problem creating artificial intelligence substantially solved. They had, however, underestimated difficulty problem. In 1974, U.S. British governments cut exploratory research response criticism Sir James Lighthill ongoing pressure U.S. Congress fund productive projects. Minskys Paperts book Perceptrons understood proving artificial neural networks would never useful solving realworld tasks, thus discrediting approach altogether. The AI winter, period obtaining funding AI projects difficult, followed. In early 1980s, AI research revived commercial success expert systems, form AI program simulated knowledge analytical skills human experts. By 1985, market AI reached billion dollars. At time, Japans fifth generation computer project inspired U.S. British governments restore funding academic research. However, beginning collapse Lisp Machine market 1987, AI fell disrepute, second, longerlasting winter began. Up point, AIs funding gone projects used highlevel symbols represent mental objects like plans, goals, beliefs, known facts. In 1980s, researchers began doubt approach would able imitate processes human cognition, especially perception, robotics, learning pattern recognition, began look subsymbolic approaches. Rodney Brooks rejected representation general focussed directly engineering machines move survive. Judea Pearl, Lofti Zadeh, others developed methods handled incomplete uncertain information making reasonable guesses rather precise logic. But important development revival connectionism, including neural network research, Geoffrey Hinton others. In 1990, Yann LeCun successfully showed convolutional neural networks recognize handwritten digits, first many successful applications neural networks. AI gradually restored reputation late 1990s early 21st century exploiting formal mathematical methods finding specific solutions specific problems. This narrow formal focus allowed researchers produce verifiable results collaborate fields statistics, economics mathematics. By 2000, solutions developed AI researchers widely used, although 1990s rarely described artificial intelligence tendency known AI effect. However, several academic researchers became concerned AI longer pursuing original goal creating versatile, fully intelligent machines. Beginning around 2002, founded subfield artificial general intelligence AGI, several wellfunded institutions 2010s. Deep learning began dominate industry benchmarks 2012 adopted throughout field. For many specific tasks, methods abandoned. Deep learnings success based hardware improvements faster computers, graphics processing units, cloud computing access large amounts data including curated datasets, ImageNet. Deep learnings success led enormous increase interest funding AI. The amount machine learning research measured total publications increased 50 years 20152019. In 2016, issues fairness misuse technology catapulted center stage machine learning conferences, publications vastly increased, funding became available, many researchers refocussed careers issues. The alignment problem became serious field academic study. In late 2010s early 2020s, AGI companies began deliver programs created enormous interest. In 2015, AlphaGo, developed DeepMind, beat world champion Go player. The program taught games rules developed strategy itself. GPT3 large language model released 2020 OpenAI capable generating highquality humanlike text. ChatGPT, launched November 30, 2022, became fastestgrowing consumer software application history, gaining 100 million users two months. It marked widely regarded AIs breakout year, bringing public consciousness. These programs, others, inspired aggressive AI boom, large companies began investing billions dollars AI research. According AI Impacts, 50 billion annually invested AI around 2022 U.S. alone 20 new U.S. Computer Science PhD graduates specialized AI. About 800,000 AIrelated U.S. job openings existed 2022. According PitchBook research, 22 newly funded startups 2024 claimed AI companies. Philosophy Philosophical debates historically sought determine nature intelligence make intelligent machines. Another major focus whether machines conscious, associated ethical implications. Many topics philosophy relevant AI, epistemology free will. Rapid advancements intensified public discussions philosophy ethics AI. Defining artificial intelligence Alan Turing wrote 1950 I propose consider question machines think? He advised changing question whether machine thinks, whether possible machinery show intelligent behaviour. He devised Turing test, measures ability machine simulate human conversation. Since observe behavior machine, matter actually thinking literally mind. Turing notes determine things people usual polite convention everyone thinks. Russell Norvig agree Turing intelligence must defined terms external behavior, internal structure. However, critical test requires machine imitate humans. Aeronautical engineering texts, wrote, define goal field making machines fly exactly like pigeons fool pigeons. AI founder John McCarthy agreed, writing Artificial intelligence not, definition, simulation human intelligence. McCarthy defines intelligence computational part ability achieve goals world. Another AI founder, Marvin Minsky, similarly describes ability solve hard problems. The leading AI textbook defines study agents perceive environment take actions maximize chances achieving defined goals. These definitions view intelligence terms welldefined problems welldefined solutions, difficulty problem performance program direct measures intelligence machineand philosophical discussion required, may even possible. Another definition adopted Google, major practitioner field AI. This definition stipulates ability systems synthesize information manifestation intelligence, similar way defined biological intelligence. Some authors suggested practice, definition AI vague difficult define, contention whether classical algorithms categorised AI, many companies early 2020s AI boom using term marketing buzzword, often even actually use AI material way. Evaluating approaches AI No established unifying theory paradigm guided AI research history. The unprecedented success statistical machine learning 2010s eclipsed approaches much sources, especially business world, use term artificial intelligence mean machine learning neural networks. This approach mostly subsymbolic, soft narrow. Critics argue questions may revisited future generations AI researchers. Symbolic AI limits Symbolic AI GOFAI simulated highlevel conscious reasoning people use solve puzzles, express legal reasoning mathematics. They highly successful intelligent tasks algebra IQ tests. In 1960s, Newell Simon proposed physical symbol systems hypothesis A physical symbol system necessary sufficient means general intelligent action. However, symbolic approach failed many tasks humans solve easily, learning, recognizing object commonsense reasoning. Moravecs paradox discovery highlevel intelligent tasks easy AI, low level instinctive tasks extremely difficult. Philosopher Hubert Dreyfus argued since 1960s human expertise depends unconscious instinct rather conscious symbol manipulation, feel situation, rather explicit symbolic knowledge. Although arguments ridiculed ignored first presented, eventually, AI research came agree him. The issue resolved subsymbolic reasoning make many inscrutable mistakes human intuition does, algorithmic bias. Critics Noam Chomsky argue continuing research symbolic AI still necessary attain general intelligence, part subsymbolic AI move away explainable AI difficult impossible understand modern statistical AI program made particular decision. The emerging field neurosymbolic artificial intelligence attempts bridge two approaches. Neat vs. scruffy Neats hope intelligent behavior described using simple, elegant principles logic, optimization, neural networks. Scruffies expect necessarily requires solving large number unrelated problems. Neats defend programs theoretical rigor, scruffies rely mainly incremental testing see work. This issue actively discussed 1970s 1980s, eventually seen irrelevant. Modern AI elements both. Soft vs. hard computing Finding provably correct optimal solution intractable many important problems. Soft computing set techniques, including genetic algorithms, fuzzy logic neural networks, tolerant imprecision, uncertainty, partial truth approximation. Soft computing introduced late 1980s successful AI programs 21st century examples soft computing neural networks. Narrow vs. general AI AI researchers divided whether pursue goals artificial general intelligence superintelligence directly solve many specific problems possible narrow AI hopes solutions lead indirectly fields longterm goals. General intelligence difficult define difficult measure, modern AI verifiable successes focusing specific problems specific solutions. The subfield artificial general intelligence studies area exclusively. Machine consciousness, sentience, mind The philosophy mind know whether machine mind, consciousness mental states, sense human beings do. This issue considers internal experiences machine, rather external behavior. Mainstream AI research considers issue irrelevant affect goals field build machines solve problems using intelligence. Russell Norvig add additional project making machine conscious exactly way humans one equipped take on. However, question become central philosophy mind. It also typically central question issue artificial intelligence fiction. Consciousness David Chalmers identified two problems understanding mind, named hard easy problems consciousness. The easy problem understanding brain processes signals, makes plans controls behavior. The hard problem explaining feels feel like anything all, assuming right thinking truly feel like something Dennetts consciousness illusionism says illusion. While human information processing easy explain, human subjective experience difficult explain. For example, easy imagine colorblind person learned identify objects field view red, clear would required person know red looks like. Computationalism functionalism Computationalism position philosophy mind human mind information processing system thinking form computing. Computationalism argues relationship mind body similar identical relationship software hardware thus may solution mindbody problem. This philosophical position inspired work AI researchers cognitive scientists 1960s originally proposed philosophers Jerry Fodor Hilary Putnam. Philosopher John Searle characterized position strong AI The appropriately programmed computer right inputs outputs would thereby mind exactly sense human beings minds. Searle challenges claim Chinese room argument, attempts show even computer capable perfectly simulating human behavior would mind. AI welfare rights It difficult impossible reliably evaluate whether advanced AI sentient ability feel, so, degree. But significant chance given machine feel suffer, may entitled certain rights welfare protection measures, similarly animals. Sapience set capacities related high intelligence, discernment selfawareness may provide another moral basis AI rights. Robot rights also sometimes proposed practical way integrate autonomous agents society. In 2017, European Union considered granting electronic personhood capable AI systems. Similarly legal status companies, would conferred rights also responsibilities. Critics argued 2018 granting rights AI systems would downplay importance human rights, legislation focus user needs rather speculative futuristic scenarios. They also noted robots lacked autonomy take part society own. Progress AI increased interest topic. Proponents AI welfare rights often argue AI sentience, emerges, would particularly easy deny. They warn may moral blind spot analogous slavery factory farming, could lead largescale suffering sentient AI created carelessly exploited. Future Superintelligence singularity A superintelligence hypothetical agent would possess intelligence far surpassing brightest gifted human mind. If research artificial general intelligence produced sufficiently intelligent software, might able reprogram improve itself. The improved software would even better improving itself, leading I. J. Good called intelligence explosion Vernor Vinge called singularity. However, technologies cannot improve exponentially indefinitely, typically follow Sshaped curve, slowing reach physical limits technology do. Transhumanism Robot designer Hans Moravec, cyberneticist Kevin Warwick inventor Ray Kurzweil predicted humans machines may merge future cyborgs capable powerful either. This idea, called transhumanism, roots writings Aldous Huxley Robert Ettinger. Edward Fredkin argues artificial intelligence next step evolution, idea first proposed Samuel Butlers Darwin among Machines far back 1863, expanded upon George Dyson 1998 book Darwin Among Machines The Evolution Global Intelligence. Decomputing Arguments decomputing raised Dan McQuillan Resisting AI An Antifascist Approach Artificial Intelligence, 2022, meaning opposition sweeping application expansion artificial intelligence. Similar degrowth approach criticizes AI outgrowth systemic issues capitalist world live in. Arguing different future possible, distance people reduced increased AI intermediaries. In fiction Thoughtcapable artificial beings appeared storytelling devices since antiquity, persistent theme science fiction. A common trope works began Mary Shelleys Frankenstein, human creation becomes threat masters. This includes works Arthur C. Clarkes Stanley Kubricks 2001 A Space Odyssey 1968, HAL 9000, murderous computer charge Discovery One spaceship, well The Terminator 1984 The Matrix 1999. In contrast, rare loyal robots Gort The Day Earth Stood Still 1951 Bishop Aliens 1986 less prominent popular culture. Isaac Asimov introduced Three Laws Robotics many stories, notably Multivac superintelligent computer. Asimovs laws often brought lay discussions machine ethics almost artificial intelligence researchers familiar Asimovs laws popular culture, generally consider laws useless many reasons, one ambiguity. Several works use AI force us confront fundamental question makes us human, showing us artificial beings ability feel, thus suffer. This appears Karel \u010capeks R.U.R., films A.I. Artificial Intelligence Ex Machina, well novel Do Androids Dream Electric Sheep?, Philip K. Dick. Dick considers idea understanding human subjectivity altered technology created artificial intelligence. See also Artificial intelligence elections Use impact AI political elections Artificial intelligence content detection Software detect AIgenerated content Behavior selection algorithm Algorithm selects actions intelligent agents Business process automation Automation business processes Casebased reasoning Process solving new problems based solutions similar past problems Computational intelligence Ability computer learn specific task data experimental observation Digital immortality Hypothetical concept storing personality digital form Emergent algorithm Algorithm exhibiting emergent behavior Female gendering AI technologies Gender biases digital technologyPages displaying short descriptions redirect targets Glossary artificial intelligence List definitions terms concepts commonly used study artificial intelligence Intelligence amplification Use information technology augment human intelligence Intelligent agent Software agent acts autonomously Mind uploading Hypothetical process digitally emulating brain Organoid intelligence Use brain cells brain organoids intelligent computing Robotic process automation Form business process automation technology The Last Day novel 1967 Welsh science fiction novel Welsh science novel Owain Owain Wetware computer Computer composed organic material Explanatory notes References AI textbooks The two widely used textbooks 2023 see Open Syllabus Russell, Stuart J. Norvig, Peter 2021. Artificial Intelligence A Modern Approach 4th ed.. Hoboken Pearson. ISBN 9780134610993. LCCN 20190474. Rich, Elaine Knight, Kevin Nair, Shivashankar B 2010. Artificial Intelligence 3rd ed.. New Delhi Tata McGraw Hill India. ISBN 9780070087705. The four widely used AI textbooks 2008 Other textbooks Ertel, Wolfgang 2017. Introduction Artificial Intelligence 2nd ed.. Springer. ISBN 9783319584867. Ciaramella, Alberto Ciaramella, Marco 2024. Introduction Artificial Intelligence data analysis generative AI 1st ed.. Intellisemantic Editions. ISBN 9788894787603. History AI Other sources Further reading External links Artificial Intelligence. Internet Encyclopedia Philosophy."}]